{"/":{"title":"M Garden.","content":"\nWelcome to my second brain where I store my notes on the interesting topics that I find amusing.\n\nMostly my blogs will be about:\n[Azure](Azure/Azure.md)\n\n[setup](notes/setup.md)","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-AWS-/-Application-Integration-/CloudFormation":{"title":"CloudFormation","content":"# CloudFormation\n#aws  #IaC #cloud\n\n\nA templating Language to write infrastructure configuration as code offered by [AWS](-=%20AWS%20=-/AWS.md)\n\n![Pasted image 20220724014004](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724014004.png)\n\n![Pasted image 20220724014404](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724014404.png)","lastmodified":"2023-03-02T18:25:17.191873828Z","tags":null},"/-AWS-/-Application-Integration-/Kinesis":{"title":"Kinesis","content":"# Kinesis\n#aws #cloud #serverless #dataanalytics \n\nFamily of services to collect, process and analyze streaming data in real-time by [AWS](-=%20AWS%20=-/AWS.md).\n\n  \n\nStreaming data is simply data continuously generated by many data sources sending a small amount of information simultaneously. (Think of harvesting rainwater)\n\n  \n\nDeals with moving data (streaming data) similar to Kafka.  \n\n  \n  \n\n![](https://lh3.googleusercontent.com/fqvPvTF6jvixi1dlnkoD1ownxLkJ4b6HO0PNA-PlkpBL8oKeMh1fR-VEQemZQrlDuVSShMgUTHhLS35knJ_c2meCBddV6Ye71wJvq9gVVM0l69UjO9voJKltwrGhmccYH6K20O5Vl12If1GGnWMl-A)\n\n# ![](https://lh3.googleusercontent.com/7awo3t9K42epjV4VL7EpB-A4WTwaQA_wfGyqZb_OpOhceDwOqin6cqEn6HC04rxs9DHf15TSeY74xK2ErVS5nelWilvrZjDUgRiftJTtge379QoL0xYvkNVD-XPpIid4JzPRi6nXKGAtFDVMyVKGcQ)\n\n  \n\n## Kinesis Streams\n\nEnables us to stream data and video. (Kinesis Data Streams and Kinesis Video Streams).\n\n(Eg recording online meeting video, Game score in real-time).\n\nUses Shards, retains data, and requires Consumers.\n\n### Kinesis Data Stream\n  \n![Pasted image 20220724152204](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724152204.png)\n\n### Kinesis Video Streams\n![Pasted image 20220724152502](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724152502.png)\n\n## Kinesis Data Firehose\n\n- Load streaming data into AWS data stores for near-real-time analytics.  \n- No Shards, No Data retention, Optional Consumer and Automatic Capacity\n- Consumers are optional. (can Chose only one consumer)\n- Data is not persisted\n- Can use Lambda for processing data.\n- Data is directly to the AWS store.\n- Inexpensive\n\n  ![Pasted image 20220724152311](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724152311.png)\n  \n  \n  \n\n## Kinesis Data Analytics\n\nFor real time analytics. You need to specify Data Firehose or Data Stream\n\nAllows running sql queries and stores the result on AWS datastore.\n\n  \n  \n\n# Kinesis Shards\n\nKinesis streams are made up of shards.\n\nData capacity of streams are determined by shards.\n\nEach shard is a sequence of one or more data records and provides a fixed unit of capacity.\n\n(read: 5 per second, 2MB per second) (write: 1000 per second, 1MB per second).\n\n  \n\n![](https://lh3.googleusercontent.com/9ULTmqXp9GDk4KADSNA8kaRFIRVcP7hTd4S2N__eBiMd8Ks_L1JbuN4GXf6KQ-8_U81aSy4k646YU4LL_NroE6axjaTS5WfOaDQ9SpVs_jFYEmzb52LxHK_cGdDNBo_9YxnmMJ_GoBZzzYCXfqc_Jw)\n\n  \n\n\n![Pasted image 20220724152615](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724152615.png)","lastmodified":"2023-03-02T18:25:17.191873828Z","tags":null},"/-AWS-/-Application-Integration-/SNS":{"title":"SNS","content":"# AWS SNS\n#aws #cloud #notification\n\nA simple service by [AWS](-=%20AWS%20=-/AWS.md) enabling users to send notifications via SMS, Push notifications, or email. It can be used to send essential automated sms to the designated users.\n\nSuscribe and send notifications via text message, push notification,\n\n\n![Pasted image 20220724104926](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724104926.png)\n\n\n## SNS Topics\n\nTopics allows you to group multiple subscriptions together.\n\nA topic is able to deliver to multiple protocols at once eg. email, text message, http/s\n\n\n## SNS-Subscriptions\nA subscription can only subscribe to one protocol and one topic.\n\n![Pasted image 20220724124451](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724124451.png)","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Application-Integration-/SQS":{"title":"SQS","content":"# SQS\n#aws #cloud #serverless #microservices  #decoupleing #queue\n\nFirst-ever [AWS](-=%20AWS%20=-/AWS.md) service that was made publicly available. (Oldest service). \nMessage Queue service enables web services applications to queue messages.\nActs like a buffer between the components between different components.\nCan set up an Autoscaling group to SQS which is a great practice.\nPick up messages using a “poll”.\nMostly used for pull-based operations.\n\n\n## Features\n-   Allow us to decouple the components of an application so that they are independent\n-   Pull based message store (Poll) (256 KB max size of the text in any format)\n-   Retrieve the messages using SQS API\n-   Text Data (XML, JSON and unformatted text)\n-   Guarantees that message will be processed at least once\n-   The default retention period is 4 days\n-   Max message retention time is 14 days\n\n\n## Visibility Timeout\n-   Default is 30 seconds\n-   If a message isn't processed within 30 seconds, the item will reappear\n-   You can increase the visibility Timeout.    \n-   Max timeout is 12 hours    \n\n  \n\n## Polling  \n![](https://lh3.googleusercontent.com/kX3LN5a7jK4UmacSq5znYiNFZuQL8dXL4uz-QOqbGQ_UR_aUdyJ3WCAm3NDREirE23EQX7IrfiTQWRzDBKjCvALs7qcJpaqMdEjaOKreRbHWKxe2Q8H54O4qlwSczdLOqCMbl1eYSFWGJCEUcr_Kag)\n\n\nSQS Delay Queue postpones delivery of new messages (makes them invisible)(0s-900s). It only affects standard queues but it will affect the whole FIFO Queue. (e.g. for confirming the order in E-commerce).\n\n  \n\nUsing S3 for large SQS message (256KB-2GB) (Amazon SQS Extended Client Library for Java, AWS SDK for java)\n\n**\n\nFully managed queing services that enables you to decouple a big complex architecture to a simpler one. It is primarily for Application integration.\n\npull based.\n\nMessege size can be between 1 byte to 256 KB\n\nExtended storage option is availabe on Java SDK which allows storage of message upto 2GB but will be required to be stored in S3.\n\nMessage retention by default is 4 days\n\nfrom min of 60 seconds to max of 14 days\n\n\n## Standard Queues\n![Pasted image 20220724103848](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724103848.png)\nAllows nearly-unlimited number of transactions per second\nGuarantees that a message will be delivered at least once.\nWhich means more than one copy of message could be potentially delivered out of order.\nProvides best-effort ordering that helps ensure a message is generally delivered in the same order that it was sent.\n\n\n## FIFO Queue\n![Pasted image 20220724104025](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724104025.png)\n\nsupports multiple ordered message groups within a single queue\nLimited to 300 transactions per second\nHave all of the capabilities of a standard queue.\n\n## Visibility Timeout\nTo prevent another app from reading a message which is already being processed by another app. This help\n\n\n## polling\n![Pasted image 20220724104406](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724104406.png)\n\n\n\n![Pasted image 20220724104428](-=%20AWS%20=-/--%20Application%20Integration%20--/Pasted%20image%2020220724104428.png)","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Compute-/Bastion":{"title":"Bastion","content":"# Bastion\n#aws #ec2 #cloud #compute \nalso known as Jump-box\n\nBastions are [Elastic Compute Cloud EC2](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Compute%20Cloud%20EC2.md) instances which are security harden. They are designed to help you gain access to your EC2 via SSH or RCP that are in private subnet which are not directly accessible from the internet.\n\nThey are also known as Jump Boxes.\n\nNAT Gateways/ Instances are only intended for EC2 instances to gain outbound access to the internet for things such as security updates. NATs cannot/should not be used as bastions.\n\nSystems Manager's SSM provides an alternative to the bastion hosts.\n\n\n\nA bastion host is a special-purpose computer on a network specifically designed and configured to withstand attacks, so named by analogy to the military fortification. The computer generally hosts a single application or process, for example, a proxy server or load balancer, and all other services are removed or limited to reduce the threat to the computer. It is hardened in this manner primarily due to its location and purpose, which is either on the outside of a firewall or inside of a demilitarized zone ([DMZ](DMZ)) and usually involves access from untrusted networks or computers. These computers are also equipped with special networking interfaces to withstand high-bandwidth attacks through the internet.\n\n\nMost often the [security group](-=%20AWS%20=-/--%20Compute%20--/security%20group.md) of the bastion is added to the security group of the instance to be accessed. This is the","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Compute-/EC2-Spot":{"title":"EC2 Spot","content":"# EC2 Spot Instances\n#aws #compute #ec2 \n\n[AWS](-=%20AWS%20=-/AWS.md) Provides a cheaper alternative compute solution in [Elastic Compute Cloud EC2](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Compute%20Cloud%20EC2.md) for non important tasks. AWS markets them as \"Amazon _EC2 Spot instances_ are spare compute capacity in the AWS cloud available to you at steep discounts compared to On-Demand prices.\" ","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Compute-/ECS":{"title":"ECS","content":"# ECS (Elastic Container Service)\n#aws #cloud #containers \n\nAmazon ECS is a fully managed [Container orchestration](Container%20orchestration) service by [AWS](-=%20AWS%20=-/AWS.md) that helps you easily deploy, manage, and scale containerized applications. It deeply integrates with the rest of the AWS platform to provide a secure and easy-to-use solution for running [container](container) workloads in the cloud and now on your infrastructure with Amazon ECS Anywhere.\n![Pasted image 20230103141505.png](Pasted%20image%2020230103141505.png)","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Compute-/EKS":{"title":"EKS","content":"# EKS (Elastic Kubernetes Service)\n#aws #cloud #Kubernetes #managed-kubernetes-cluster \n\nAmazon EKS is a managed [Kubernetes](Kubernetes) service to run Kubernetes in the [AWS](-=%20AWS%20=-/AWS.md) cloud and on-premises data centers. In the cloud, Amazon EKS automatically manages the availability and scalability of the Kubernetes control plane nodes responsible for scheduling containers, managing application availability, storing cluster data, and other key tasks. With Amazon EKS, you can take advantage of all the performance, scale, reliability, and availability of AWS infrastructure, as well as integrations with AWS networking and security services. On-premises, EKS provides a consistent, fully-supported Kubernetes solution with integrated tooling and simple deployment to AWS Outposts, virtual machines, or bare metal servers.","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Compute-/Elastic-Compute-Cloud-EC2":{"title":"Elastic Compute Cloud EC2","content":"# EC2\n\n#aws #cloud #compute \n\nThe Amazon Elastic Compute Cloud, is an [AWS](-=%20AWS%20=-/AWS.md) platform for providing cloud-based compute capacity. That means it provides virtual machines in the sky. Where [S3](-=%20AWS%20=-/--%20Storage%20--/S3.md) is cloud storage and [RDS](-=%20AWS%20=-/--%20Databases%20--/RDS.md) is cloud relational databases, EC2 gives you a machine where you can run anything you want. Want to run a web server, EC2 can do that. Want to run a database, EC2 can do that.  \n-   AWS Elastic Compute Cloud is a computing web service which provides re-sizeable, secure, and reliable capacity in the cloud\n-   You have complete control of your EC2 computing resources.\n-   You can scale up or scale down the capacity of your EC2 resources as your technical requirements change\n-   You must pay only for EC2 resources that you use\n-   You can build and boot new computing instances in only some little minutes\n\n## Instance Types\n![Pasted image 20220722150557](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220722150557.png)\n\n## Instance Size\n\n## Instance Categories\n\n![EC2 state transfer characteistics](-=%20AWS%20=-/EC2%20state%20transfer%20characteistics.png)\n\n## Instance Pricing\n\n![Pasted image 20220706163457.png](Pasted%20image%2020220706163457.png)\n\n\n## Instance Status\n![EC2 states](-=%20AWS%20=-/EC2%20states.png)\n\n\n## Placement Groups\n\nPlacement Groups lets you choose the logical placement of your instances to optimize for communication, performance or durability. Placement groups are free\n![Pasted image 20220722151020](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220722151020.png)\n\n\n## Userdata\nA simple bash script that will be run automatically while launching the EC2 instance. \n\n\n## Metadata\nAdditional information about the current EC2 instance which you can get from the instance. Can be accessed via http://169.254.169.254/latest/meta-data.\n\n## AMI\nAmazon Machine Image (AMI) provides the information required to launch an instance. We can turn EC2 instances into AMIs to make copies of your servers. We can create an ami from an running or stopped ec2 instance. While launching a new instance we will need to pick an AMI with the operating systems and configurations of our choice. AMIs have different IDs on different regions. We can make copies of our AMIs which will let you transport AMIs to other regions or even accounts using `copy ami` command.\n\n**Use cases:**\n1. Help you keep incremental changes to your OS, application code and system packages.\n2. Can be configured with Systems Manager Automation to routinely patch your AMIs with security updates\n3. Is required to launch new instances in the autoscaling groups as it is required to create a launch configuration/launch template.\n\n\n## Storage Options\n\n\n## Network Options\n\n\n## Security Options\n\n### Instance Profile\nInstead of embedding your AWS access key, you can attach a role to an instance via an Instance Profile. It holds a reference to a role. The EC2 instance is associated with the Instance Profile. Basically a container for an IAM role that you can use to pass role information to an EC2 instance when the instance starts.\n\n\n## Elastic Load Balance\n\n\n## Auto Scaling Groups\nSet scaling rules which will add or reduce ec2 instance in an group to meet the demand of the traffic. \n\n### ASG-Capacity Settings\n\nThe size of tan ASG is based on Min, Max and Desired Capacity.\n\nASG will always launch instances to meet minimum capacity.\n\n\n### Health Check Replacements\n\n#### 1. EC2 Health Check\n[EC2 health check](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html) watches for instance availability from hypervisor and networking point of view. For example, in case of a hardware problem, the check will fail. Also, if an instance was misconfigured and doesn't respond to network requests, it will be marked as faulty.\n\n#### 2. ELB Health Check\n[ELB health check](http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html) verifies that a specified TCP port on an instance is accepting connections OR a specified web page returns 2xx code. Thus ELB health checks are a little bit smarter and verify that actual app works instead of verifying that just an instance works.\n\n#### 3. Custom Health Check\nIf your application can't be checked by simple HTTP request and requires advanced test logic, you can implement a custom check in your code and set instance health though API: [Health Checks for Auto Scaling Instances](http://docs.aws.amazon.com/autoscaling/latest/userguide/healthcheck.html)\n\n### Scaling Polices\nScale out or in to add or remove instances in an ASG.\nAmazon’s EC2 Auto Scaling provides an effective way to ensure that your infrastructure is able to dynamically respond to changing user demands. For example, to accommodate a sudden traffic increase on your web application, you can set your Auto Scaling group to automatically add more instances. And when traffic is low, have it automatically reduce the number of instances. This is a cost-effective solution since it only provisions EC2 instances when you need them. EC2 Auto Scaling provides you with several dynamic scaling policies to control the scale-in and scale-out events.\n\n#### 1. Simple Scaling\nSimple scaling relies on a metric as a basis for scaling. For example, you can set a CloudWatch alarm to have a CPU Utilization threshold of 80%, and then set the scaling policy to add 20% more capacity to your Auto Scaling group by launching new instances. Accordingly, you can also set a CloudWatch alarm to have a CPU utilization threshold of 30%. When the threshold is met, the Auto Scaling group will remove 20% of its capacity by terminating EC2 instances. \n\nWhen EC2 Auto Scaling was first introduced, this was the only scaling policy supported. It does not provide any fine-grained control to scaling in and scaling out.\n\n#### 2. Target Tracking\nTarget tracking policy lets you specify a scaling metric and metric value that your auto scaling group should maintain at all times. Let’s say for example your scaling metric is the average CPU utilization of your EC2 auto scaling instances, and that their average should always be 80%. When CloudWatch detects that the average CPU utilization is beyond 80%, it will trigger your target tracking policy to scale out the auto scaling group to meet this target utilization. Once everything is settled and the average CPU utilization has gone below 80%, another scale in action will kick in and reduce the number of auto scaling instances in your auto scaling group. With target tracking policies, your auto scaling group will always be running in a capacity that is defined by your scaling metric and metric value.\n\n#### 3. Step Scaling\nStep Scaling further improves the features of simple scaling. Step scaling applies “step adjustments” which means you can set multiple actions to vary the scaling depending on the size of the alarm breach. \n\nWhen a scaling event happens on simple scaling, the policy must wait for the health checks to complete and the cooldown to expire before responding to an additional alarm. This causes a delay in increasing capacity especially when there is a sudden surge of traffic on your application. With step scaling, the policy can continue to respond to additional alarms even in the middle of the scaling event. \n\nHere is an example that shows how step scaling works:\n\n![Step Scaling vs Simple Scaling Policies in Amazon EC2](https://td-mainsite-cdn.tutorialsdojo.com/wp-content/uploads/2020/06/Step-Scaling1.jpg)","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Compute-/Elastic-Load-Balancer-ELB":{"title":"Elastic Load Balancer (ELB)","content":"# Elastic Load balancer (ELB)\n#aws #cloud #vpc #networking #loadbalancer\n\nLoadbalancer service provided by [AWS](-=%20AWS%20=-/AWS.md)\n\nElastic Load Balancing supports the following types of load balancers: **Application Load Balancers, Network Load Balancers, and Classic Load Balancers**.\n\n## Common Features\n\nLet’s start by taking a look at what is common for all three types of load balancers. \n\nObviously, all AWS load balancers distribute incoming requests to a number of targets, which can be either EC2 instances or Docker containers. They all implement health checks, which are used to detect unhealthy instances. They are all highly available and elastic (in AWS parlance: They scale up and down within a few minutes according to workload). \n\nTLS termination is a feature available for all three as well, and they can all be either internet-facing or internal. Finally, ELB, ALB, and NLB all export useful metrics to CloudWatch and can log pertinent information to CloudWatch Logs.\n\n![Pasted image 20220723213315](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220723213315.png)\n\n\n# Classic Load Balancer (CLB)\n\nWidely known as CLB it was the original Elastic Load Balancer, as this was its name when it was first introduced in 2009 and was the only type of load balancer available. It can be thought of as an Nginx or HAProxy instance if that makes it easier for you to understand.\n\nELB works at both layer 4 (TCP) and 7 (HTTP) but not on the same time. It is the only load balancer that works in EC2-Classic, in case you have a very old AWS account. Also, it’s the only load balancer that supports application-defined sticky session cookies; in contrast, ALB uses its own cookies, and you have no control over that.\n\nAt layer 7, ELB can terminate TLS traffic. It can also re-encrypt the traffic to the targets as long as they provide an SSL certificate (a self-signed certificate is fine, BTW). This provides end-to-end encryption, which is a usual requirement in many compliance programs. Optionally, ELB can be configured to verify the TLS certificate provided by the target for extra security.\n\nELB has quite a few limitations. For example, it isn’t compatible with EKS containers running on Fargate. Also, it can’t forward traffic on more than one port per instance, and it doesn’t support forwarding to IP addresses—it can only forward to explicit EC2 instances or containers in ECS or EKS. Finally, ELB doesn’t support websockets; however, you may be able to work around this limitation by using layer 4.\n\nTo run an ELB in the us-east-1 region, it will cost you $0.025 per ELB-hour + $0.008 per GB of traffic.\n\nAWS discourages the use of ELB in favor of its newer load balancers. Admittedly, there are very few scenarios where the use of an ELB would be preferable; typically, these are cases where you simply don’t have a choice. For example, your workload might still run on [EC2-Classic](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-classic-platform.html), or you need the load balancer to use your own sticky session cookies, in which cases ELB would be the only option available to you.\n\n\n\n## Application Load Balancer (ALB)\n\nIt works only on layer 7 (HTTP) of the [OSI](OSI). It has a wide range of routing rules for incoming requests based on host name, path, query string parameter, HTTP method, HTTP headers, source IP, or port number. In contrast, ELB only allows routing based on port number. Also, contrary to ELB, ALB can route requests to many ports on a single target. Plus, ALB can route requests to Lambda functions.\n\nIt has a feature called Request Routing which allows you to add routing rules to your application.\n\nA very useful feature of ALB is that it can be configured to return a fixed response or a redirection. So you don’t need a server to perform such basic tasks because it is all embedded in the ALB itself. Also very importantly, ALB supports HTTP/2 and websockets.\n\nALB further supports [Server Name Indication (SNI)](https://www.cloudflare.com/learning/ssl/what-is-sni/), which allows it to serve many domain names. (In contrast, ELB can serve only one domain name). There is a limit, however, to the number of certificates you can attach to an ALB, [namely 25 certificates](https://aws.amazon.com/blogs/aws/new-application-load-balancer-sni/) plus the default certificate.\n\nAn interesting feature of ALB is that it supports user authentication via a variety of methods, including OIDC, SAML, LDAP, Microsoft AD, and well-known social identity providers such as Facebook and Google. This can help you off-load the user authentication part of your application to the load balancer. \n\nALB pricing is a bit more complicated than ELB. For the us-east-1 region, it would cost you $0.0225 per ALB + $0.008 per LCU-hour. The definition of an LCU can be found [here](https://aws.amazon.com/elasticloadbalancing/pricing/). All in all, pricing is roughly equivalent to ELB.\n\nALBs are typically used for web applications. If you have a microservices architecture, ALB can be used as an internal load balancer in front of EC2 instances or Docker containers that implement a given service. You can also use them in front of an application implementing a REST API, although [AWS API Gateway](https://aws.amazon.com/api-gateway/) would generally be a better choice here.\n\n## Network Load Balancer\n\nNLB works on the layer 4 of the [OSI model](OSI%20model) only and can handle both TCP and UDP, as well as TCP connections encrypted with TLS. Its main feature is that it has a very high performance. Also, it uses static IP addresses and can be assigned Elastic IPs—not possible with ALB and ELB.\n\nNLB natively preserves the source IP address in TCP/UDP packets; in contrast, ALB and ELB can be configured to add additional HTTP headers with forwarding information, and those have to be parsed properly by your application.\n\nNLB pricing for the us-east-1 region is $0.0225 per NLB-hour + $0.006 per LCU-hour. The definition of an LCU for NLB is quite similar to that for ALB, and more information can be found [here](https://aws.amazon.com/elasticloadbalancing/pricing/). All in all, pricing is roughly equivalent to ELB and ALB.\n\nNLBs would be used for anything that ALBs don’t cover. A typical use case would be a near real-time data streaming service (video, stock quotes, etc.) Another typical case is that you would need to use an NLB if your application uses non-HTTP protocols.\n\n## Sticky Session\n\nA method to bind a user's session to a specific EC2 session.\ncan only be applied to CLB or ALBs\n\nIt ensures that all requests from that session are sent to the same instance. It is Typically utilized with a Classic Load Balancer\n\n## X-Forwarded-For (XFF) Header\n\nIf you need the IPv4 address of a user, check this header.\n\nThis header is a common method for identifying the originating IP addresses of clients connecting to a web server through an HTTP proxy or a load balancer.\n\n![Pasted image 20220723214311](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220723214311.png)\n\n## ELB - Health Checks\n\n![Pasted image 20220723214425](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220723214425.png)\n\n\n## Cross-Zone Load Balancing\n![Pasted image 20220723214447](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220723214447.png)\n\n\n## ALB - Request Routing\n\nApply riles to incomming request and then forward or redirect traffic\n\n- Host header\n- HTTP header\n- Source IP\n- HTTP header method\n- Path\n- Query string\n![Pasted image 20220723214622](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220723214622.png)\n\n\n\n![Pasted image 20220723214636](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220723214636.png)","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Compute-/Lambda":{"title":"Lambda","content":"# Lambda\n#aws #cloud #serverless #compute #development \n\n\nRun code without provisioning or managing servers in [AWS](-=%20AWS%20=-/AWS.md).\n\nLambda executes your code only when needed and scales automatically to a few to a 1000 lambda functions concurrently in seconds.\n\nPay only for the times the lambda function is invoked.\n\nLambda is **Cheap**, **Serverless**, and **Scales Automatically**.\n\n7 runtime languages are supported:\n\n1. Ruby\n2. Python\n3. Java\n4. Go\n5. Powershell\n6. Nodejs\n7. C#\n\n\n## Use Cases:\nLambda is used to glue different services together so the use cases are endless.\nExample of use cases are:\n1. Processing Thumbnails\n![Pasted image 20220724095845](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220724095845.png)\n2. Contact Email Form\n![Pasted image 20220724095857](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220724095857.png)\n\n\n## Triggers\nTO invoke a lambda it can be accomplished via the AWS SDK or from other AWS Services.\n\nIt can also be configured with 3rd party partner sources.\n\n\n## Pricing\nThe 1st million requests per month are free.\nThere-after $0.20 per additional 1 million requests\n\n400,000 GB seconds free per month\nThereafter $0.0000166667 for every GB second\n\neg. 128MB RAM X 30Mins pm X 200ms runtime per invokation = $5.83\n\n\n## Defaults and limits\nCan only have 1000 Lambda running concurrently, Ask AWS support for Limit Increase.\n\n/tmp directory can contain upto 500MB\n\nBy default Lambda run in No VPC. You can set them to by in your own VPC but your lambda will lose internet access.\n\nYou can set timeout to be a mazimu of 15 minutes.\n\nMemory can be set between 128MB to a mazimum of 2008MB at an increment of 64MB.\n\n\n## Cold Starts\nA negative trade-off on using server-less functions. At first when the lambda function has not been triggered and is on an turned off state, It will require some time to start the server. \n\nThis can cause delays in the User Experience.\n\nCan be addressed through Pre Warning.\n\n![Pasted image 20220724100910](-=%20AWS%20=-/--%20Compute%20--/Pasted%20image%2020220724100910.png)","lastmodified":"2023-03-02T18:25:17.215874044Z","tags":null},"/-AWS-/-Compute-/Windows-Docker-on-AWS":{"title":"Windows Docker on AWS","content":"# Windows Container Docker on AWS\n#docker #windows #aws \n\n\nTo run windows containers in docker within [AWS](-=%20AWS%20=-/AWS.md), launch an [Elastic Compute Cloud EC2](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Compute%20Cloud%20EC2.md)with an Windows_Server-2022-English-Core-ContainersLatest-2022.11.10\n![Pasted image 20230105145020.png](Pasted%20image%2020230105145020.png)\n\nMake sure to give it plenty of cpu and ram resources so it can peform well.\n\nThis will launch an Windows ec2 instance with docker container support.\n\n\nThe dotnet framework docker versions:\nhttps://hub.docker.com/_/microsoft-dotnet-framework-runtime/\n\n\nBlog  on configuring dotnet build with codebuild and docker:\nhttps://aws.amazon.com/blogs/devops/extending-aws-codebuild-with-custom-build-environments-for-the-net-framework/\n\n\nArticle found with demo of how to use docker CLI in Windows docker setup:\nhttps://web.archive.org/web/20220120042518/https://www.docker.com/blog/build-your-first-docker-windows-server-container/\n\nOneliner google chrome silent installer powershell:\nhttps://www.snel.com/support/install-chrome-in-windows-server/\n\n\nCommand to switch from windows container \u003c\u003e linux containers: \n(This method Didin't work for the mirantis)\nhttps://forums.docker.com/t/cli-to-switch-between-linux-and-windows-images/30297\n\nExtensive article on using docker within WSL (useful for linux containers):\nhttps://dev.to/_nicolas_louis_/how-to-run-docker-on-windows-without-docker-desktop-hik\n\n\n## Docker containers for windows on aws codepipeline\nhttps://aws.amazon.com/blogs/devops/building-windows-containers-with-aws-codepipeline-and-custom-actions/#:~:text=AWS%20CodeBuild%20supports%20Windows%20builds,NET%20Framework%20SDK%20installed).\n\n### Limitations: (????)\n-   AWS CodeBuild executes Windows Server containers using Windows Server 2016 hosts, which means that build containers are huge—it is not uncommon to have an image size of 15 GB or more (with .NET Framework SDK installed). Windows Server 2019 containers, which are almost half as small, cannot be used due to host-container mismatch. (???)\n\n-   AWS CodeBuild runs build jobs inside Docker containers. You should [enable privileged mode](https://docs.aws.amazon.com/codebuild/latest/APIReference/API_ProjectEnvironment.html) in order to build and publish Linux Docker images as part of your build job. However, [DIND is not supported on Windows](https://github.com/docker-library/docker/issues/49) and, therefore, AWS CodeBuild cannot be used to build Windows Server container images. (???)\n\nThe last point is the critical one for microservice type of applications based on Microsoft stacks (.NET Framework, Web API, IIS). The usual workflow for this kind of applications is to build a Docker image, push it to ECR and update ECS / EKS cluster deployment.\n\n\n## Custom AWS codebuild with ephemeral windows container envs:\nhttps://github.com/aws-samples/aws-codepipeline-custom-action\n\nhttps://aws.amazon.com/blogs/devops/building-windows-containers-with-aws-codepipeline-and-custom-actions/#:~:text=AWS%20CodeBuild%20supports%20Windows%20builds,NET%20Framework%20SDK%20installed\n\n## ALT:\nhttps://aws.amazon.com/blogs/modernizing-with-aws/building-windows-containers-with-aws-codepipeline-on-aws-govcloud-us/\n\n\n\n\n## Windows containers:\n\nMore on what windows containers are:\nhttps://learn.microsoft.com/en-us/virtualization/windowscontainers/about/\n\nPreparing windows for containers:\nhttps://learn.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=containerd\n![Pasted image 20230106173933.png](Pasted%20image%2020230106173933.png)\n![Pasted image 20230106173955.png](Pasted%20image%2020230106173955.png)\nhttps://hub.docker.com/_/microsoft-dotnet-framework-runtime/\n![Pasted image 20230106182532.png](Pasted%20image%2020230106182532.png)\n\n\nwindows vs linux container service\n![Pasted image 20230106173745.png](Pasted%20image%2020230106173745.png)\n\n\nhttps://www.youtube.com/watch?v=RjwzADNGUUg\n\nhttps://drive.google.com/file/d/1KK56yO8XTgSZ7jTjstz1ZAFCM2a2co-0/view","lastmodified":"2023-03-02T18:25:17.231874188Z","tags":null},"/-AWS-/-Compute-/security-group":{"title":"security group","content":"# Security Groups\n#aws #cloud \n\n[Defence In Depth](Defence%20In%20Depth)\n[Zero-Trust](Zero-Trust)\n[Elastic Compute Cloud EC2](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Compute%20Cloud%20EC2.md)\n[RDS](-=%20AWS%20=-/--%20Databases%20--/RDS.md)\n[Elastic Load Balancer (ELB)](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Load%20Balancer%20(ELB).md)","lastmodified":"2023-03-02T18:25:17.231874188Z","tags":null},"/-AWS-/-Databases-/Aurora":{"title":"Aurora","content":"# Aurora\n#aws #cloud #rdbms #serverless #sql\n\nFully managed Postgres or MySQL database by [AWS](-=%20AWS%20=-/AWS.md).\n\nCombines the speed and availability of high end database with the simplicity and cost-effectiveness of opensource databases\n\n## Aurora Scaling\nStarts with 10GG of Storage, and scale in 10GB increments upto 64TB\n\nStorage is auto-scaling\n\nComputing resource can scale all the way upto 32 vCPUs and 244Gb of memory\n\n\n## Aurora-Availability\n\nA minimum of 3-availability zones each contain 2 copies of your database.\n\nso 6 copies are created. (2 copies in each availability zones)\n\n\n## Aurora-Fault Tolerance and Durability\nAurora Backup and Failover are handelled automatically\nSnapshots of Data can be shared with other AWS accounts\n\nStorage is self-healing, in that data blocks and disks are continiously scanned for errors and repaired automatically.\n\n## Aurora-Replicas\n\nThere are 2 types of replicas available:\n\n![Pasted image 20220724011616](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724011616.png)\n\n\n\n## Aurora-Serverless\n\nAurora except the database will automatically startup, shut-down, and scale capacity up or down based on your application's needs\n\nApps used a few times several times per day or week.. eg. low accessed databases.\n\npay for database storage and the database capacity and I/O your database consumes while it is active\n\n\n![Pasted image 20220724011843](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724011843.png)\n","lastmodified":"2023-03-02T18:25:17.231874188Z","tags":null},"/-AWS-/-Databases-/DynamoDB":{"title":"DynamoDB","content":"# DynamoDB\n#aws #cloud #databases #nosql\n\nKey value and document database (NoSQL) solution by [AWS](-=%20AWS%20=-/AWS.md) which can guarantee consistent read and write speed at any scale .\n\nNoSQL is a database which is neither relational and does not use SQL ro query the data for results.\n\n**Features:**\n- Fully managed\n- Multiregion\n- Multimaster\n- Durable database\n- Built-in Security\n- Backup and restore\n- In-memory cacheing\n\n**Provides:**\nEventual Consistent Reads (default)\nStrongly Consistent Reads\n\n\n## Table Structure\n![Pasted image 20220724013608](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724013608.png)\n\n\n\n\n## Reads:\nWhen data needs to be updated it has to write updates to all copies. It is possible for data to be inconsistent if you are reading from a copy which has yet to be updated. You have the ability to choose the read consistency in DynamoDB to meet your needs.\n\n![Pasted image 20220724013641](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724013641.png)\n\n\n\n\n![Pasted image 20220724013804](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724013804.png)","lastmodified":"2023-03-02T18:25:17.231874188Z","tags":null},"/-AWS-/-Databases-/RDS":{"title":"RDS","content":"# RDS\n\n#aws #cloud #sql #databases #rdbms\nA fully managed Relational Database Service by [AWS](-=%20AWS%20=-/AWS.md)\n\nA managed relational Database service which supports many RDMS engine which are easy to scale, maintain and update easily.\n\n## Encryption\n\nYou can turn encryption for all RDS engines\n\n\n\n\n\n## Backups\n\nThere are 2 types:\n\n### Automated Backups\nChoose a Retention Period between 1 and 35 days, stores transaction logs throughout the day and Automated backups are enabled by default. All data is stored in S3\n There is no additional charge for backup storage\n Yo can define your backup window\n\n### Manual Backup\nManual backups\n\n\n## Restoring Backups\n\nWhen recovering AWS it will restore it via the most recently taken snapshot.\n\nIt never restores ontop of running instance.\n\nYou will need to create a new RDS to retore on top of it\n\n\n### Multi AZ\n- Slave Database\n- Makes an exact \n- Synchronous replication (highly durable)\n- Used for Durability\n- Only the database on the primary instance is active\n- Backups are taken automatically\n- Always Span across two AZ\n- DB engine version upgrade happens on primary\n- Automatic fail-over to standby instance when a problem is detected on the primary instance\n\n## Read Replica\n\n- Only allows read\n- Asynchronous replication\n- Used to improve performance\n- All of the replicas are active\n- No backups are configured by default\n- Can be within a AZ, Cross-AZ or even Cross-Region\n- DB engine version upgrade is independent from source instance.\n- Should be manually promoted to a standalone dataabase instance\n\n\n\n## Performance Insights\nGives you a rich performance insights of your database.\n\n\n## Aurora Server-less\nA fully managed Serverless solution provided by aws for RDBMS. \n\n\n\n![Pasted image 20220724010918](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724010918.png)\n\n![Pasted image 20220724011034](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724011034.png)\n\n","lastmodified":"2023-03-02T18:25:17.251874368Z","tags":null},"/-AWS-/-Databases-/Redshift":{"title":"Redshift","content":"# Redshift\n#aws #cloud #storage #datawarehousing \n\nIt is a fully managed Petabase-sized solution for data ware housing by [AWS](-=%20AWS%20=-/AWS.md).\nRedshift is singe AZ\nSnapshots can be resored at a different AZ\n\n\n\nPricing starts at $0.25 per hour with no upfront costs or commitments.\n\nScale up to petabytes for $1000 \n\nDataware house \n\n![Pasted image 20220724012000](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724012000.png)\n\n\n![Pasted image 20220724012758](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724012758.png)\n\n![Pasted image 20220724013125](-=%20AWS%20=-/--%20Databases%20--/Pasted%20image%2020220724013125.png)","lastmodified":"2023-03-02T18:25:17.251874368Z","tags":null},"/-AWS-/-Migration-Transfer-/Snowball":{"title":"Snowball","content":"# Snowball\n#aws #cloud #snowball #storage #cloud-migration\n\n\nLow Cost data transfer service by [AWS](-=%20AWS%20=-/AWS.md) (Petabyte Scale). Snowball can reduce the cost by 1/5th\n\nFeatures:\n- E-ink display (shipping information)\n- Tamper and weather proof\n- Data is encrypted end-to-end using 256 bit encryption\n- users Trusted Platform Module (TPM)\n- For security purposes, data transfers must be completed within 90 days of snowball being created\n- Snowball can Import/Export from [S3](-=%20AWS%20=-/--%20Storage%20--/S3.md)\n- Comes in 2 sizes \n\t- (50 TB) \n\t- (80 TB)\n\n# Snowball Edge\nsimilar to Snowball but more storage and local processing\n\nFeatures:\n- LCD Display\n- Can undertake local processing and edge-computing workloads\n- Can use in a groups of 5 to 10 devices.\n- Three options for device configurations:\n\t- Storage Optimised (24 vCPUs)\n\t- Compute Optimised (54 vCPUs)\n\t- GPU Optimised (54 vCPUs)\n- Comes in 2 Sizes:\n\t- 100TB (83 usable)\n\t- 100TB Clustered (45 TB per node)\n\n\n# Snow Mobile#\nMade for Exabyte size data migration\n\nA 45-foot long ruggedized shipping container, pulled by a semi-trailer truck. transfer up to 100PB per Snowmobile.\n\nAWS personnel will help you connect your network to the snowmobile and when data transfer is complete they'll drive it back to AWS to import into [S3](-=%20AWS%20=-/--%20Storage%20--/S3.md) or Glacier\n\n*Security Features*\n- GPS Tracking\n- Alarm monitoring\n- 24/7 video surveillance\n- an escort security vehicle while in transit (optional)\n\n\n![Pasted image 20220714014138](-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220714014138.png)","lastmodified":"2023-03-02T18:25:17.251874368Z","tags":null},"/-AWS-/-Migration-Transfer-/Storage-Gateway":{"title":"Storage Gateway","content":"# Storage Gateway\n#aws #cloud #storage #networking\n\nA networking service by [AWS](-=%20AWS%20=-/AWS.md) which provides a seamless and secure integration between your organization's on-premise IT environment and AWS's storage infrastructure.\n\n\n## File Gateway (NFS) (store your files in S3)\n\nTo extend your local storage to S3\n\n\n\n## Volume Gateway (iSCSI) (stores copies of your HDD in S3)\n\nPresents your application with Internet Small Computer Systems Interface block protocol.\n\nData that is written to volumes can be asyncronously backed up as point-in-time snapshots of the volumes, and stored in the cloud as AWS EBS Snapshots.\n\nSnapshots are incremental backups\n\nTreats your local HDD as EBS.\n\nPrimary data is stored locally, while asyncronously backing up that data to AWS\n\n\n- Stored Volumes (primary data is on onsite) (1GB - 16TB)\n- Cached Volumes (primary data is in aws) (1GB - 32GB)\n\n## Tape Gateway (VTL) (virtual tape library)\n\nA durable, cost-effective solution to archive your data in the AWS Cloud\n\nThe VTL interface it provides let you leverage existing tape based backup application infrastructure.\n\nStore data on virtual tape cartridges that you create on your \n\n![Pasted image 20220724155600](-=%20AWS%20=-/--%20Migration%20\u0026%20Transfer%20--/Pasted%20image%2020220724155600.png)","lastmodified":"2023-03-02T18:25:17.251874368Z","tags":null},"/-AWS-/-Monitoring-/CloudTrail":{"title":"CloudTrail","content":"# CloudTrail\n#aws #cloud #auditing #logs #monitoring \n\nLogs API calls between [AWS](-=%20AWS%20=-/AWS.md) services. when you need to know who to blame.\n\nenables governance, complience, operational auditing and risk auditing of aws account.\n\n\nused to monitor API calls and actions made by a user.\n\nEhere Source IP address\nWhen EventTile\nWho User, UserAgent\nWhat Region, Resource, Action\n\n\nCloudTrail is already logging by default and will collect logs for last 90 days via Event History.\n\nIf you need more than 90 days you need to create a Trail\n\nTrails are output to S3 and do not have GUI like Event History. You can use Amazon Athena to analyze these Event Histories. \n\n\n- A Trail can be set to log all regions\n\n- A Trail can be set to across all accounts in an Organization\n\n- You can Encrypt your Logs using Server Side Encryption via (SSE-KMS)\n\n- We can ensure the Integrity of our logs to see if they have been tampered we need to turn on Log File Validation.\n\n## CloudTrail to CloudWatch\n\nCloudTrail can be set to deliver events to a CloudWatch Logs.\n\n\n## Management vs Data Events\n\n![Pasted image 20220724020553](-=%20AWS%20=-/--%20Monitoring%20--/Pasted%20image%2020220724020553.png)\n\n\n- [ ] ![Pasted image 20220724020844](-=%20AWS%20=-/--%20Monitoring%20--/Pasted%20image%2020220724020844.png)","lastmodified":"2023-03-02T18:25:17.251874368Z","tags":null},"/-AWS-/-Monitoring-/CloudWatch":{"title":"CloudWatch","content":"# Cloudwatch\n#aws #cloud  #monitoring #logs \n\nmonitoring solution for all of the various AWS resources by [AWS](-=%20AWS%20=-/AWS.md).\n\n![Pasted image 20220724014551](-=%20AWS%20=-/--%20Monitoring%20--/Pasted%20image%2020220724014551.png)\n\n\n## Cloudwatch-Logs\n, store, and access your log files.\n\n\nA Log Group is a collection of logs. Log files must belong to a log group.\n\nA log in Log Group is called a Log Stream\n\nBy default, logs are kept indefinitely and never expire\n\nMostAWS services are integrated with CloudWatch Logs.\nLogging of services sometimes need to be turned on or requires the IAM Permissions to write to CloudWatch Logs.\n\n## CloudWatch-Metrics\nRepresents a tie-ordered set of data points.\n\nCloudWatch comes with many predefined metrics eg.\n\nEC2 Per-Instance Metrics\nsuch as CPU Utilization/ DiskReadOps, NetworkIn\n\n### Custom Metrics\nUsing AWS CLI or SDK we can create and publish custom metrics. (Like Memory Utilization, Disk Usage which usually requires a cloudwatch agent).\n\nHigh resolution metrics can be enabled instead of standard metrics. A high definition metrics lets you track a metric under 1 minute down to 1 second. \n\n\n## Cloudwatch-Events\n\nTrigger an event based on condition or on schedule.\n\n\n## Cloudwatch-Alarms\nTriggers a notification based on a metric which breach a defined threshold. \n\n\n## Cloudwatch-Dashboards\nCreate custom dashboards from CloudWatch metrics.\n\n\n## Cloudwatch-Availability\n\n\n\n![Pasted image 20220724015847](-=%20AWS%20=-/--%20Monitoring%20--/Pasted%20image%2020220724015847.png)\n","lastmodified":"2023-03-02T18:25:17.251874368Z","tags":null},"/-AWS-/-Networking-/CloudFront":{"title":"CloudFront","content":"# CloudFront\n#aws #cloud #edge #CDN\n\nA CDN service provided by [AWS](-=%20AWS%20=-/AWS.md).\n\nA CDN is a distributed network of servers which delivers web pages and contents to users based on their geographical location, the origin of the webpage.\n\n## Core Components\n\n### Origin\n\nThe location where the original files are located. eg an S3 Bucket, EC2, \n\n\n### Edge location\n\nThe location where the the web content will be cached.\n\n\n## CloudFront Distributions\n\nA Distribution is a collection of Edge locations. You can set the origin eg. EC2, S3, ELB, Route53.\n\nIt replicates copies based on your Price class\n\nThere are 2 types of Distributions\n1. Web (For websites)\n2. RTMP (For streaming media)\n\n\n#### Settings:\nBehaveour\n\n\n\n\n## Cloudfront-Lambda@Edge\n\nWe use these functions to overrice the behaviour of request and responces\n![Pasted image 20220723225149](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220723225149.png)\n\n A common use case will be using it to authenticate users before they can access secured web content which needs to be authorised via cognito or similar case\n\n## CloudFront-Protection\n\nBy default a Distribution allows everyone to have access\n\n### Original Identity Access (OAI)\nA virtual user identity that will be users to give your CloudFront Distribution permission to fetch a private object\n\nIn order to use Signed URLs or Signed Cookies you need to have an OAI\n\n#### Signed URLs \n\n\n\n![Pasted image 20220723230258](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220723230258.png)","lastmodified":"2023-03-02T18:25:17.259874439Z","tags":null},"/-AWS-/-Networking-/Route53":{"title":"Route53","content":"# Route53\n#aws #cloud #dns #networking \n\nA DNS solution by [AWS](-=%20AWS%20=-/AWS.md).\nRoute53 is a [DNS](DNS) similar to Godaddy or Namecheap.\n\nUse cases:\n\ncan be used to get your custom domains to your AWS Resources\n\n\n![Pasted image 20220719161710](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220719161710.png)\n\n## Record Sets:\n\nWe create the customs domains using Record sets.\n\n## Alias Record\nAWS has its own special alias Record which extends DNS Functionality. It will route AWS resources easily.\n\n## Routing Policies\nThere are 7 different types of Routing policies:\n![Pasted image 20220720094427](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720094427.png)\n\n\n### 1. Simple Routing Policy\nIts the most basic routing policy in Route53\nIt is also the default Routing policy\n1 record and provide multiple IP addresses.\nWhen multiple values are specified the Route53 will return all\n\nThis is the default routing policy. Use this only when you have exactly one resource such as one EC2 web server. This policy can contain multiple values but it returns one resource. This policy is not recommend for production sites.\n\n![Pasted image 20220720094522](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720094522.png)\n\n\n### 2. Weighted\nThis routing policy lets you split up traffic based on different 'weights' assigned to the routes allowing user to send a certain percentage of overall traffic apart from that directed to a different server.\nIt’s based on a numer2ical value ranging from 0 to 255. If you specify a value of 0 for all regions then it’s routed equally.\n\n![Pasted image 20220720101226](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720101226.png)\n![Pasted image 20220720101237](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720101237.png)\n\n### 3. Latency\nWhen you have multiple resources in multiple regions, this policy routes the user not to the closest resource necessarily but the resource who responds the fastest or lowest latency.\n![Pasted image 20220720101348](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720101348.png)\n\n![Pasted image 20220720101321](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720101321.png)\n\n### 4. Failover\nAllows creating two records for the same name. This starts like simple policy but with a health check. If that single web server is unhealthy then you can point elsewhere. That next pointer can be another web server or possibly an error.html page hosted in AWS S3.\n![Pasted image 20220720101408](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720101408.png)\n![Pasted image 20220720101903](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720101903.png)\n\n\n### 5. Geolocation\nUse this when you want to serve your site based on the location of the client or user. ie. different servers for different users from regions. Like how all users from North American subcontinent to servers in one american servers and traffic from Asia to one of the servers in Asia.\n![Pasted image 20220720101949](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720101949.png)\n![Pasted image 20220720094744](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720094744.png)\n\n### 6. Geoproximity\nGeoproximity routing lets Amazon Route 53 route traffic to your resources based on the geographic location of your users and your resources. You can also optionally choose to route more traffic or less to a given resource by specifying a value, known as a _bias_. A bias expands or shrinks the size of the geographic region from which traffic is routed to a resource.\n\nThe effect of changing the bias for your resources depends on a number of factors, including the following:\n\n-   The number of resources that you have.\n    \n-   How close the resources are to one another.\n    \n-   The number of users that you have near the border area between geographic regions. For example, suppose you have resources in the AWS Regions US East (Northern Virginia) and US West (Oregon) and you have a lot of users in Dallas, Austin, and San Antonio, Texas, USA. Those cities are roughly equidistant between your resources, so a small change in bias could result in a large swing in traffic from resources in one AWS Region to the other.\n\n![Pasted image 20220720094814](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720094814.png)\n\n![Pasted image 20220720094827](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720094827.png)\n![Pasted image 20220720094850](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720094850.png)\n\n### 7. Multivalue\nThis one lets your return multiple values for each of your resources. The client or user browser randomly chooses one. Optionally you can add health checks. If any value becomes unhealthy then the client chooses another value to resolve. This is not an alternative solution to load balancing, it’s an enhancement. This is similar to the [#1 Simple Routing Policy](#1%20Simple%20Routing%20Policy) routing except .\n\n![Pasted image 20220720102628](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220720102628.png)\n\n## Health Checks\n\nChecks health every 30s by default. Can be reduced to every 10s.\nA health check can initiate a failover if the status is returned to unhealthy.\nA CloudWatch Alarm can be created to alert you about the health of the route.\nHealth check can monitor other health checks to create a chain of reactions.\nCan create up to 50 health checks for AWS endpoints that are within or linked to the same AWS Account.\n\n\n## Traffic Flow:\nA visual editor which lets you create routing configurations for your resources using existing routing types.\n","lastmodified":"2023-03-02T18:25:17.295874763Z","tags":null},"/-AWS-/-Networking-/VPC":{"title":"VPC","content":"# VPC (Virtual Private Cloud)\n#aws #cloud #vpc #networking\n\n\nAmazon Virtual Private Cloud (VPC) is a commercial cloud computing service that provides users a virtual private cloud, by “provisioning a logically isolated section of [AWS](-=%20AWS%20=-/AWS.md) Cloud”.\n\n[VPC FAQ](https://aws.amazon.com/vpc/faqs/)\n\nA \n\nA VPC is like a digital data centre.\nAll VPC traffic can be logged via Flowlogs.\nIn an Amazon VPC, an EC2 instance retains it’s private IP address when the instance is stopped.\nA VPC consists of following components:\n\n![Pasted image 20220714145840](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220714145840.png)\n\n\n\n\nKey Features and Limitations:\n\n- VPCs are Region Specific and they do not span across regions\n- You can create 5 VPCs per region\n- Every region comes with a default VPC\n- You can have 200 subnets per VPC\n- You can use IPv4 CIDR Blocks and in addition to a IPv6 CIDR blocks\n- It costs nothing\n- Some things like NAT Gateway, VPC Endpoints, VPN Gateway and Customer Gateway are not free\n- DNS host names are disabled by default.\n\n\n## VPC Peering\n\nVPC peering can be used when a VPC needs to communicate with another VPC over a direct network route using private IP addresses.\n\nVPC Peering is supported across multiple accounts.\nVPC peering allows direct network connection via a private ip address. Instances behave as if they were on the same private network.\nPeering uses a star Configuration if you were to connect multiple different VPC i.e. a VPC will need to be in the middle of every other VPCs. (No Transitive peering)\nThe following peering configurations are invalid:\n\n-   Overlapping CIDR blocks\n-   Transitive peering\n-   Edge to edge routing through a gateway or private connection\n\n[More info on invalid peering configurations](https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html)\n\nVPC peering is only supported in a star configuration.\n\nTransitive peering / edge-to-edge routing is not supported. i.e. if you have VPC A \u003c-\u003e VPC B \u003c-\u003e VPC C, VPC A can communicate with VPC B, and VPC B with C, but A cannot directly communicate with C unless a direct connection is made between A and C.\n\n[More info on VPC peering](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html)\n\n**You must update both sides of the route tables for VPC peering to work**\n\n\n## Route Tables\nRoute tables are used to determine where the network traffic is directed. Each subnet in VPC must be associated with a route table. \nA subnet can only be associated with one route table at a time.\nA route table can be used to associate multiple subnets.\nEach record in the route table is called a route.\n\nIn VPCs, even though we have these different subnets, we need to allow traffic to flow through them. We do this with Route Tables. **A Route Table is just a list of CIDR blocks (IP ranges) that our traffic can leave and come from.** By default, newly created Route Tables will have the CIDR of our VPC defined. This means that traffic from anywhere within our VPC is allowed.\n\nIn addition to a list of IP ranges that our Route Table connect traffic between, it also has **Subnet Associations**. Simply put, these are \"which subnets use this route table.\"\n\n## Direct Connect \n\n\n## Internet Gateway\n\nCreating a VPC also creates a route table, but doesn’t create a subnet or internet gateway by default.\n\nFor a VPC route table point to an internet gateway, you must first attach the internet gateway to the VPC.\n\n**You can attach only one internet gateway to a VPC at a time**; if youre getting an error when trying to attach an Internet Gateway to a VPC, it could be that an Internet Gateway is already attached to the VPC.\n\nBefore deleting an IGW, you must first detach it from the VPC it’s attached to.\n\n[More info on VPC Internet Gateways](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html)\n\n\n## Direct Connect\n\nA solution for establishing dedicated network connections from on-premises locations to AWS.\n\nVery fast network with Lower bandwidth of 50M-500M or Higher Bandwidth 1GB or 10GB.\n\nHelps reduce network costs and increase bandwidth throughput\nProvides a more consistent network experience than internet based connections. (reliable and secure)\n\n## VPC Endpoints\n\nVPC endpoints allow you to privately connect your VPC to other AWS services, and VPC endpoint services.\n\nEliminates the need for [#Internet Gateway](#Internet%20Gateway), NAT device, VPN connection or even AWS Direct Connect connections.\n\nInstances in the VPC do not require public IP address to communicate with service resources.\n\nTraffic between your VPC and other services does not leave the AWS network.\n\nHorizontally scaled, redundant, and highly available.\n\nAllows secure communication between instances and services without adding availability risks or bandwidth constraints on your traffic.\n\n![Pasted image 20220715002212](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715002212.png)\n### Interface endpoints\n\n![Pasted image 20220715002052](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715002052.png)\n\n\n### Gateway Endpoint\n\nA gateway endpoint is a target for specific route in your route table. \nOnly support [DynamoDB](-=%20AWS%20=-/--%20Databases%20--/DynamoDB.md) and [S3](-=%20AWS%20=-/--%20Storage%20--/S3.md)\n\nGateway endpoints are free\n\n\n\n## VPC Flow Logs\n\ncaptures IP traffic information flow of Network Interfaces withhin VPC.\ncan be created for:\n\t- VPC\n\t- Subnets\n\t- Network Interface\n\nAll data is stored in Amazon Cloudwatch logs\nCan be viewed in detail in Cloudwatch logs,\nCannot do much than delete it.\nCannot be tagged like other resources\ncan be delivered to S3 or cloudwatch logs\nsome instance traffic can not be monitored\n\n![Pasted image 20220715002555](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715002555.png)\n\n![Pasted image 20220715002614](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715002614.png)\n\n## VPC Virtual Private Gateway\n\nAn Amazon VPC VPN connection links your data-center (or network) to your Amazon VPC virtual private cloud (VPC). A customer gateway is the anchor on your side of that connection. It can be a physical or software appliance. The anchor on the AWS side of the VPN connection is called a virtual private gateway.\n\n[More info](https://docs.aws.amazon.com/vpc/latest/adminguide/Introduction.html)\n\n\n\n### CIDR - Classless Inter-domain Routing\n\n**The first four IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance.**\n\ni.e.\n\n-   10.0.0.0: Network address.\n-   10.0.0.1: Reserved by AWS for the VPC router.\n-   10.0.0.2: Reserved by AWS for DNS.\n-   10.0.0.3: Reserved by AWS for future use.\n-   10.0.0.255: Network broadcast address. We do not support broadcast in a VPC, therefore we reserve this address.\n\nNetwork masks:\n\n-   /16 - supports up to 65,536 IP addresses. Best for large networks.\n-   /24 - supports up to 256 IP addresses. Best for smaller networks.\n-   /27 - supports up to 32 IP addresses\n-   /28 - supports up to 16 IP addresses\n-   /32 - an absolute ip address - matches exactly one\n\nIt’s possible to split a CIDR block into two subnets:\n\n-   one subnet can use CIDR block 10.0.0.0/25 (for addresses 10.0.0.0 - 10.0.0.127)\n-   and then the other subnet can use the CIDR block 10.0.0.128/ 25 (for addresses 10.0.0.128 - 10.0.0.255)\n\nThe allowed CIDR block size in a VPC is between a /16 and /28 netmask.\n\nTo enable ping, you need to allow ICMP traffic.\n\nIn order to ensure providioned EC2 instances have a public IP address, enable “Auto-Assign Public IP” for the subnet.\n\n0.0.0.0/0 is also known as default \nIt represents all possible IP addresses\n\n\n## Network Access Control List (NACL)\n\nNACLs acts as a virtual firewall at a subnet level.\n\nVPCs automatically get a default NACL\nSubnets are associated with NACLs. Subnets can only belong to single NACL.\nEach NACL contains a set of rules that can allow or deny traffic in and out of the subnet. \nStateless\nA default NACL denies all traffic \n\n![Pasted image 20220715002905](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715002905.png)\n![Pasted image 20220715002945](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715002945.png)\n\n\n## Security Groups\nA virtual firewall at an instance level.\nSecurity groups are associated with EC2 instances.\nEach security Group contains a set of rules that filter traffic coming into in or out of Ec2 instances. \nMultiple Instances across multiple subnets can belong to a Security Group.\n\nThere are no deny rules. All inbound traffic are denied as default unless there is a rule specifically allows it. All outbound traffic is allowed by default.\n\nthese are stateful\nchanges take effect immediately.\n\n![Pasted image 20220715003259](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715003259.png)\n\n\n#### Limits\n\ncan have upto 10,000 SGs in a single region. (Default is 2,500)\ncan have 60 inbound and 60 outbound rules per SG\n16 SG per ENI (default is 5)\n\n![Pasted image 20220715003440](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715003440.png)\n\n\n## Network address translation (NAT)\n\nNAT is a method of remapping one IP address space to another.\nIn a private network NAT can help gain outbound access to the internet by using a NAT gateway which will remap the Private IPs.\n\nIf there are two networks which have conflicting network addresses, NAT can be used to make the addresses more agreeable\n\n### NAT Instances vs NAT Gateways\n![Pasted image 20220715003856](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715003856.png)\n\n\n![Pasted image 20220715004501](-=%20AWS%20=-/--%20Networking%20--/Pasted%20image%2020220715004501.png)\n\n","lastmodified":"2023-03-02T18:25:17.295874763Z","tags":null},"/-AWS-/-Organizations-/AWS-Control-Tower":{"title":"AWS Control Tower","content":"# Control Tower\n#aws #cloud \n\nIs an extention to aws organization, that lets you create a landing zone (a well-architected multi-account baseline)\n","lastmodified":"2023-03-02T18:25:17.295874763Z","tags":null},"/-AWS-/-Organizations-/SCP":{"title":"SCP","content":"# Service Control Policies\n#aws #cloud \n\nService control policies (SCPs) are **a type of organization policy that you can use to manage permissions in your organization**. SCPs offer central control over the maximum available permissions for all accounts in your organization.\n\n![Pasted image 20230225014157.png](Pasted%20image%2020230225014157.png)\nExplicit deny overrides any allows later levels\n![Pasted image 20230225014220.png](Pasted%20image%2020230225014220.png)\n\n\n\n**Topics**\n-   [Testing effects of SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-warning-testing-effect)\n-   [Maximum size of SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-size-limit)\n-   [Inheritance of SCPs in the OU hierarchy](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-about-inheritance)\n-   [SCP effects on permissions](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-effects-on-permissions)\n-   [Using access data to improve SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#data-from-iam)\n-   [Tasks and entities not restricted by SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#not-restricted-by-scp)\n-   [Creating, updating, and deleting service control policies](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_create.html)\n-   [Attaching and detaching service control policies](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_attach.html)\n-   [Strategies for using SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_strategies.html)\n-   [SCP syntax](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_syntax.html)\n-   [Example service control policies](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples.html)","lastmodified":"2023-03-02T18:25:17.295874763Z","tags":null},"/-AWS-/-Security-Identity-/Cognito":{"title":"Cognito","content":"# Amazon Cognito\n#aws #cloud #security \n\nDecentralised way of managing [Authentication](Authentication) by [AWS](-=%20AWS%20=-/AWS.md).\n\n\n## Web Identity Federation and IpD\n\n### Web Identity Federation\nTo exchange identity and security information between an [#Identity Provider IdP](#Identity%20Provider%20IdP) and application.\n\n### Identity Provider (IdP)\na trusted provider of your user identity that lets you use authenticate to access other services. Identity Providers could be: Google, Facebook, GitHub, etc\n\ntypes:\n\t1. Security Assertion Markup Language (SAML)\n\t2. OpenID Connect (OIDC) OAuth (Used by Google, Facebook, Github, etc)\n\n## Cognito User Pools\nUser directory with authentication to [#Identity Provider IdP](#Identity%20Provider%20IdP) to grant access to your app to manage actions for web and mobile apps such as:\n\t1. Sign-up\n\t2. Sign-in\n\t3. Account recovery\n\t4. Account Confirmation\n\nAllows users to sign in directly to the user pool or using Web Identity Federation.\n\nUses AWS Cognito as the identity broker between AWS and the identity provider.\n\nSuccessfully authentication generates a JSON Web Token (JWTs).\n\nUser Pools can be thought of as the account used to access the system (ie. email address and password)\n\n*  Choose password requirements\n* Apply MFA\n* Restrict whether users are allows to signup on their own or need admin verification.\n* Analytics with Pinpoint for user campaigns.\n* Trigger custom log via Lambdas after actions such as signup\n\n\n\n## Cognito Identity Pools\n\n**Identity Pools** provide temporary AWS credentials to access services eg. S3 DynamoDB. Identity Pools can be thought of as the actual mechanism authorising access to the AWS resources.\n\n\n## Cognito Sync\n\nSync user data and preferences across devices with one line of code.\n\nCognito uses push synchronisation  to push updates and synchronise data. Uses [SNS](-=%20AWS%20=-/--%20Application%20Integration%20--/SNS.md) to send notifications to all user devices when data in the cloud changes.\n\n![Pasted image 20220719153956](-=%20AWS%20=-/--%20Security%20\u0026%20Identity%20--/Pasted%20image%2020220719153956.png)\n\n","lastmodified":"2023-03-02T18:25:17.295874763Z","tags":null},"/-AWS-/-Security-Identity-/IAM":{"title":"IAM","content":"# IAM\n#aws #cloud #security #rbac\n\nIdentity based management solution by [AWS](-=%20AWS%20=-/AWS.md)\n\nIAM allows management of access of users and resources\n\n\n**IAM Users** - End users who access AWS resources via the console or the API\n\n**IAM Groups** - Group of users with shared permission levels which will be common for all of the users.\n\n**IAM Roles** - Associate permissions to a Role and then assign this to an **IAM Users** or **IAM Groups**.\n\n**IAM Policies** - JSON documents granting permissions for a specific user, group, or role to access the services. Policies are attached to **IAM Identities**.\n\n![Pasted image 20220715093815](-=%20AWS%20=-/--%20Security%20\u0026%20Identity%20--/Pasted%20image%2020220715093815.png)\n\n\n## IAM Policies\n![Pasted image 20220715094058](-=%20AWS%20=-/--%20Security%20\u0026%20Identity%20--/Pasted%20image%2020220715094058.png)\n\n## Managed vs Customer vs Inline policies\n\n### Managed Policies \ndefault policies defined and given by AWS which is designed to support common use cases.\nthese cannot be edited.\nTHese are indicated by an orange box.\n\n### Customer Managed Policies\nCustom policies created by users which is editable.\n\n### Inline Policies\nA policy which is directly attached to a user or a resource.\n\n\n\n\n## IAM - Password Policy\n\nIn IAM you can set a Password Policy to set the minimum requirements of a password and rotate passwords so users have to update their password after X days\n\n\n## IAM - Access Keys\n\nAccess keys allow user to interact with AWS services programmatically via the AWS CLI or the SDK\n\nPer user can have 2 access keys.\n\n## IAM - MFA\n\nCan be turned on per user\nThe user has to turn on MFA themselves.\nAdministrator cannot enforce users to have MFA\n\nThe Administrator cannot create a policy requiring MFA to access certain resources.\n\n![Pasted image 20220719151854](-=%20AWS%20=-/--%20Security%20\u0026%20Identity%20--/Pasted%20image%2020220719151854.png)","lastmodified":"2023-03-02T18:25:17.295874763Z","tags":null},"/-AWS-/-Security-Identity-/KMS":{"title":"KMS","content":"# KMS\n#cloud #aws #security \n\n[AWS](-=%20AWS%20=-/AWS.md) Key Management Service (AWS KMS) lets you create, manage, and control cryptographic keys across your applications and more than 100 AWS services. These keys could be used for [== Cyber Security ==/Encryption](==%20Cyber%20Security%20==/Encryption) as well as a form of [Authorization](Authorization) of the users/services. \n\n\n\n![Pasted image 20230103145238.png](Pasted%20image%2020230103145238.png)","lastmodified":"2023-03-02T18:25:17.295874763Z","tags":null},"/-AWS-/-Security-Identity-/WAF":{"title":"WAF","content":"# WAF\n\n#aws #cloud \n\nAWS WAF is a web application firewall [== Cyber Security ==/Cloud Security/WAF](==%20Cyber%20Security%20==/Cloud%20Security/WAF) that helps protect apps and APIs against bots and exploits that consume resources, skew metrics, or cause downtime.","lastmodified":"2023-03-02T18:25:17.303874835Z","tags":null},"/-AWS-/-Storage-/EBS":{"title":"EBS","content":"# EBS\n#cloud #aws #storage\n\nA device access block storage solution by [AWS](-=%20AWS%20=-/AWS.md). \n\nHighly available and durable solution for attaching persistent block storage volumes to an [Elastic Compute Cloud EC2](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Compute%20Cloud%20EC2.md) instance. Volumes are automatically replicated within their Availability Zone (AZ) to protect from component failure.\n![Pasted image 20220723215556](-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220723215556.png)\n![Pasted image 20220723215541](-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220723215541.png)\n\n## Moving Volumes\n\n### From one AZ to another\n1. Take a snapshot\n2. create an AMI from the snapshot \n3. launch an EC2 instance\n\n\n### From one Region to another\n1. Take a snapshot\n2. create an AMI from the snapshot \n3. Copy the AMI from one region to another\n4. launch an EC2 instance\n\n## EBS - Encrypted Root Volume\nYou can enable encrypto\n![Pasted image 20220723224133](-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220723224133.png)\n\n\n\n## EBS vs Instance Store Volumes\n![Pasted image 20220723224353](-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220723224353.png)\n\n\n\n![Pasted image 20220723224449](-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220723224449.png)","lastmodified":"2023-03-02T18:25:17.303874835Z","tags":null},"/-AWS-/-Storage-/Elastic-File-Storage-EFS":{"title":"Elastic File Storage (EFS)","content":"# EFS\n#aws #cloud #storage #nfs\n\nScalable, Elastic Cloud-native NFS file System offered by [AWS](-=%20AWS%20=-/AWS.md).\n\nActs as a single drive which could be utilized by multiple [Elastic Compute Cloud EC2](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Compute%20Cloud%20EC2.md) instances.\n\nEFS is using Network File System version 4 (NFSv4) protocol\nEFS create multiple mount targets to mount to various AZs\n\nIt can expand elasticly just like an S3\n\n","lastmodified":"2023-03-02T18:25:17.303874835Z","tags":null},"/-AWS-/-Storage-/S3":{"title":"S3","content":"# S3\n#aws #s3 #storage #serverless #cloud \n\n\nObject storage solution provided by AWS.\nServerless storage in the cloud.\nDo not have to worry about the underlying infrastructure\n\nObject storage is  a a simple data storage architecture that manages data as objects, as opposed to other storage architectures which manages data as files and file hierarchy (file systems) and block storage which manages data as blocks within sectors and tracks.\n\nS3 provides unlimited storage.\n\n\n## Objects\n\nObjects contains data and acts similar to files. they contain:\n- Key (name)\n- Value (data itself)\n- Version ID (if enabled the version)\n- Metadata (additional information i.e.  file-type)\n\n## Buckets\nBucket holds [#Objects](#Objects) \nBuckets can have folders to organise Objects.\nThese should be unique universally similar to domain names. (i.e. there cannot be bucket with same name even in cross-account scenario)\n\n## Storage Classes\n\n![== Cloud Computing ==/-= AWS =-/-- Storage --/Pasted image 20220713123659.png](==%20Cloud%20Computing%20==/-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220713123659.png)\n![Pasted image 20220714012155](-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220714012155.png)\n\n### S3-Standard (Default)\n The default storage class. If you don't specify the storage class when you upload an object, Amazon S3 assigns the S3 Standard storage class.\n\n- Fast (Low latency and high throughput performance.)\n- 99.99% Availability\n- 11 9's Durability (Resilient against events that impact an entire Availability Zone.)\n- Replicated across at least 3 [](AWS#Avilability%20Zones%20AZ#Avilability%20Zones%20AZ#)\n- Backed with the Amazon S3 Service Level Agreement for availability.\n- Supports SSL for data in transit and encryption of data at rest.\n- S3 Life-cycle management for automatic migration of objects to other S3 Storage classes\n\n\n### S3-Intelligent Tiering\nUses ML/AI to analyse object usage and automate cost savings by moving objects between four access tiers when accessing patterns change. data is moved to most suitable tier, without any performance impact or added overhead.\n\n-   Automatically optimises the storage costs for data with changing access patterns.\n-   Stores objects in four access tiers, optimised for frequent, infrequent, archive, and deep archive access.\n-   Frequent and In-frequent Access tiers have the same low latency and high throughput performance as S3 Standard.\n-   Designed for durability of 99.999999999% of objects across multiple Availability zones.\n-   Designed for 99.9% availability over a given year.\n-   Backed with the Amazon S3 Service Level Agreement for availability.\n-   Small monthly monitoring and auto-tiering free.\n\n\n### S3-Standard Infrequently Accessed (IA)\n\n### S3-Onezone IA\n\n- 1 AZ only\n- Avilability is decreased to 99.5%\n### S3-Glacier\n### S3-Glacier-Deep Archive\n- Slowest storage class ()\n- \n-  Cheapest tier here\n\n\n\n## S3 Security\n- All new buckets are PRIVATE by default.\n- Logging per request can be turned on to see the access log of the users\n- Access Control is configured using Bucket Policies and Access Control Lists (ACL)\n- **ACL** are Leagacy feature of controlling access to buckets and objects\n- **Bucket Policies** are newer compared to ACL's and use JSON format policies\n\n\n### S3 Encryption at transit\nSSL/TLS is enabled at transit by default\n\n\n### S3 Encryption at rest\nthere are three types of S3 SSE and also supports Client Side Encryption\n\n\n#### Server Side Encryption (SSE) \n- **SSE-AES** S3 handles the key and uses AES-256 algorithm\n- **SSE-KMS** Envelope the encryption using two passes. Both Amazon KMS and the client manages the keys \n- **SSE-C** Similar to KMS but the customer is responsible for managing the key in the aws.\n\n\n#### Client Side Encryption (CSE)\nwe the clients are responsible for the encryption of the files being stored in the S3. i.e. the file will be encrypted locally even before being transferred to the s3\n\n\n### Data Consistency\n**Read After Write Consistency**\nWhen you upload a new object\n\n**Eventual Consistency** \nwhen you overwrite or delete an object it takes time for S3 to replicate versions to multiple AZ's.\nFetching the updated object from S3 which was just updated might result in returning the old object instead of the newer copy.\n\n## S3 Cross Region Replication\n\nWhen enabled, any object that is uploaded will be automatically replicated to another region/s. It provides higher durability and potential disaster recovery for objects.\nThis requires versioning turned on on both Source and Destination Bucket. Cross account replication is also possible.\n\n\n## S3- Versioning\nStores all version of S3 Objects\nOnce enabled it cannot be disabled, only suspended on the bucket\nFully integrates with [](-=%20AWS%20=-/--%20Storage%20--/S3.md#S3%20Life-cycle%20Management) Rules\nMFA Delete feature provides extra protection against accidental deletions\n\n\n\n## S3 Life-cycle Management\n\nAutomated the process of moving objects to different Storage Classes or deleting.\nSort of like a cronjob. \nCan be used together with versioning and can apply changes and commands to both current and previous versions.\n\n\n\n## Transfer Acceleration\n\nFast and secure transfer of files over long distances between your end users and an S3 bucket.\nUtilises CloudFront's Edge Locations\nInstead of uploading directly to the bucket it will use a distinct URL of an Edge Location to upload it there.\nWhen the data is uploaded in the Edge Location it is automatically routed to S3 over a optimised network path\n \n\n## S3 Presigned URLs\n\nGenerates a URL which provides a temporary access to the object to either upload or download object data. Presigned URLs are commonly used to provide access to private objects. You can use AWS CLI or the SDK to generate these Presigned URLs.\n\nwill be required when a web-application requires to allow users to download/upload files to a password protected part of a web-app. The web-app can generate quickly expiring URLs to give the users the brief access they need for their operation\n\n## MFA Delete\n\nEnsures users cannot delete object form S3 bucket unless they provide a valid MFA code.\nIt requires: \n\n\n\n![Pasted image 20220714013034](-=%20AWS%20=-/--%20Storage%20--/Pasted%20image%2020220714013034.png)","lastmodified":"2023-03-02T18:25:17.323875015Z","tags":null},"/-AWS-/AWS":{"title":"AWS","content":"WS# AWS\n#aws #cloud #development \n\nAWS (Amazon Web Services) is one of the comprehensive, [](Cloud%20Providers#Cloud%20Providers) AWS services can offer an organization tools such as compute power, database storage and content delivery services.\n\nAWS launched in 2006 from the internal infrastructure that Amazon.com built to handle its online retail operations. AWS was one of the first companies to introduce a [pay-as-you-go](https://www.techtarget.com/searchstorage/definition/pay-as-you-go-cloud-computing-PAYG-cloud-computing) cloud computing model that [scales](https://www.techtarget.com/searchdatacenter/definition/scalability) to provide users with compute, storage or throughput as needed.\n\nAWS offers many different tools and solutions for enterprises and software developers that can be used in data centers in up to 190 countries. Groups such as government agencies, education institutions, nonprofits and private organizations can use AWS services.\n[Elastic Compute Cloud EC2](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Compute%20Cloud%20EC2.md)\n\n\n## AWS Global Infrastructure\n\n### Regions\n**Geographically distinct** Location with AWS datacentres clustered around multiple [#Avilability Zones AZ](#Avilability%20Zones%20AZ) within the same region. There are 22 Geographic Regions set up by AWS all around the world.\n\n- 22 Regions\n- Largest region = US-EAST\n- US-EAST-1 (North Virginia) is the region where you see all of your billing information\n\n\n![AWS Regions map](-=%20AWS%20=-/AWS%20Regions%20map.png)\n\n### Avilability Zones [AZ]\n\nOne or more Datacenters within a AWS Region.\n\nThere are total of 69 AZ Spread all around the world.\n\n- 69 AZs\n- At least 2 AZs in a single regions\n- Aming for 3 AZs per region\n- Latency between AZ is sub 10 milliseconds\n\n![AZs in a region of EU-AF](-=%20AWS%20=-/AZs%20in%20a%20region%20of%20EU-AF.png)\n\n\n### Edge Locations\nData Centers owned by AWS or partners used for accelerating data access across the world. It as direct connection to the AWS network.\n\n\n- Many Edge locations (~225)\n- To upload/download data fast\n- Serves requests for CloudFront and Route 53\n- [S3](-=%20AWS%20=-/--%20Storage%20--/S3.md) Transfer Acceleration traffic and API Gateway endpoint traffic also utilizes edge locations\n\n\n### GovCloud (US)\n\nAWS GovCloud Region allow customers to host sensitive **Controlled Unclassified Information** and other types of regulated workload.\n\n- GovCloud Regions are only operated by employees who are US citizens, on US soil.\n- So they are exclusively for US\n- Made for customers who require secure solutions that comply with us government regulations\n\n\n\n---\n\n\n## Services\n\n![AWS service and resources](-=%20AWS%20=-/AWS%20service%20and%20resources.png)\n\n\n### Free Services:\n\n1. IAM\n2. VPC\n3. Organizations \u0026 Consolidated Billing \n4. AWS Cost Explorer \n5. Auto Scaling\n6. CloudFormation\n7. Elastic Beanstalk\n8. Opswork\n9. Amplify\n10. AppSync\n11. CodeStar\n\n### Business Centric Services\n![Pasted image 20220706225126.png](Pasted%20image%2020220706225126.png)\n\n\n\n## AWS Support Plans\n![Pasted image 20220706164829.png](Pasted%20image%2020220706164829.png)\n\n## AWS Marketplace\n","lastmodified":"2023-03-02T18:25:17.323875015Z","tags":null},"/-AWS-/AWS-CLI-SDK":{"title":"AWS CLI \u0026 SDK","content":"# AWS CLI\n#aws #cli\n\nA [CLI](CLI) tool by [AWS](-=%20AWS%20=-/AWS.md) to controll aws resources via command line. It requires user credentials to perform actions to the account in which the credentials are valid and authorized to perform equivalent console based actions.\n\nLets users interact with AWS form a command line.\nThe CLI is installed via a Python Script.\n\n\n# AWS SDK\n#aws #sdk\n\nA set of tools and libraries that you can use to create applcation sfor a specific software package\n\nThe AWS SDK is a set of API libraries that let you Integrate AWS services into your applications. The SDK is available on the following languages:\n\n1. C++\n2. Go\n3. Java\n4. JavaScript\n5. .NET\n6. NodeJS\n7. PHP\n8. Python (boto3)\n9. Ruby\n\n\n\n## Programmatic Access - Access Key and Secret\n\nTo access the AWS CLI and SDK, this is required for authenticating the making from which the user is trying to apply those commands and access the AWS resources.\n\nthe credentials get stored in a plain-text file. `~/.aws/credentials`\n\nwhenever possible use roles instead of AWS credentials for the programmatic access.\n\nProgrammatic access must be enabled for the user to use the [#AWS CLI](#AWS%20CLI) or [#AWS SDK](#AWS%20SDK)\n\n\n\n","lastmodified":"2023-03-02T18:25:17.323875015Z","tags":null},"/-Azure-/AAD":{"title":"AAD","content":"# Azure Active Directory (AAD)\n#Azure #Active-Directory #rbac \n\n\nAzure AD is not simply a cloud version of [Active Directory](Active%20Directory) in [Azure](-=%20Azure%20=-/Azure.md) as the name might suggest. Although it performs some of the same functions, it is quite different. Azure Active Directory is a secure online authentication store, which can contain users and groups. \n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/ACR":{"title":"ACR","content":"# ACR (Azure Container Registry)\n#Azure #cloud #containers #registry #container-registry #docker \n\nIt is a simple container registry service provided by [Azure](-=%20Azure%20=-/Azure.md). It is similar to [ECR](ECR) Provided by AWS.","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/AVD":{"title":"AVD","content":"# Azure Virtual Desktop\n#cloud #Azure #virtual-machines #compute \n\nAzure Virtual Desktop, (formerly known as Windows Virtual Desktop) is a Microsoft [Azure](-=%20Azure%20=-/Azure.md)-based system for [virtualizing](virtualizing) its Windows operating systems,  aimed at enterprise customers rather than at individual users.\n\n\n\n\n## Demo\nSetup of AVD with existing [AAD](-=%20Azure%20=-/AAD.md).\n\nSteps:\n1. Create a Resource Group\n2. Create a [VNET](-=%20Azure%20=-/VNET.md) link it with the created [Resource Groups](-=%20Azure%20=-/Resource%20Groups.md) with a simple subnet\n3. Create a Hostpool under the [AVD](-=%20Azure%20=-/AVD.md)\n4. \n\nhttps://www.youtube.com/watch?v=jMAanEp-ugI\n\n## AVD with custom windows 11 image\n\n1. Install necessary program and do required changes\n2. Generalize the VM (Remove specific names from VM) \n3. Stop the instance\n4. Create an Image ","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/App-Service":{"title":"App Service","content":"# Azure App Service\n#azure #cloud #compute \n\nIt is a cloud computing based platform for hosting websites in [Azure](-=%20Azure%20=-/Azure.md), created and operated by Microsoft. It is a [PaaS](PaaS) which allows publishing Web apps running on multiple frameworks and written in different programming languages, including Microsoft proprietary ones and 3rd party ones.An Azure subscription is a logical container used to provision resources in Azure. It holds the details of all your resources like virtual machines (VMs), databases, and more. When you create an Azure resource like a VM, you identify the subscription it belongs to.","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Az-900":{"title":"Az 900","content":"# AZ 900\n\nCloud Concepts 15-25%\nAzure Core Services 30-35%\nSecurity 25-30%\nPricing 20-25%\n\n40-60 questions\n\n\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Azure":{"title":"Azure","content":"# Azure\n#azure #cloud #microsoft\n\n## Azure Geographies:\n-  US\n-  Azure Government US\n-  Canada\n-  Brazil \n-  Mexico\n\n58 Regions available across 140 Countries\n\n### Pared Regions\nEach region is pared with another region 300 miles away.\nOne region is updated at a time to ensure no outages\nServices are relied on pared region for Disaster Recovery\n\n### Region Types and Service Availability\n![Pasted image 20230210163119.png](Pasted%20image%2020230210163119.png)\n\n### Special Regions\nHas specialised regions to meet compliance or legal reasons\n\n- US DoD Central\n- US Gov Virginia\n- US Gov Iowa\n- China East\n- China North\n\n### AZ supported Regions\n**Alternate** or **Other** will not have support for AZ.\nThe Regions with atleast 3 AZs are:\n- Central US\n- East US 2\n- West US 2\n- Went Europe\n- France Central\n- North Europe\n- Southeast Asia\n\n\n## Availability zone (AZ)\n- A physical location made up of one or more data-center.\n- A region will generally contain 3 AZs\n- Data-centers within a region will be isolate from each other.\n- For high availability it is common to run workloads on at least 3AZs\n\n![Pasted image 20230210163519.png](Pasted%20image%2020230210163519.png)\n\n### Fault and Update Domain\n\n**Fault Domain** is a logical grouping of hardware to avoid a single point of failure within an AZ\n\n**Update Domain** is used when Azure needs to apply updates to the underlying hardware and software. (Azure make sure by using update domain to eliminate downtime)\n\n**Availability Set** is a logical grouping that can be configured in Azure to ensure that the VMs are placed in different fault/update domains to avoid downtime.\n\n![Pasted image 20230210164159.png](Pasted%20image%2020230210164159.png)\n\n\n---\n\n\n\n## Computing Services\n- Azure VM\n- Azure Container Instances (Docker as a Service)\n- Azure kubernetes Service (Kubernetes as a Service)\n- Azure Service Fabric (Tier-1 Enterprise Container as a Service)\n- Azure Functions\n- Azure Batch\n\n\n## Storage Services\n- Azure Blob storage\n- Azure Disk Storage (Similar to EBS)\n- Azure File Storage (NFS, Similar to EFS)\n- \\*Azure Queue Storage (Messaging Queue)\n- \\*Azure Table Storage (Wide column NoSQL Database)\n- Azure Data Box/Azure Databox Heavy (Rugged breifcase computer)\n- Azure Archive Storage (Long term cold storage)\n- Azure Data Lake Storage (centralized repository like [Snowflake](Snowflake))\n\n\n## Database Services\n- Azure Cosmos DB (NoSQL database)\n- Azure SQL Database (MS SQL database)\n- Azure Database for MySQL/PLSQL/MariaDB\n- SQL Server on VMs (lift and shift existing on-prem sql server dbs)\n- Azure Synapse Analytics (Azure SQL Data Warehouse)\n- Azure Database Migration Service\n- Azure Cache for Redis\n- \\*Azure Table Storage\n\n\n## Application Integration Services\n- Azure Notifications Hub (SNS)\n- Azure API Apps (Essentially API Gateways)\n- Azure Service Bus (Messaging as a service SES)\n- Azure Stream Analytics (Serverless real-time analytics)\n- Azure Logic apps\n- Azure API Management (add in front of an existing APIs)\n- \\*Azure Queue service (SQS)\n\n\n## Developer and Mobile Tools\n- Azure Signal Service (Real-time Messaging)\n- Azure App Service (PaaS like Heroku)\n- Visual Studio (IDE code editor)\n- Xamarin (Mobile app framework)\n\n\n## Azure DevOps Services\nAzure devops is basically a \nAzure Boards\nAzure Pipelines\nAzure Repos\nAzure Test Plans (manual and exploratory testing tools like cyprus.io)\nAzure Artifacts\nAzure DevTest Labs\n\n\n## Azure Resource Manager (ARM)\n\nIaC  of Azure, Azure Resources Manager or ARM allows you to create Azure resources via Json templates. \n\n**Azure QuickStart** is a library of pre-made ARM templates provided by the community and partners to help you quickly launch new projects for a variety of stack scenarios\n\n\n## Azure Virtual Networks\n\n**vNet** is a logically isolated section of Azure Network where you launch your Azure resources. you choose a CIDR range to be used within the network.\n\n**Subnet** is a logical partition of an IP network to breakup the IP-ranges within a vNet. The CIDRs range must be smaller than the vNets. There could be Public or Private Subnets.\n\n\n## Cloud-Native Networking Services\n- Azure DNS (like Route 53)\n- Azure Virtual Network (vNet)\n- Azure Load Balancer (OSI level 4 (Transport) Load Balancer)\n- Azure Application Gateway (OSI Layer 7 HTTP load balancer, WAF applicable)\n- Network Security Groups (NSGs) (virtual firewall at subnet level)\n\n## Enterprise/Hybrid Networking Services\n- Azure Frontdoor ()\n- Azure Express Route (Connection between On-prem to cloud)\n- Virtual WAN \n- Azure Connection (VPN connection)\n- Virtual Network Gateway (A site to site VPN)\n\n## Scale Sets\nThis allows you to group together identical virtual machines and automatically increase or decrease the amount of servers based on:\n- change  in CPU, memory, disk and network performance\n- On a predefined schedule\n\nSimilar to AWS EC2 auto scaling groups.\n\n## IOT Services\n- IoT central (device-cloud connection)\n- IoT Hub (device-application connection)\n- IoT Edge (edge computing)\n- Windows 10 IOT Core Services\n\n\n## Big Data and Analytics Services\n- Azure Synapse Analytics (Enterprise data warehousing and BD analytics)\n- HDInsight (Runs Open-source analytics software like Hadoop, Kafka, Spark)\n- Azure Databricks (Apace Spark based analytic platform)\n- Data Lake Analytics\n\n\n## AI/ML Services\n- **Azure Machine Learning Service**  \n- Personalizer\n- Translator\n- Anomaly Detector\n- Azure Bot Service\n- Form Recognizer\n- Computer Vision\n- Language understanding\n- QnA maker (QA bot)\n- Text Analytics\n- Content Moderator\n- Face\n- ink Recogniser (OCR)\n\n\n## Serverless Services\nHighly Available, Scaleable, and Cost-effective solution that could be **Event Driven Scaled**, **Abstract Servers**, and ** Bill in microseconds for cost effectiveness**.\n- Azure Functions\n- Blob storage\n- Logic Apps (Like Lambda step function)\n- Event Grid (pub/sub to trigger other services)\n\n\n**Azure Portal** is a web based, unified console as an alternative to azure cli. There are also *Azure Preview Portal* to utilize new features.\n`preview.portal.azure.com`\n\n**Azure CLI**\nSupported on Windows, Mac and Linux and can be used to manage Azure resources via CLI.\n\n**PowerShell** is a task automation and configuration management framework. Can be used as a command-line shell and a scripting language like bash. It is built on top of .NET Common Language Runtime, it accepts and returns .Net objects.\n\n**Azure PowerShell** are a set of cmdlets for managing Azure resources directly from PowerShell command Line\n\n**Azure Cloud Shell** is and interactive, authenticated browser-accessible shell for managing azure resources via Bash or PowerShell.\n\n**Visual Studio Code** is a free source-code editor. \n\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Azure-AD":{"title":"Azure AD","content":"# Azure AD\n#azure #Active-Directory \n\nAzure Active Directory (Azure AD) is a directory service provided by Microsoft [Azure](-=%20Azure%20=-/Azure.md) that enables you to sign in and access both Microsoft cloud applications and cloud applications that you develop. Azure AD can also help you maintain your on-premises [Active Directory](Active%20Directory) deployment.\n\nAzure AD provides services such as:\n\n- **Authentication**: This includes verifying identity to access applications and resources. It also includes providing functionality such as self-service password reset, multi-factor authentication, a custom list of banned passwords, and smart lockout services.\n\n- **Single sign-on**: Single sign-on (SSO) enables you to remember only one username and one password to access multiple applications. A single identity is tied to a user, which simplifies the security model. As users change roles or leave an organization, access modifications are tied to that identity, which greatly reduces the effort needed to change or disable accounts.\n\n- **Application management**: You can manage your cloud and on-premises apps by using Azure AD. Features like Application Proxy, SaaS apps, the My Apps portal, and single sign-on provide a better user experience.\n\n- **Device management**: Along with accounts for individual people, Azure AD supports the registration of devices. Registration enables devices to be managed through tools like Microsoft Intune. It also allows for device-based Conditional Access policies to restrict access attempts to only those coming from known devices, regardless of the requesting user account.","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Azure-DNS":{"title":"Azure DNS","content":"# Azure DNS\n#Azure #cloud #networking \n\nThis service is used to manage your DNS records and also host them. Similar to AWS [Route53](-=%20AWS%20=-/--%20Networking%20--/Route53.md). ","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Azure-Load-Balancer":{"title":"Azure Load Balancer","content":"# Azure Load Balancer\n#Azure #cloud \n\nIs used for evenly distributing incoming network traffic across a group of backend resources or servers using **OSI Layer 4 (Transport Layer)**. A A basic networking servile provided by [Azure](-=%20Azure%20=-/Azure.md) similar to AWS [Elastic Load Balancer (ELB)](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Load%20Balancer%20(ELB).md) There can be a Public Load Balancer as well as Private Load balancer.\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Azure-NACL":{"title":"Azure NACL","content":"# NACL (Network Access Control List)\n#Azure #cloud #security #acl\n\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Azure-NSG":{"title":"Azure NSG","content":"# NSG (Network Security Groups)\n#Azure #cloud #security #security-groups\n\nAn [Azure](-=%20Azure%20=-/Azure.md) networking firewall like service similar to [AWS NSG](AWS%20NSG). ","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Azure-Traffic-Manager":{"title":"Azure Traffic Manager","content":"# Azure Traffic Manager\n#Azure #cloud #networking \n\nthis services operates at the DNS layer to quickly and efficiently direct incoming DNS requests based on the routing method of your choice. (In AWS it is done within the **Route53**)\n- Route traffic to servers the geographically near (reduces latency)\n- Fail-over to redundant systems (increases fault-tolerance)\n- Route traffics to random VM for A/B testing\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Azure-WAF":{"title":"Azure WAF","content":"# WAF\n#Azure #cloud #security #waf \n\nA cloud native [WAF 1](WAF%201) Solution by [Azure](-=%20Azure%20=-/Azure.md) which protects web-apps from common cyber attacks. \nAzure WAF consists of [](-=%20Azure%20=-/Azure%20WAF.md#Managed%20Rules) and [](-=%20Azure%20=-/Azure%20WAF.md#Custom%20Rules) .which provides basic configuration such as Comprehensive protection for the Open Web Application Security Project (OWASP) top 10 security risks. \n\n\n## Managed Rules\n\n\n## Custom Rules\n\n\n\n\nREFERENCES:\nhttps://azure.microsoft.com/en-gb/pricing/details/web-application-firewall/","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Blob-Storage":{"title":"Blob Storage","content":"# Azure Blob Storage\n#Azure #cloud #storage \n\nIt is a object storage solution provided by [Azure](-=%20Azure%20=-/Azure.md) for cloud-native workloads, data archives, data lakes, etc. It is similar to the [S3](-=%20AWS%20=-/--%20Storage%20--/S3.md) A service offered by AWS.\n\nIt is:\nScaleWSable, durable, and available\nSecured\nOptimised for data lakes","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/CosmosDB":{"title":"CosmosDB","content":"# Cosmos DB\n#cloud #Azure #databases \n\nAzure SQL Database is a high-performance, reliable, fully managed, and secure [relational database](relational%20database) based on the latest stable version of the [Microsoft SQL Server](Microsoft%20SQL%20Server) database engine provided by [Azure](-=%20Azure%20=-/Azure.md). \n\nAzure Cosmos DB is flexible as it stores data in atom-record-sequence (ARS) format which is then abstracted and projected as an API, which you specify when you're creating your database. Your choices include SQL, MongoDB, Cassandra, Tables, and Gremlin. This allows the user to keep the native API (i.e. no changes to the application code).\n\n## Managed Database engines:\nAzure provides fully managed database capabilities for SQLServer, MySQL and PostgreSQL databases which provides the following benifits:\n-   Built-in high availability with no additional cost.\n-   Predictable performance and inclusive, pay-as-you-go pricing.\n-   Scale as needed, within seconds.\n-   Ability to protect sensitive data at rest and in motion.\n-   Automatic backups.\n-   Enterprise-grade security and compliance.\n\n### Azure Database for MySQL\n\nAzure Database for MySQL offers several service tiers, and each tier provides different performance and capabilities to support lightweight to heavyweight database workloads. You can build your first app on a small database for a few dollars a month, then adjust the scale to meet the needs of your solution. Dynamic scalability enables your database to transparently respond to rapidly changing resource requirements. You only pay for the resources you need, and only when you need them.\n\n\n### Azure Database for PostgreSQL\n\nAzure Database for PostgreSQL is a relational database service in the cloud. The server software is based on the community version of the open-source PostgreSQL database engine. Your familiarity with tools and expertise with PostgreSQL is applicable when you're using Azure Database for PostgreSQL.\n\nAzure Database for PostgreSQL is available in two deployment options: **Single Server** and **Hyperscale (Citus)**.\n\n**Single Server**\nAll those capabilities require almost no administration, and all are provided at no additional cost. You can focus on rapid application development and accelerating your time to market rather than having to manage virtual machines and infrastructure. You can continue to develop your application with the open-source tools and platform of your choice, without having to learn new skills.\n\nThe Single Server deployment option offers three pricing tiers: Basic, General Purpose, and Memory Optimized. Each tier offers different resource capabilities to support your database workloads. You can build your first app on a small database for a few dollars a month, then adjust the scale to meet the needs of your solution. Dynamic scalability enables your database to transparently respond to rapidly changing resource requirements. You only pay for the resources you need, and only when you need them.\n\n**Hyperscale (Citus)**\nThe Hyperscale (Citus) option horizontally scales queries across multiple machines by using sharding. Its query engine parallelizes incoming SQL queries across these servers for faster responses on large datasets. It serves applications that require greater scale and performance, generally workloads that are approaching, or already exceed, 100 GB of data.\n\nThe Hyperscale (Citus) deployment option supports multi-tenant applications, real-time operational analytics, and high-throughput transactional workloads. Applications built for PostgreSQL can run distributed queries on Hyperscale (Citus) with standard connection libraries and minimal changes.\n\n\n### Azure SQL Managed Instance (MI) \n\nSQL Managed Instance (SQL MI) provides native Virtual Network (VNet) integration while Azure SQL Database enables restricted Virtual Network (VNet) access using [VNET](-=%20Azure%20=-/VNET.md) Endpoints and SQL MI also helps bridge the gap between Azure SQL Database and On-premises SQL Server due to being built on an instance scoped configuration model.\n\nAzure SQL Managed Instance (MI) is similar to The Azure [SQL-Database](-=%20Azure%20=-/SQL-Database.md) on the following topics:\nManagement\n1. Backup\n2. Availability\n3. Host Accessibility\n4. License\n\nHowever the key differences are:\n**1. Recovery model**  \n_Azure SQL Database_: From automated backups only.  \n_SQL MI_: From automated backups and from full backups placed on Azure Blob Storage.\n\n**2. Active Geo-replication**  \n_SQL Database:_ Supported. In all service tiers other than Hyperscale.  \n_SQL MI:_ Not supported. alternative solution is [Auto-failover groups](https://docs.microsoft.com/en-us/azure/azure-sql/database/auto-failover-group-overview).\n\n**3. Auto-failover groups**  \n_SQL Database:_ Supported. In all service tiers other than Hyperscale.  \n_SQL MI:_ Supported.\n\n**4. Auto-scale**  \n_SQL Database:_ Only supported in Serverless model.  \n_SQL MI:_ Not supported. You need to choose reserved compute and storage (vCore or max storage).\n\n**5. Automatic tuning (indexes)**  \n_SQL Database:_ Supported.  \n_SQL MI:_ Not supported.\n\n**6. Elastic jobs**  \n_SQL Database:_ Supported.  \n_SQL MI:_ Not supported. [SQL Agent](https://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/transact-sql-tsql-differences-sql-server#sql-server-agent) can be used instead.\n\n**7. Long-term backup retention (LTR)**  \n_SQL Database:_ Supported. keep automatically taken backups up to 10 years.  \n_SQL MI:_ Not supported yet. Manual backups as a temporary workaround.\n\n**8. Hyperscale architecture**  \n_SQL Database:_ Supported.  \n_SQL MI:_ Not supported.\n\n**9. SQL Server Profiler**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**10. Cross-database transactions**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**11. Database mail (DbMail)**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**12. Linked servers**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**13. Service Broker**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**14. SQL Server Agent**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**15. SQL Server Auditing**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n\n\n## REFERENCES:\nhttps://medium.com/awesome-azure/azure-difference-between-azure-sql-database-and-azure-sql-managed-instance-sql-mi-2e61e4485a65#:~:text=SQL%20Managed%20Instance%20(SQL%20MI)%20provides%20native%20Virtual%20Network%20(,an%20instance%20scoped%20configuration%20model.\n\n### Azure database documentation\n\n-   [Azure Analytics Services](https://azure.microsoft.com/product-categories/analytics/)\n-   [Azure Cosmos DB documentation](https://learn.microsoft.com/en-us/azure/cosmos-db/)\n-   [Azure SQL Database documentation](https://learn.microsoft.com/en-us/azure/sql-database/)\n-   [Azure SQL Managed Instance documentation](https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/)\n-   [Azure Database for MySQL documentation](https://learn.microsoft.com/en-us/azure/mysql/)\n-   [Azure Database for PostgreSQL documentation](https://learn.microsoft.com/en-us/azure/postgresql/)\n\n### Migrating database workloads to Azure\n\n-   [Migrate SQL workloads to Azure](https://learn.microsoft.com/en-us/training/paths/migrate-sql-workloads-azure/)\n-   [Migrate SQL Workloads to Azure SQL Databases](https://learn.microsoft.com/en-us/training/modules/migrate-sql-workloads-azure-sql-databases/)\n-   [Migrate SQL Workloads to Azure SQL Managed Instances](https://learn.microsoft.com/en-us/training/modules/migrate-sql-workloads-azure-managed-instances/)\n-   [Migrate on-premises MySQL databases to Azure Database for MySQL](https://learn.microsoft.com/en-us/training/modules/migrate-on-premises-mysql-databases/)\n\n### Working with Azure databases\n\n-   [Create an Azure Database for PostgreSQL server](https://learn.microsoft.com/en-us/training/modules/create-azure-db-for-postgresql-server/)\n-   [Insert and query data in your Azure Cosmos DB database](https://learn.microsoft.com/en-us/training/modules/access-data-with-cosmos-db-and-sql-api/)\n-   [Provision an Azure SQL database to store application data](https://learn.microsoft.com/en-us/training/modules/provision-azure-sql-db/)","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/DP-900":{"title":"DP 900","content":"# DP-900\n\n## Core Data related Azure Services\n\n![Pasted image 20230217231056.png](Pasted%20image%2020230217231056.png)\n\n![Pasted image 20230217231305.png](Pasted%20image%2020230217231305.png)\n\n\nAzure Storage Explorer (To explore Azure Storage accounts)\nAzure Synapse Analytics \nAzure Data Lake Storage\nAzure Data Analytics\nAzure Data Box\nAzure Databricks (Apache spark 3rd party)\nMicrosoft Power BI (Dashboards)\nHDInsight (fully managed Hadoop)\nAzure Data Studio (IDE like VSCode for data related tasks similar to SSIS)\nAzure Data Factory (ETL/ELT pipeline builder)\nSQL Server Integration Services (SSIS)\n![Pasted image 20230217231411.png](Pasted%20image%2020230217231411.png)\n\n## Azure Data Roles\n![Pasted image 20230217231752.png](Pasted%20image%2020230217231752.png)\n\n\n### Data Engineer Tools\n![Pasted image 20230217232108.png](Pasted%20image%2020230217232108.png)\n\n\n## Data Overview\n![Pasted image 20230217232341.png](Pasted%20image%2020230217232341.png)\n\n### Data \nBasically Information\n\n\n### Data Documents \nCollective Data (Datasets, Databases, Datastores, Data warehouses, notebooks)\n\n\n### Datasets \nLogical Grouping of units of data (mnist, Stackoverflow developer dataset, etc)\n![Pasted image 20230217232822.png](Pasted%20image%2020230217232822.png)\n\n\n### Data Structure \na specific storage format.\n- unstructured (Sharepoint, blob, azure files, Azure Data Lakes) \n- semi-structured (slight relations XML, JSON, AVRO, PARQUET) (Azure Tables, Cosmos DB, Mongo, Cassandra)\n![Pasted image 20230218001000.png](Pasted%20image%2020230218001000.png)\n![Pasted image 20230218001143.png](Pasted%20image%2020230218001143.png)\n\n![Pasted image 20230218001106.png](Pasted%20image%2020230218001106.png)\n- structured \nusually just tables\n\n### Data Type\nSingle unit of data to tell a computer how a data is intended to be used (Int, Float, Characters, String, Array, Hash, Binary, bool, enums etc) some of these overlap with data structures\n\n\n## Schema\nBlueprint of database\n![Pasted image 20230217233245.png](Pasted%20image%2020230217233245.png)\n\n### Schemaless\nA cell can accept many types related to Nosql Databases\n\n\n\n### Batch Processing\nUsually a scheduled action to process a collection of data, are cost effective and is not real-time (ie, analysing daily logs)\n\n### Stream Processing\nFor realtime data processing\nProducers send to stream and Consumer pull from stream\n\n\n### Relational Data\n**Tables**: Logical grouping of rows and columns\n**Views**: Result of query which is stored in memory (Temp table)\n**Materialized** View: similar to Views but stored on disk\n**Indexes**: copy of a column to accelerate stuff (By storing partial redundant data)\n**Constraints**: Rules for writes\n**Triggers**: A function triggered on a certain database event\n**PK/FK**: A data to create relationship between tables\n\n**Row Store**: generally used in relational database\n**Column Store**: NoSQL Faster for analytics, good for  large amounts of data (OLTP), for limited columns use\n\n**Pivot Tables**: A table of statistics easy to create in  Excel to draw attention to useful information and finding figures and facts quickly.\n\n**Data Consistency**: when data is kept in many places and weather they match or not. (Strongly consistent vs Eventually Consistent).\nSyncronous data transmissions are used in Strongly consistent data.\n\n### Non Relational Data\n- Key/Value\n- Document\n- Columnar\n- Graph\n\n### Data Sources\nWhere Data originates from, can be:\nData lake\nData warehouse\nDatastore\nDatabase\nData requested from API\nFlat Files (spreadsheet)\n\n\n### Data Store\nA repo for storing data, Database is a subset of data store\n\n### Database \nStores semi-structured or structured data\nA more complex data store with a formal design\n\n### Data Warehouse\nA relational data store for analytic workloads, utilizing usually column-oriented data-store to aggrigate huge amounts of data. they are desined to be HOT (fast). They are run in a schedule. It needs to consume data from a relational database.\n\n### Data Mart\nSubset of Datawarehouse which stores a smaller sets of data and are designed to be read only.\n\n### Data Lake\nA centralized place to store vast amount of raw data. Used for:\nVisualization\nReal-time analytics\nMachine Learning\n![Pasted image 20230218111944.png](Pasted%20image%2020230218111944.png)\n![Pasted image 20230218112119.png](Pasted%20image%2020230218112119.png)\n\n### Data Lakehouse\nCombines the best elements of Data Lakes and Data warehouse.\nSupports video, audio and text files, used for data science and ML.\nsupport for both streaming and ELT\n\n### Azure Synapse\nBasically Data Lake or LakeHouse service by Azure\n![Pasted image 20230218111352.png](Pasted%20image%2020230218111352.png)\n**Synapse SQL**\n- Extends TSQL for ML\n- streaming capabilities to load data\n- Integrate AI with SQL\n- Offers both serverless and dedicated resource models\n\n**Features**:\n- Integrate with Apache Spark (SparkML, )\n- Simplified resource model\n- Fast spark load\n- Built in support for dotnet\n- makes it easy to use SQL and spark\n\n### PolyBase\nData virtualization feature for Sql Server\nQuery directly TSQL from \n- SQL server\n- Oracle\n- Teradata\n- MongoDB\n- Hadoop clusters\n- Cosmos DB\n![Pasted image 20230218112328.png](Pasted%20image%2020230218112328.png)\ncan bu used to perform ETL transformation\n![Pasted image 20230218112430.png](Pasted%20image%2020230218112430.png)\n\n\n### Azure Data Lake Analytics\nOn demand analytics job service\n![Pasted image 20230218112644.png](Pasted%20image%2020230218112644.png)\n\n\n## Data Mining\n![Pasted image 20230218001406.png](Pasted%20image%2020230218001406.png)\nfind valid patterns and relationships (classification, clustering, regression, sequential, association rules, Outer Detection, Prediction).\n\n## Data Wrangling\nMatching data from raw to other format. \n\n\n## Data Modelling\nOrganizing elements of data and standardises how they relate to one another. could be conceptial, logical or physical. example a ER diagram.\n\n\n## ETL vs ELT\nused when you want to move data from one location to another. Ie moving data from relational to non relational database\n\n![Pasted image 20230218002020.png](Pasted%20image%2020230218002020.png)\n\n## Data Analytics\nExamining, transforming and arranging data to view useful information.\n![Pasted image 20230218002122.png](Pasted%20image%2020230218002122.png)\n\n**Techniques**\nDescriptive\nDiagnostic\nPredictive\nPrescriptive\nCognitive\n\n\n\n\n\n# Azure HDInsights\n![Pasted image 20230218103328.png](Pasted%20image%2020230218103328.png)\nCan use **Apache Ambari** an opensource Hadoop implementation\n\n**Apache spark** is a unified analytics engine for BD and ML.\n- Super fast \n\n**DataBricks** Fully managed Spark Clusters.\nAvailable on all major cloud platform.\nAzure Data Bricks is a partnership with Databricks to offer the services within Azure.\n- Azure Data-bricks Workspace (for data pipelines: Batching, Streaming, Storage)\n- Azure Database SQL Analytics (run SQL on Data Lakes, visualizations, dashboards)\n\n\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/DP-900-cheatsheets":{"title":"DP-900 cheatsheets","content":"# Cheet Sheets\n\n**Power BI**\n![Pasted image 20230218113522.png](Pasted%20image%2020230218113522.png)\n![Pasted image 20230218114405.png](Pasted%20image%2020230218114405.png)\n![Pasted image 20230218114833.png](Pasted%20image%2020230218114833.png)\n\n**Data Cheetsheets**\n![Pasted image 20230218110331.png](Pasted%20image%2020230218110331.png)\n![Pasted image 20230218110557.png](Pasted%20image%2020230218110557.png)\n![Pasted image 20230218110835.png](Pasted%20image%2020230218110835.png)\n![Pasted image 20230218111000.png](Pasted%20image%2020230218111000.png)\n\n**Relational Databases**\n![Pasted image 20230218120115.png](Pasted%20image%2020230218120115.png)\n![Pasted image 20230218002710.png](Pasted%20image%2020230218002710.png)\n\n**Account Storage**\n![Pasted image 20230218113200.png](Pasted%20image%2020230218113200.png)\n\n**CosmosDB**\n![Pasted image 20230218121343.png](Pasted%20image%2020230218121343.png)\n![Pasted image 20230218121706.png](Pasted%20image%2020230218121706.png)\n\n\n**Azure Synapse and Data Lake**\n![Pasted image 20230218112816.png](Pasted%20image%2020230218112816.png)\n\n**Hadoop**\n![Pasted image 20230218122232.png](Pasted%20image%2020230218122232.png)\n\n**Spark and DataBricks**\n![Pasted image 20230218122602.png](Pasted%20image%2020230218122602.png)\n\n**SQL Management Studio (SSMS)**\n![Pasted image 20230218122457.png](Pasted%20image%2020230218122457.png)\n\n![Pasted image 20230218105604.png](Pasted%20image%2020230218105604.png)\n![Pasted image 20230218105647.png](Pasted%20image%2020230218105647.png)\n![Pasted image 20230218122909.png](Pasted%20image%2020230218122909.png)\n![Pasted image 20230218105830.png](Pasted%20image%2020230218105830.png)\n![Pasted image 20230218105929.png](Pasted%20image%2020230218105929.png)\n![Pasted image 20230218105936.png](Pasted%20image%2020230218105936.png)\n![Pasted image 20230218110125.png](Pasted%20image%2020230218110125.png)\n\n**Database Security**\n![Pasted image 20230218120454.png](Pasted%20image%2020230218120454.png)","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Resource-Groups":{"title":"Resource Groups","content":"# Resource Groups (Azure)\n#Azure #cloud #organization\n\nA required grouping tag for all of the [Azure](-=%20Azure%20=-/Azure.md) services. It helps in organizing the resources. == Microservice Architecture ==/-= AKS =-/AKS","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/SQL-Database":{"title":"SQL-Database","content":"# Azure SQL Database\n#cloud #Azure #databases \n\nAzure SQL Database is a PaaS deployment option of Azure SQL that abstracts both the OS and the SQL Server instance provided by [Azure](-=%20Azure%20=-/Azure.md). An Azure SQL database is a fully managed service. You don't have to deal with complex database tasks like configuring and managing high availability, tuning, and backups. The service automatically upgrades each SQL database to run the most recent version of SQL Server. You get the latest SQL Server capabilities without having to perform manual updates.\n\n![Pasted image 20221030085434.png](Pasted%20image%2020221030085434.png)","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/Subscriptions":{"title":"Subscriptions","content":"# Subscriptions\n#Azure #cloud \n\nAn [Azure](-=%20Azure%20=-/Azure.md) subscription is **a logical container used to provision resources in Azure**. It holds the details of all your resources like virtual machines (VMs), databases, and more. When you create an Azure resource like a VM, you identify the subscription it belongs to.","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/VM":{"title":"VM","content":"# VM (Virtual Macines)\n#Azure #cloud #compute \n\n\nIt is a simple compute service provided by [Azure](-=%20Azure%20=-/Azure.md) to host [VM](-=%20Azure%20=-/VM.md)s in a [VNET](-=%20Azure%20=-/VNET.md). Comparable to the [Elastic Compute Cloud EC2](-=%20AWS%20=-/--%20Compute%20--/Elastic%20Compute%20Cloud%20EC2.md) of AWS.\n\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/-Azure-/VNET":{"title":"VNET","content":"# VNET (Virtual Network)\n#Azure #cloud\n\n-   An [Azure](-=%20Azure%20=-/Azure.md) Virtual Network (VNet) is a network or environment that can be used to run VMs and applications in the cloud.\n-   When it is created, the services and Virtual Machines within the Azure network interact securely with each other.\n- It is similar to the [VPC](-=%20AWS%20=-/--%20Networking%20--/VPC.md) service provided by AWS\n\nAzure Virtual Network (VNet) is the fundamental building block for your private network in Azure. You can use a VNets to:\n\n-   **Communicate between Azure resources**: You can deploy VMs, and several other types of Azure resources to a virtual network, such as Azure App Service Environments, the Azure Kubernetes Service (AKS), and Azure Virtual Machine Scale Sets.\n    \n-   **Communicate between each other**: You can connect virtual networks to each other, enabling resources in either virtual network to communicate with each other, using virtual network peering. The virtual networks you connect can be in the same, or different, Azure regions.\n    \n-   **Communicate to the internet**: All resources in a VNet can communicate outbound to the internet, by default. You can communicate inbound to a resource by assigning a public IP address or a public Load Balancer. You can also use [Public IP addresses](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-public-ip-address) or public [Load Balancer](https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-overview) to manage your outbound connections.\n    \n-   **Communicate with on-premises networks**: You can connect your on-premises computers and networks to a virtual network using [VPN Gateway](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways) or [ExpressRoute](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-introduction).\n    \n\nWhen you design a network from bottom up, you gather some basic information. This information could be number of hosts, network devices, number of [subnets](subnets), routing between subnets, isolation domains such as VLANs. This information helps in sizing the network and security devices as well creating the architecture to support applications and services.\n\nWhen you plan to deploy your applications and services in Azure, you will start by creating a logical boundary in Azure, which is called a virtual network. This virtual network is akin to a physical network boundary. As it is a virtual network, you don't need physical gear but still have to plan for the logical entities such as IP addresses, IP subnets, routing, and policies.\n\nWhen you create a virtual network in Azure, it's pre-configured with an IP range (10.0.0.0/16). This range isn't fixed, you can define your own IP range. You can define both IPv4 and IPv6 address ranges. IP ranges defined for the virtual network are not advertised to Internet. You can create multiple subnets from your IP range. These subnets will be used to assign IP addresses to virtual network interfaces (vNICs). Azure reserves the first four and last IP address for a total of 5 IP addresses within each subnet. There is no concept of VLANs in a public cloud. However, you can create isolation within a virtual network based on your defined subnets.\n\nYou can create one large subnet encompassing all the virtual network address space or choose to create multiple subnets.\n\nA virtual network is a virtual, isolated portion of the Azure public network. Each virtual network is dedicated to your subscription. Things to consider when deciding whether to create one virtual network, or multiple virtual networks in a subscription:\n\n-   Do any organizational security requirements exist for isolating traffic into separate virtual networks? You can choose to connect virtual networks or not. If you connect virtual networks, you can implement a network virtual appliance, such as a firewall, to control the flow of traffic between the virtual networks. For more information, visit [security](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-vnet-plan-design-arm?toc=/azure/networking/fundamentals/toc.json) and [connectivity](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-vnet-plan-design-arm?toc=/azure/networking/fundamentals/toc.json).\n    \n-   Do any organizational requirements exist for isolating virtual networks into separate [subscriptions](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-vnet-plan-design-arm?toc=/azure/networking/fundamentals/toc.json) or [regions](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-vnet-plan-design-arm?toc=/azure/networking/fundamentals/toc.json)?\n    \n-   A [network interface](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-network-interface) enables a VM to communicate with other resources. Each network interface has one or more private IP addresses assigned to it. How many network interfaces and [private IP addresses](https://learn.microsoft.com/en-us/azure/virtual-network/private-ip-addresses) do you require in a virtual network? There are [limits](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits?toc=/azure/virtual-network/toc.json) to the number of network interfaces and private IP addresses that you can have within a virtual network.\n\n[Azure NSG](-=%20Azure%20=-/Azure%20NSG.md)\n\n[Azure NACL](-=%20Azure%20=-/Azure%20NACL.md)","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/notes/callouts":{"title":"Callouts","content":"\n## Callout support\n\nQuartz supports the same Admonition-callout syntax as Obsidian.\n\nThis includes\n- 12 Distinct callout types (each with several aliases)\n- Collapsable callouts\n\nSee [documentation on supported types and syntax here](https://help.obsidian.md/How+to/Use+callouts#Types).\n\n## Showcase\n\n\u003e [!EXAMPLE] Examples\n\u003e\n\u003e Aliases: example\n\n\u003e [!note] Notes\n\u003e\n\u003e Aliases: note\n\n\u003e [!abstract] Summaries \n\u003e\n\u003e Aliases: abstract, summary, tldr\n\n\u003e [!info] Info \n\u003e\n\u003e Aliases: info, todo\n\n\u003e [!tip] Hint \n\u003e\n\u003e Aliases: tip, hint, important\n\n\u003e [!success] Success \n\u003e\n\u003e Aliases: success, check, done\n\n\u003e [!question] Question \n\u003e\n\u003e Aliases: question, help, faq\n\n\u003e [!warning] Warning \n\u003e\n\u003e Aliases: warning, caution, attention\n\n\u003e [!failure] Failure \n\u003e\n\u003e Aliases: failure, fail, missing\n\n\u003e [!danger] Error\n\u003e\n\u003e Aliases: danger, error\n\n\u003e [!bug] Bug\n\u003e\n\u003e Aliases: bug\n\n\u003e [!quote] Quote\n\u003e\n\u003e Aliases: quote, cite\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/notes/config":{"title":"Configuration","content":"\n## Configuration\nQuartz is designed to be extremely configurable. You can find the bulk of the configuration scattered throughout the repository depending on how in-depth you'd like to get.\n\nThe majority of configuration can be found under `data/config.yaml`. An annotated example configuration is shown below.\n\n```yaml {title=\"data/config.yaml\"}\n# The name to display in the footer\nname: Jacky Zhao\n\n# whether to globally show the table of contents on each page\n# this can be turned off on a per-page basis by adding this to the\n# front-matter of that note\nenableToc: true\n\n# whether to by-default open or close the table of contents on each page\nopenToc: false\n\n# whether to display on-hover link preview cards\nenableLinkPreview: true\n\n# whether to render titles for code blocks\nenableCodeBlockTitle: true \n\n# whether to render copy buttons for code blocks\nenableCodeBlockCopy: true \n\n# whether to render callouts\nenableCallouts: true\n\n# whether to try to process Latex\nenableLatex: true\n\n# whether to enable single-page-app style rendering\n# this prevents flashes of unstyled content and improves\n# smoothness of Quartz. More info in issue #109 on GitHub\nenableSPA: true\n\n# whether to render a footer\nenableFooter: true\n\n# whether backlinks of pages should show the context in which\n# they were mentioned\nenableContextualBacklinks: true\n\n# whether to show a section of recent notes on the home page\nenableRecentNotes: false\n\n# whether to display an 'edit' button next to the last edited field\n# that links to github\nenableGitHubEdit: true\nGitHubLink: https://github.com/jackyzha0/quartz/tree/hugo/content\n\n# whether to render mermaid diagrams\nenableMermaid: true\n\n# whether to use Operand to power semantic search\n# IMPORTANT: replace this API key with your own if you plan on using\n# Operand search!\nsearch:\n  enableSemanticSearch: false\n  operandApiKey: \"REPLACE-WITH-YOUR-OPERAND-API-KEY\"\n  operandIndexId: \"REPLACE-WITH-YOUR-OPERAND-INDEX-ID\"\n\n# page description used for SEO\ndescription:\n  Host your second brain and digital garden for free. Quartz features extremely fast full-text search,\n  Wikilink support, backlinks, local graph, tags, and link previews.\n\n# title of the home page (also for SEO)\npage_title:\n  \"🪴 Quartz 3.3\"\n\n# links to show in the footer\nlinks:\n  - link_name: Twitter\n    link: https://twitter.com/_jzhao\n  - link_name: Github\n    link: https://github.com/jackyzha0\n```\n\n### Code Block Titles\nTo add code block titles with Quartz:\n\n1. Ensure that code block titles are enabled in Quartz's configuration:\n\n    ```yaml {title=\"data/config.yaml\", linenos=false}\n    enableCodeBlockTitle: true\n    ```\n\n2. Add the `title` attribute to the desired [code block\n   fence](https://gohugo.io/content-management/syntax-highlighting/#highlighting-in-code-fences):\n\n      ```markdown {linenos=false}\n       ```yaml {title=\"data/config.yaml\"}\n       enableCodeBlockTitle: true  # example from step 1\n       ```\n      ```\n\n**Note** that if `{title=\u003cmy-title\u003e}` is included, and code block titles are not\nenabled, no errors will occur, and the title attribute will be ignored.\n\n### HTML Favicons\nIf you would like to customize the favicons of your Quartz-based website, you \ncan add them to the `data/config.yaml` file. The **default** without any set \n`favicon` key is:\n\n```html {title=\"layouts/partials/head.html\", linenostart=15}\n\u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n```\n\nThe default can be overridden by defining a value to the `favicon` key in your \n`data/config.yaml` file. For example, here is a `List[Dictionary]` example format, which is\nequivalent to the default:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon:\n  - { rel: \"shortcut icon\", href: \"icon.png\", type: \"image/png\" }\n#  - { ... } # Repeat for each additional favicon you want to add\n```\n\nIn this format, the keys are identical to their HTML representations.\n\nIf you plan to add multiple favicons generated by a website (see list below), it\nmay be easier to define it as HTML. Here is an example which appends the \n**Apple touch icon** to Quartz's default favicon:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon: |\n  \u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n  \u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"\u003e\n```\n\nThis second favicon will now be used as a web page icon when someone adds your \nwebpage to the home screen of their Apple device. If you are interested in more \ninformation about the current and past standards of favicons, you can read \n[this article](https://www.emergeinteractive.com/insights/detail/the-essentials-of-favicons/).\n\n**Note** that all generated favicon paths, defined by the `href` \nattribute, are relative to the `static/` directory.\n\n### Graph View\nTo customize the Interactive Graph view, you can poke around `data/graphConfig.yaml`.\n\n```yaml {title=\"data/graphConfig.yaml\"}\n# if true, a Global Graph will be shown on home page with full width, no backlink.\n# A different set of Local Graphs will be shown on sub pages.\n# if false, Local Graph will be default on every page as usual\nenableGlobalGraph: false\n\n### Local Graph ###\nlocalGraph:\n    # whether automatically generate a legend\n    enableLegend: false\n    \n    # whether to allow dragging nodes in the graph\n    enableDrag: true\n    \n    # whether to allow zooming and panning the graph\n    enableZoom: true\n    \n    # how many neighbours of the current node to show (-1 is all nodes)\n    depth: 1\n    \n    # initial zoom factor of the graph\n    scale: 1.2\n    \n    # how strongly nodes should repel each other\n    repelForce: 2\n\n    # how strongly should nodes be attracted to the center of gravity\n    centerForce: 1\n\n    # what the default link length should be\n    linkDistance: 1\n    \n    # how big the node labels should be\n    fontSize: 0.6\n    \n    # scale at which to start fading the labes on nodes\n    opacityScale: 3\n\n### Global Graph ###\nglobalGraph:\n\t# same settings as above\n\n### For all graphs ###\n# colour specific nodes path off of their path\npaths:\n  - /moc: \"#4388cc\"\n```\n\n\n## Styling\nWant to go even more in-depth? You can add custom CSS styling and change existing colours through editing `assets/styles/custom.scss`. If you'd like to target specific parts of the site, you can add ids and classes to the HTML partials in `/layouts/partials`. \n\n### Partials\nPartials are what dictate what gets rendered to the page. Want to change how pages are styled and structured? You can edit the appropriate layout in `/layouts`.\n\nFor example, the structure of the home page can be edited through `/layouts/index.html`. To customize the footer, you can edit `/layouts/partials/footer.html`\n\nMore info about partials on [Hugo's website.](https://gohugo.io/templates/partials/)\n\nStill having problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n\n## Language Support\n[CJK + Latex Support (测试)](notes/CJK%20+%20Latex%20Support%20(测试).md) comes out of the box with Quartz.\n\nWant to support languages that read from right-to-left (like Arabic)? Hugo (and by proxy, Quartz) supports this natively.\n\nFollow the steps [Hugo provides here](https://gohugo.io/content-management/multilingual/#configure-languages) and modify your `config.toml`\n\nFor example:\n\n```toml\ndefaultContentLanguage = 'ar'\n[languages]\n  [languages.ar]\n    languagedirection = 'rtl'\n    title = 'مدونتي'\n    weight = 1\n```\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/notes/custom-Domain":{"title":"Custom Domain","content":"\n### Registrar\nThis step is only applicable if you are using a **custom domain**! If you are using a `\u003cYOUR-USERNAME\u003e.github.io` domain, you can skip this step.\n\nFor this last bit to take effect, you also need to create a CNAME record with the DNS provider you register your domain with (i.e. NameCheap, Google Domains).\n\nGitHub has some [documentation on this](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site), but the tldr; is to\n\n1. Go to your forked repository (`github.com/\u003cYOUR-GITHUB-USERNAME\u003e/quartz`) settings page and go to the Pages tab. Under \"Custom domain\", type your custom domain, then click **Save**.\n2. Go to your DNS Provider and create a CNAME record that points from your domain to `\u003cYOUR-GITHUB-USERNAME.github.io.` (yes, with the trailing period).\n\n\t![Example Configuration for Quartz](/notes/images/google-domains.png)*Example Configuration for Quartz*\n3. Wait 30 minutes to an hour for the network changes to kick in.\n4. Done!","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/notes/editing":{"title":"Editing Content in Quartz","content":"\n## Editing \nQuartz runs on top of [Hugo](https://gohugo.io/) so all notes are written in [Markdown](https://www.markdownguide.org/getting-started/).\n\n### Folder Structure\nHere's a rough overview of what's what.\n\n**All content in your garden can found in the `/content` folder.** To make edits, you can open any of the files and make changes directly and save it. You can organize content into any folder you'd like.\n\n**To edit the main home page, open `/content/_index.md`.**\n\nTo create a link between notes in your garden, just create a normal link using Markdown pointing to the document in question. Please note that **all links should be relative to the root `/content` path**. \n\n```markdown\nFor example, I want to link this current document to `notes/config.md`.\n[A link to the config page](notes/config.md)\n```\n\nSimilarly, you can put local images anywhere in the `/content` folder.\n\n```markdown\nExample image (source is in content/notes/images/example.png)\n![Example Image](/content/notes/images/example.png)\n```\n\nYou can also use wikilinks if that is what you are more comfortable with!\n\n### Front Matter\nHugo is picky when it comes to metadata for files. Make sure that your title is double-quoted and that you have a title defined at the top of your file like so. You can also add tags here as well.\n\n```yaml\n---\ntitle: \"Example Title\"\ntags:\n- example-tag\n---\n\nRest of your content here...\n```\n\n### Obsidian\nI recommend using [Obsidian](http://obsidian.md/) as a way to edit and grow your digital garden. It comes with a really nice editor and graphical interface to preview all of your local files.\n\nThis step is **highly recommended**.\n\n\u003e 🔗 Step 3: [How to setup your Obsidian Vault to work with Quartz](notes/obsidian.md)\n\n## Previewing Changes\nThis step is purely optional and mostly for those who want to see the published version of their digital garden locally before opening it up to the internet. This is *highly recommended* but not required.\n\n\u003e 👀 Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n\nFor those who like to live life more on the edge, viewing the garden through Obsidian gets you pretty close to the real thing.\n\n## Publishing Changes\nNow that you know the basics of managing your digital garden using Quartz, you can publish it to the internet!\n\n\u003e 🌍 Step 5: [Hosting Quartz online!](notes/hosting.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/notes/obsidian":{"title":"Obsidian Vault Integration","content":"\n## Setup\nObsidian is the preferred way to use Quartz. You can either create a new Obsidian Vault or link one that your already have.\n\n### New Vault\nIf you don't have an existing Vault, [download Obsidian](https://obsidian.md/) and create a new Vault in the `/content` folder that you created and cloned during the [setup](notes/setup.md) step.\n\n### Linking an existing Vault\nThe easiest way to use an existing Vault is to copy all of your files (directory and hierarchies intact) into the `/content` folder.\n\n## Settings\nGreat, now that you have your Obsidian linked to your Quartz, let's fix some settings so that they play well.\n\nOpen Settings \u003e Files \u0026 Links and look for these two items:\n\n1. Set the **New link format** to **Absolute Path in vault**.\n2. Turn **on** the **Automatically update internal links** setting.\n\n![Obsidian Settings](/notes/images/obsidian-settings.png)*Obsidian Settings*\n\n## Templates\nInserting front matter everytime you want to create a new Note gets annoying really quickly. Luckily, Obsidian supports templates which makes inserting new content really easily.\n\n**If you decide to overwrite the `/content` folder completely, don't remove the `/content/templates` folder!**\n\nHead over to Options \u003e Core Plugins and enable the Templates plugin. Then go to Options \u003e Hotkeys and set a hotkey for 'Insert Template' (I recommend `[cmd]+T`). That way, when you create a new note, you can just press the hotkey for a new template and be ready to go!\n\n\u003e 👀 Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/notes/preview-changes":{"title":"Preview Changes","content":"\nIf you'd like to preview what your Quartz site looks like before deploying it to the internet, the following\ninstructions guide you through installing the proper dependencies to run it locally.\n\n\n## Install `hugo-obsidian`\nThis step will generate the list of backlinks for Hugo to parse. Ensure you have [Go](https://golang.org/doc/install) (\u003e= 1.16) installed.\n\n```bash\n# Install and link `hugo-obsidian` locally\ngo install github.com/jackyzha0/hugo-obsidian@latest\n```\n\nIf you are running into an error saying that `command not found: hugo-obsidian`, make sure you set your `GOPATH` correctly! This will allow your terminal to correctly recognize hugo-obsidian as an executable.\n\nAfterwards, start the Hugo server as shown above and your local backlinks and interactive graph should be populated!\n\n##  Installing Hugo\nHugo is the static site generator that powers Quartz. [Install Hugo with \"extended\" Sass/SCSS version](https://gohugo.io/getting-started/installing/) first. Then,\n\n```bash\n# Navigate to your local Quartz folder\ncd \u003clocation-of-your-local-quartz\u003e\n\n# Start local server\nmake serve\n\n# View your site in a browser at http://localhost:1313/\n```\n\n\u003e [!INFO] Docker Support\n\u003e\n\u003e If you have Docker installed already, open your terminal, navigate to your folder with Quartz and run `make docker`\n\nNow that you are happy with how your Quartz instance looks, let's get it hosted!\n\n\u003e 🌍 Step 5: [Hosting Quartz online!](notes/hosting.md)\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/notes/search":{"title":"Search","content":"\nQuartz supports two modes of searching through content.\n\n## Full-text\nFull-text search is the default in Quartz. It produces results that *exactly* match the search query. This is easier to setup but usually produces lower quality matches.\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nenableSemanticSearch: false\n```\n\n## Natural Language\nNatural language search is powered by [Operand](https://beta.operand.ai/). It understands language like a person does and finds results that best match user intent. In this sense, it is closer to how Google Search works.\n\nNatural language search tends to produce higher quality results than full-text search.\n\nHere's how to set it up.\n\n1. Login or Register for a new Operand account. Click the verification link sent to your email, and you'll be redirected to the dashboard. (Note) You do not need to enter a credit card to create an account, or get started with the Operand API. The first $10 of usage each month is free. To learn more, see pricing. If you go over your free quota, we'll (politely) reach out and ask you to configure billing.\n2. Create your first index. On the dashboard, under \"Indexes\", enter the name and description of your index, and click \"Create Index\". Note down the ID of the index (obtained by clicking on the index name in the list of indexes), as you'll need it in the next step. IDs are unique to each index, and look something like `uqv1duxxbdxu`.\n3. Click into the index you've created. Under \"Index Something\", select \"SITEMAP\" from the dropdown and click \"Add Source\".\n4. For the \"Sitemap.xml URL\", put your deployed site's base URL followed by `sitemap.xml`. For example, for `quartz.jzhao.xyz`, put `https://quartz.jzhao.xyz/sitemap.xml`. Leave the URL Regex empty. \n5. Get your API key. On the dashboard, under \"API Keys\", you can manage your API keys. If you don't already have an API key, click \"Create API Key\". You'll need this for the next step.\n6. Open `data/config.yaml`. Set `enableSemanticSearch` to `true`, `operandApiKey` to your copied key, and `operandIndexId` to the ID of the index we created from earlier..\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nsearch:\n  enableSemanticSearch: true\n  operandApiKey: \"jp9k5hudse2a828z98kxd6z3payi8u90rnjf\"\n  operandIndexId: \"s0kf3bd6tldw\"\n```\n7. Push your changes to the site and wait for it to deploy.\n8. Check the Operand dashboard and wait for your site to index. Enjoy natural language search powered by Operand!\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null},"/notes/troubleshooting":{"title":"Troubleshooting and FAQ","content":"\nStill having trouble? Here are a list of common questions and problems people encounter when installing Quartz.\n\nWhile you're here, join our [Discord](https://discord.gg/cRFFHYye7t) :)\n\n### Does Quartz have Latex support?\nYes! See [CJK + Latex Support (测试)](notes/CJK%20+%20Latex%20Support%20(测试).md) for a brief demo.\n\n### Can I use \\\u003cObsidian Plugin\\\u003e in Quartz?\nUnless it produces direct Markdown output in the file, no. There currently is no way to bundle plugin code with Quartz.\n\nThe easiest way would be to add your own HTML partial that supports the functionality you are looking for.\n\n### My GitHub pages is just showing the README and not Quartz\nMake sure you set the source to deploy from `master` (and not `hugo`) using `/ (root)`! See more in the [hosting](/notes/hosting) guide\n\n### Some of my pages have 'January 1, 0001' as the last modified date\nThis is a problem caused by `git` treating files as case-insensitive by default and some of your posts probably have capitalized file names. You can turn this off in your Quartz by running this command.\n\n```shell\n# in the root of your Quartz (same folder as config.toml)\ngit config core.ignorecase true\n\n# or globally (not recommended)\ngit config --global core.ignorecase true\n```\n\n### Can I publish only a subset of my pages?\nYes! Quartz makes selective publishing really easy. Heres a guide on [excluding pages from being published](notes/ignore%20notes.md).\n\n### Can I host this myself and not on GitHub Pages?\nYes! All built files can be found under `/public` in the `master` branch. More details under [hosting](notes/hosting.md).\n\n### `command not found: hugo-obsidian`\nMake sure you set your `GOPATH` correctly! This will allow your terminal to correctly recognize `hugo-obsidian` as an executable.\n\n```shell\n# Add the following 2 lines to your ~/.bash_profile\nexport GOPATH=/Users/$USER/go\nexport PATH=$GOPATH/bin:$PATH\n\n# In your current terminal, to reload the session\nsource ~/.bash_profile\n```\n\n### How come my notes aren't being rendered?\nYou probably forgot to include front matter in your Markdown files. You can either setup [Obsidian](notes/obsidian.md) to do this for you or you need to manually define it. More details in [the 'how to edit' guide](notes/editing.md).\n\n### My custom domain isn't working!\nWalk through the steps in [the hosting guide](notes/hosting.md) again. Make sure you wait 30 min to 1 hour for changes to take effect.\n\n### How do I setup analytics?\nQuartz by default uses [Plausible](https://plausible.io/) for analytics. \n\nIf you would prefer to use Google Analytics, you can follow this [guide in the Hugo documentation](https://gohugo.io/templates/internal/#google-analytics). \n\nAlternatively, you can also import your Google Analytics data into Plausible by [following this guide](https://plausible.io/docs/google-analytics-import).\n\n\n### How do I change the content on the home page?\nTo edit the main home page, open `/content/_index.md`.\n\n### How do I change the colours?\nYou can change the theme by editing `assets/custom.scss`. More details on customization and themeing can be found in the [customization guide](notes/config.md).\n\n### How do I add images?\nYou can put images anywhere in the `/content` folder.\n\n```markdown\nExample image (source is in content/notes/images/example.png)\n![Example Image](/content/notes/images/example.png)\n```\n\n### My Interactive Graph and Backlinks aren't up to date\nBy default, the `linkIndex.json` (which Quartz needs to generate the Interactive Graph and Backlinks) are not regenerated locally. To set that up, see the guide on [local editing](notes/editing.md)\n\n### Can I use React/Vue/some other framework?\nNot out of the box. You could probably make it work by editing `/layouts/_default/single.html` but that's not what Quartz is designed to work with. 99% of things you are trying to do with those frameworks you can accomplish perfectly fine using just vanilla HTML/CSS/JS.\n\n## Still Stuck?\nQuartz isn't perfect! If you're still having troubles, file an issue in the GitHub repo with as much information as you can reasonably provide. Alternatively, you can message me on [Twitter](https://twitter.com/_jzhao) and I'll try to get back to you as soon as I can.\n\n🐛 [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n","lastmodified":"2023-03-02T18:25:17.331875087Z","tags":null}}