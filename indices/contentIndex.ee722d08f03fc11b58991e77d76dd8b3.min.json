{"/":{"title":"M Garden.","content":"\nWelcome to my second brain where I store my notes on the topics that I am currently studying. \n\n\u003e [!info]\n\u003e This site contains works from other authors! \n\nMostly my blogs will be about:\n1. [AWS](Cloud%20Computing/AWS/AWS.md)\n2. [Azure](Cloud%20Computing/Azure/Azure.md)\n3. [Cyber Security](Cyber%20Security/Cyber%20Security.md)\n4. [Terraform](DevOps/IAC/Terraform/Terraform.md)\n5. [Docker](Microservice%20Architecture/Docker/Docker.md)\n6. [Linux](Cyber%20Operations/Operation%20Tools/Linux.md)\n7. [IaC](DevOps/IAC/IaC.md)\n8. [Kubernetes](Microservice%20Architecture/Kubernetes/Kubernetes.md)","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Cloud-Computing/AWS/AWS":{"title":"AWS","content":"\nAWS (Amazon Web Services) is one of the comprehensive, [](Cloud%20Computing/Cloud%20Providers.md#Cloud%20Providers) AWS services can offer an organization tools such as compute power, database storage and content delivery services.\n\nAWS launched in 2006 from the internal infrastructure that Amazon.com built to handle its online retail operations. AWS was one of the first companies to introduce a [pay-as-you-go](https://www.techtarget.com/searchstorage/definition/pay-as-you-go-cloud-computing-PAYG-cloud-computing) cloud computing model that [scales](https://www.techtarget.com/searchdatacenter/definition/scalability) to provide users with compute, storage or throughput as needed.\n\nAWS offers many different tools and solutions for enterprises and software developers that can be used in data centers in up to 190 countries. Groups such as government agencies, education institutions, nonprofits and private organizations can use AWS services.\n[Elastic Compute Cloud EC2](Cloud%20Computing/AWS/Compute/Elastic%20Compute%20Cloud%20EC2.md)\n\n\n## AWS Global Infrastructure\n\n### Regions\n**Geographically distinct** Location with AWS datacentres clustered around multiple [#Avilability Zones AZ](#Avilability%20Zones%20AZ) within the same region. There are 22 Geographic Regions set up by AWS all around the world.\n\n- 22 Regions\n- Largest region = US-EAST\n- US-EAST-1 (North Virginia) is the region where you see all of your billing information\n\n\n![AWS Regions map](Cloud%20Computing/AWS/AWS%20Regions%20map.png)\n\n### Avilability Zones [AZ]\n\nOne or more Datacenters within a AWS Region.\n\nThere are total of 69 AZ Spread all around the world.\n\n- 69 AZs\n- At least 2 AZs in a single regions\n- Aming for 3 AZs per region\n- Latency between AZ is sub 10 milliseconds\n\n![AZs in a region of EU-AF](Cloud%20Computing/AWS/AZs%20in%20a%20region%20of%20EU-AF.png)\n\n\n### Edge Locations\nData Centers owned by AWS or partners used for accelerating data access across the world. It as direct connection to the AWS network.\n\n\n- Many Edge locations (~225)\n- To upload/download data fast\n- Serves requests for CloudFront and Route 53\n- [S3](Cloud%20Computing/AWS/Storage/S3.md) Transfer Acceleration traffic and API Gateway endpoint traffic also utilizes edge locations\n\n\n### GovCloud (US)\n\nAWS GovCloud Region allow customers to host sensitive **Controlled Unclassified Information** and other types of regulated workload.\n\n- GovCloud Regions are only operated by employees who are US citizens, on US soil.\n- So they are exclusively for US\n- Made for customers who require secure solutions that comply with us government regulations\n\n\n\n---\n\n\n## Services\n\n![AWS service and resources](Cloud%20Computing/AWS/AWS%20service%20and%20resources.png)\n\n\n### Free Services:\n\n1. IAM\n2. VPC\n3. Organizations \u0026 Consolidated Billing \n4. AWS Cost Explorer \n5. Auto Scaling\n6. CloudFormation\n7. Elastic Beanstalk\n8. Opswork\n9. Amplify\n10. AppSync\n11. CodeStar\n\n### Business Centric Services\n![Pasted image 20220706225126](Cloud%20Computing/Pasted%20image%2020220706225126.png)\n\n\n\n## AWS Support Plans\n![Pasted image 20220706164829](Cloud%20Computing/Pasted%20image%2020220706164829.png)\n\n## AWS Marketplace\n","lastmodified":"2023-03-02T22:23:38.741537917Z","tags":null},"/Cloud-Computing/AWS/AWS-CLI-SDK":{"title":"AWS CLI \u0026 SDK","content":"# AWS CLI\n#aws #cli\n\nA [CLI](CLI) tool by [AWS](Cloud%20Computing/AWS/AWS.md) to controll aws resources via command line. It requires user credentials to perform actions to the account in which the credentials are valid and authorized to perform equivalent console based actions.\n\nLets users interact with AWS form a command line.\nThe CLI is installed via a Python Script.\n\n\n# AWS SDK\n#aws #sdk\n\nA set of tools and libraries that you can use to create applcation sfor a specific software package\n\nThe AWS SDK is a set of API libraries that let you Integrate AWS services into your applications. The SDK is available on the following languages:\n\n1. C++\n2. Go\n3. Java\n4. JavaScript\n5. .NET\n6. NodeJS\n7. PHP\n8. Python (boto3)\n9. Ruby\n\n\n\n## Programmatic Access - Access Key and Secret\n\nTo access the AWS CLI and SDK, this is required for authenticating the making from which the user is trying to apply those commands and access the AWS resources.\n\nthe credentials get stored in a plain-text file. `~/.aws/credentials`\n\nwhenever possible use roles instead of AWS credentials for the programmatic access.\n\nProgrammatic access must be enabled for the user to use the [#AWS CLI](#AWS%20CLI) or [#AWS SDK](#AWS%20SDK)\n\n\n\n","lastmodified":"2023-03-02T22:23:38.737537903Z","tags":null},"/Cloud-Computing/AWS/Application-Integration/CloudFormation":{"title":"CloudFormation","content":"# CloudFormation\n#aws  #IaC #cloud\n\n\nA templating Language to write infrastructure configuration as code offered by [AWS](Cloud%20Computing/AWS/AWS.md)\n\n![Pasted image 20220724014004](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724014004.png)\n\n![Pasted image 20220724014404](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724014404.png)","lastmodified":"2023-03-02T22:23:38.741537917Z","tags":null},"/Cloud-Computing/AWS/Application-Integration/Kinesis":{"title":"Kinesis","content":"# Kinesis\n#aws #cloud #serverless #dataanalytics \n\nFamily of services to collect, process and analyze streaming data in real-time by [AWS](Cloud%20Computing/AWS/AWS.md).\n\n  \n\nStreaming data is simply data continuously generated by many data sources sending a small amount of information simultaneously. (Think of harvesting rainwater)\n\n  \n\nDeals with moving data (streaming data) similar to Kafka.  \n\n  \n  \n\n![](https://lh3.googleusercontent.com/fqvPvTF6jvixi1dlnkoD1ownxLkJ4b6HO0PNA-PlkpBL8oKeMh1fR-VEQemZQrlDuVSShMgUTHhLS35knJ_c2meCBddV6Ye71wJvq9gVVM0l69UjO9voJKltwrGhmccYH6K20O5Vl12If1GGnWMl-A)\n\n# ![](https://lh3.googleusercontent.com/7awo3t9K42epjV4VL7EpB-A4WTwaQA_wfGyqZb_OpOhceDwOqin6cqEn6HC04rxs9DHf15TSeY74xK2ErVS5nelWilvrZjDUgRiftJTtge379QoL0xYvkNVD-XPpIid4JzPRi6nXKGAtFDVMyVKGcQ)\n\n  \n\n## Kinesis Streams\n\nEnables us to stream data and video. (Kinesis Data Streams and Kinesis Video Streams).\n\n(Eg recording online meeting video, Game score in real-time).\n\nUses Shards, retains data, and requires Consumers.\n\n### Kinesis Data Stream\n  \n![Pasted image 20220724152204](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724152204.png)\n\n### Kinesis Video Streams\n![Pasted image 20220724152502](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724152502.png)\n\n## Kinesis Data Firehose\n\n- Load streaming data into AWS data stores for near-real-time analytics.  \n- No Shards, No Data retention, Optional Consumer and Automatic Capacity\n- Consumers are optional. (can Chose only one consumer)\n- Data is not persisted\n- Can use Lambda for processing data.\n- Data is directly to the AWS store.\n- Inexpensive\n\n  ![Pasted image 20220724152311](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724152311.png)\n  \n  \n  \n\n## Kinesis Data Analytics\n\nFor real time analytics. You need to specify Data Firehose or Data Stream\n\nAllows running sql queries and stores the result on AWS datastore.\n\n  \n  \n\n# Kinesis Shards\n\nKinesis streams are made up of shards.\n\nData capacity of streams are determined by shards.\n\nEach shard is a sequence of one or more data records and provides a fixed unit of capacity.\n\n(read: 5 per second, 2MB per second) (write: 1000 per second, 1MB per second).\n\n  \n\n![](https://lh3.googleusercontent.com/9ULTmqXp9GDk4KADSNA8kaRFIRVcP7hTd4S2N__eBiMd8Ks_L1JbuN4GXf6KQ-8_U81aSy4k646YU4LL_NroE6axjaTS5WfOaDQ9SpVs_jFYEmzb52LxHK_cGdDNBo_9YxnmMJ_GoBZzzYCXfqc_Jw)\n\n  \n\n\n![Pasted image 20220724152615](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724152615.png)","lastmodified":"2023-03-02T22:23:38.741537917Z","tags":null},"/Cloud-Computing/AWS/Application-Integration/SNS":{"title":"SNS","content":"# AWS SNS\n#aws #cloud #notification\n\nA simple service by [AWS](Cloud%20Computing/AWS/AWS.md) enabling users to send notifications via SMS, Push notifications, or email. It can be used to send essential automated sms to the designated users.\n\nSuscribe and send notifications via text message, push notification,\n\n\n![Pasted image 20220724104926](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724104926.png)\n\n\n## SNS Topics\n\nTopics allows you to group multiple subscriptions together.\n\nA topic is able to deliver to multiple protocols at once eg. email, text message, http/s\n\n\n## SNS-Subscriptions\nA subscription can only subscribe to one protocol and one topic.\n\n![Pasted image 20220724124451](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724124451.png)","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Application-Integration/SQS":{"title":"SQS","content":"# SQS\n#aws #cloud #serverless #microservices  #decoupleing #queue\n\nFirst-ever [AWS](Cloud%20Computing/AWS/AWS.md) service that was made publicly available. (Oldest service). \nMessage Queue service enables web services applications to queue messages.\nActs like a buffer between the components between different components.\nCan set up an Autoscaling group to SQS which is a great practice.\nPick up messages using a “poll”.\nMostly used for pull-based operations.\n\n\n## Features\n-   Allow us to decouple the components of an application so that they are independent\n-   Pull based message store (Poll) (256 KB max size of the text in any format)\n-   Retrieve the messages using SQS API\n-   Text Data (XML, JSON and unformatted text)\n-   Guarantees that message will be processed at least once\n-   The default retention period is 4 days\n-   Max message retention time is 14 days\n\n\n## Visibility Timeout\n-   Default is 30 seconds\n-   If a message isn't processed within 30 seconds, the item will reappear\n-   You can increase the visibility Timeout.    \n-   Max timeout is 12 hours    \n\n  \n\n## Polling  \n![](https://lh3.googleusercontent.com/kX3LN5a7jK4UmacSq5znYiNFZuQL8dXL4uz-QOqbGQ_UR_aUdyJ3WCAm3NDREirE23EQX7IrfiTQWRzDBKjCvALs7qcJpaqMdEjaOKreRbHWKxe2Q8H54O4qlwSczdLOqCMbl1eYSFWGJCEUcr_Kag)\n\n\nSQS Delay Queue postpones delivery of new messages (makes them invisible)(0s-900s). It only affects standard queues but it will affect the whole FIFO Queue. (e.g. for confirming the order in E-commerce).\n\n  \n\nUsing S3 for large SQS message (256KB-2GB) (Amazon SQS Extended Client Library for Java, AWS SDK for java)\n\n**\n\nFully managed queing services that enables you to decouple a big complex architecture to a simpler one. It is primarily for Application integration.\n\npull based.\n\nMessege size can be between 1 byte to 256 KB\n\nExtended storage option is availabe on Java SDK which allows storage of message upto 2GB but will be required to be stored in S3.\n\nMessage retention by default is 4 days\n\nfrom min of 60 seconds to max of 14 days\n\n\n## Standard Queues\n![Pasted image 20220724103848](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724103848.png)\nAllows nearly-unlimited number of transactions per second\nGuarantees that a message will be delivered at least once.\nWhich means more than one copy of message could be potentially delivered out of order.\nProvides best-effort ordering that helps ensure a message is generally delivered in the same order that it was sent.\n\n\n## FIFO Queue\n![Pasted image 20220724104025](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724104025.png)\n\nsupports multiple ordered message groups within a single queue\nLimited to 300 transactions per second\nHave all of the capabilities of a standard queue.\n\n## Visibility Timeout\nTo prevent another app from reading a message which is already being processed by another app. This help\n\n\n## polling\n![Pasted image 20220724104406](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724104406.png)\n\n\n\n![Pasted image 20220724104428](Cloud%20Computing/AWS/Application%20Integration/Pasted%20image%2020220724104428.png)","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Compute/Bastion":{"title":"Bastion","content":"# Bastion\n#aws #ec2 #cloud #compute \nalso known as Jump-box\n\nBastions are [Elastic Compute Cloud EC2](Cloud%20Computing/AWS/Compute/Elastic%20Compute%20Cloud%20EC2.md) instances which are security harden. They are designed to help you gain access to your EC2 via SSH or RCP that are in private subnet which are not directly accessible from the internet.\n\nThey are also known as Jump Boxes.\n\nNAT Gateways/ Instances are only intended for EC2 instances to gain outbound access to the internet for things such as security updates. NATs cannot/should not be used as bastions.\n\nSystems Manager's SSM provides an alternative to the bastion hosts.\n\n\n\nA bastion host is a special-purpose computer on a network specifically designed and configured to withstand attacks, so named by analogy to the military fortification. The computer generally hosts a single application or process, for example, a proxy server or load balancer, and all other services are removed or limited to reduce the threat to the computer. It is hardened in this manner primarily due to its location and purpose, which is either on the outside of a firewall or inside of a demilitarized zone ([DMZ](Cyber%20Security/Cloud%20Security/DMZ.md)) and usually involves access from untrusted networks or computers. These computers are also equipped with special networking interfaces to withstand high-bandwidth attacks through the internet.\n\n\nMost often the [security group](Cloud%20Computing/AWS/Compute/security%20group.md) of the bastion is added to the security group of the instance to be accessed. This is the","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Compute/EC2-Spot":{"title":"EC2 Spot","content":"# EC2 Spot Instances\n#aws #compute #ec2 \n\n[AWS](Cloud%20Computing/AWS/AWS.md) Provides a cheaper alternative compute solution in [Elastic Compute Cloud EC2](Cloud%20Computing/AWS/Compute/Elastic%20Compute%20Cloud%20EC2.md) for non important tasks. AWS markets them as \"Amazon _EC2 Spot instances_ are spare compute capacity in the AWS cloud available to you at steep discounts compared to On-Demand prices.\" ","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Compute/ECS":{"title":"ECS","content":"# ECS (Elastic Container Service)\n#aws #cloud #containers \n\nAmazon ECS is a fully managed [Container orchestration](Container%20orchestration) service by [AWS](Cloud%20Computing/AWS/AWS.md) that helps you easily deploy, manage, and scale containerized applications. It deeply integrates with the rest of the AWS platform to provide a secure and easy-to-use solution for running [container](container) workloads in the cloud and now on your infrastructure with Amazon ECS Anywhere.\n![Pasted image 20230103141505](Microservice%20Architecture/Attachments/Pasted%20image%2020230103141505.png)","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Compute/EKS":{"title":"EKS","content":"# EKS (Elastic Kubernetes Service)\n#aws #cloud #Kubernetes #managed-kubernetes-cluster \n\nAmazon EKS is a managed [Kubernetes](Microservice%20Architecture/Kubernetes/Kubernetes.md) service to run Kubernetes in the [AWS](Cloud%20Computing/AWS/AWS.md) cloud and on-premises data centers. In the cloud, Amazon EKS automatically manages the availability and scalability of the Kubernetes control plane nodes responsible for scheduling containers, managing application availability, storing cluster data, and other key tasks. With Amazon EKS, you can take advantage of all the performance, scale, reliability, and availability of AWS infrastructure, as well as integrations with AWS networking and security services. On-premises, EKS provides a consistent, fully-supported Kubernetes solution with integrated tooling and simple deployment to AWS Outposts, virtual machines, or bare metal servers.","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Compute/Elastic-Compute-Cloud-EC2":{"title":"Elastic Compute Cloud EC2","content":"# EC2\n\n#aws #cloud #compute \n\nThe Amazon Elastic Compute Cloud, is an [AWS](Cloud%20Computing/AWS/AWS.md) platform for providing cloud-based compute capacity. That means it provides virtual machines in the sky. Where [S3](Cloud%20Computing/AWS/Storage/S3.md) is cloud storage and [RDS](Cloud%20Computing/AWS/Databases/RDS.md) is cloud relational databases, EC2 gives you a machine where you can run anything you want. Want to run a web server, EC2 can do that. Want to run a database, EC2 can do that.  \n-   AWS Elastic Compute Cloud is a computing web service which provides re-sizeable, secure, and reliable capacity in the cloud\n-   You have complete control of your EC2 computing resources.\n-   You can scale up or scale down the capacity of your EC2 resources as your technical requirements change\n-   You must pay only for EC2 resources that you use\n-   You can build and boot new computing instances in only some little minutes\n\n## Instance Types\n![Pasted image 20220722150557](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220722150557.png)\n\n## Instance Size\n\n## Instance Categories\n\n![EC2 state transfer characteistics](Cloud%20Computing/AWS/EC2%20state%20transfer%20characteistics.png)\n\n## Instance Pricing\n\n![Pasted image 20220706163457](Cloud%20Computing/Pasted%20image%2020220706163457.png)\n\n\n## Instance Status\n![EC2 states](Cloud%20Computing/AWS/EC2%20states.png)\n\n\n## Placement Groups\n\nPlacement Groups lets you choose the logical placement of your instances to optimize for communication, performance or durability. Placement groups are free\n![Pasted image 20220722151020](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220722151020.png)\n\n\n## Userdata\nA simple bash script that will be run automatically while launching the EC2 instance. \n\n\n## Metadata\nAdditional information about the current EC2 instance which you can get from the instance. Can be accessed via http://169.254.169.254/latest/meta-data.\n\n## AMI\nAmazon Machine Image (AMI) provides the information required to launch an instance. We can turn EC2 instances into AMIs to make copies of your servers. We can create an ami from an running or stopped ec2 instance. While launching a new instance we will need to pick an AMI with the operating systems and configurations of our choice. AMIs have different IDs on different regions. We can make copies of our AMIs which will let you transport AMIs to other regions or even accounts using `copy ami` command.\n\n**Use cases:**\n1. Help you keep incremental changes to your OS, application code and system packages.\n2. Can be configured with Systems Manager Automation to routinely patch your AMIs with security updates\n3. Is required to launch new instances in the autoscaling groups as it is required to create a launch configuration/launch template.\n\n\n## Storage Options\n\n\n## Network Options\n\n\n## Security Options\n\n### Instance Profile\nInstead of embedding your AWS access key, you can attach a role to an instance via an Instance Profile. It holds a reference to a role. The EC2 instance is associated with the Instance Profile. Basically a container for an IAM role that you can use to pass role information to an EC2 instance when the instance starts.\n\n\n## Elastic Load Balance\n\n\n## Auto Scaling Groups\nSet scaling rules which will add or reduce ec2 instance in an group to meet the demand of the traffic. \n\n### ASG-Capacity Settings\n\nThe size of tan ASG is based on Min, Max and Desired Capacity.\n\nASG will always launch instances to meet minimum capacity.\n\n\n### Health Check Replacements\n\n#### 1. EC2 Health Check\n[EC2 health check](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html) watches for instance availability from hypervisor and networking point of view. For example, in case of a hardware problem, the check will fail. Also, if an instance was misconfigured and doesn't respond to network requests, it will be marked as faulty.\n\n#### 2. ELB Health Check\n[ELB health check](http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html) verifies that a specified TCP port on an instance is accepting connections OR a specified web page returns 2xx code. Thus ELB health checks are a little bit smarter and verify that actual app works instead of verifying that just an instance works.\n\n#### 3. Custom Health Check\nIf your application can't be checked by simple HTTP request and requires advanced test logic, you can implement a custom check in your code and set instance health though API: [Health Checks for Auto Scaling Instances](http://docs.aws.amazon.com/autoscaling/latest/userguide/healthcheck.html)\n\n### Scaling Polices\nScale out or in to add or remove instances in an ASG.\nAmazon’s EC2 Auto Scaling provides an effective way to ensure that your infrastructure is able to dynamically respond to changing user demands. For example, to accommodate a sudden traffic increase on your web application, you can set your Auto Scaling group to automatically add more instances. And when traffic is low, have it automatically reduce the number of instances. This is a cost-effective solution since it only provisions EC2 instances when you need them. EC2 Auto Scaling provides you with several dynamic scaling policies to control the scale-in and scale-out events.\n\n#### 1. Simple Scaling\nSimple scaling relies on a metric as a basis for scaling. For example, you can set a CloudWatch alarm to have a CPU Utilization threshold of 80%, and then set the scaling policy to add 20% more capacity to your Auto Scaling group by launching new instances. Accordingly, you can also set a CloudWatch alarm to have a CPU utilization threshold of 30%. When the threshold is met, the Auto Scaling group will remove 20% of its capacity by terminating EC2 instances. \n\nWhen EC2 Auto Scaling was first introduced, this was the only scaling policy supported. It does not provide any fine-grained control to scaling in and scaling out.\n\n#### 2. Target Tracking\nTarget tracking policy lets you specify a scaling metric and metric value that your auto scaling group should maintain at all times. Let’s say for example your scaling metric is the average CPU utilization of your EC2 auto scaling instances, and that their average should always be 80%. When CloudWatch detects that the average CPU utilization is beyond 80%, it will trigger your target tracking policy to scale out the auto scaling group to meet this target utilization. Once everything is settled and the average CPU utilization has gone below 80%, another scale in action will kick in and reduce the number of auto scaling instances in your auto scaling group. With target tracking policies, your auto scaling group will always be running in a capacity that is defined by your scaling metric and metric value.\n\n#### 3. Step Scaling\nStep Scaling further improves the features of simple scaling. Step scaling applies “step adjustments” which means you can set multiple actions to vary the scaling depending on the size of the alarm breach. \n\nWhen a scaling event happens on simple scaling, the policy must wait for the health checks to complete and the cooldown to expire before responding to an additional alarm. This causes a delay in increasing capacity especially when there is a sudden surge of traffic on your application. With step scaling, the policy can continue to respond to additional alarms even in the middle of the scaling event. \n\nHere is an example that shows how step scaling works:\n\n![Step Scaling vs Simple Scaling Policies in Amazon EC2](https://td-mainsite-cdn.tutorialsdojo.com/wp-content/uploads/2020/06/Step-Scaling1.jpg)","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Compute/Elastic-Load-Balancer-ELB":{"title":"Elastic Load Balancer (ELB)","content":"# Elastic Load balancer (ELB)\n#aws #cloud #vpc #networking #loadbalancer\n\nLoadbalancer service provided by [AWS](Cloud%20Computing/AWS/AWS.md)\n\nElastic Load Balancing supports the following types of load balancers: **Application Load Balancers, Network Load Balancers, and Classic Load Balancers**.\n\n## Common Features\n\nLet’s start by taking a look at what is common for all three types of load balancers. \n\nObviously, all AWS load balancers distribute incoming requests to a number of targets, which can be either EC2 instances or Docker containers. They all implement health checks, which are used to detect unhealthy instances. They are all highly available and elastic (in AWS parlance: They scale up and down within a few minutes according to workload). \n\nTLS termination is a feature available for all three as well, and they can all be either internet-facing or internal. Finally, ELB, ALB, and NLB all export useful metrics to CloudWatch and can log pertinent information to CloudWatch Logs.\n\n![Pasted image 20220723213315](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220723213315.png)\n\n\n# Classic Load Balancer (CLB)\n\nWidely known as CLB it was the original Elastic Load Balancer, as this was its name when it was first introduced in 2009 and was the only type of load balancer available. It can be thought of as an Nginx or HAProxy instance if that makes it easier for you to understand.\n\nELB works at both layer 4 (TCP) and 7 (HTTP) but not on the same time. It is the only load balancer that works in EC2-Classic, in case you have a very old AWS account. Also, it’s the only load balancer that supports application-defined sticky session cookies; in contrast, ALB uses its own cookies, and you have no control over that.\n\nAt layer 7, ELB can terminate TLS traffic. It can also re-encrypt the traffic to the targets as long as they provide an SSL certificate (a self-signed certificate is fine, BTW). This provides end-to-end encryption, which is a usual requirement in many compliance programs. Optionally, ELB can be configured to verify the TLS certificate provided by the target for extra security.\n\nELB has quite a few limitations. For example, it isn’t compatible with EKS containers running on Fargate. Also, it can’t forward traffic on more than one port per instance, and it doesn’t support forwarding to IP addresses—it can only forward to explicit EC2 instances or containers in ECS or EKS. Finally, ELB doesn’t support websockets; however, you may be able to work around this limitation by using layer 4.\n\nTo run an ELB in the us-east-1 region, it will cost you $0.025 per ELB-hour + $0.008 per GB of traffic.\n\nAWS discourages the use of ELB in favor of its newer load balancers. Admittedly, there are very few scenarios where the use of an ELB would be preferable; typically, these are cases where you simply don’t have a choice. For example, your workload might still run on [EC2-Classic](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-classic-platform.html), or you need the load balancer to use your own sticky session cookies, in which cases ELB would be the only option available to you.\n\n\n\n## Application Load Balancer (ALB)\n\nIt works only on layer 7 (HTTP) of the [OSI](Networking/OSI.md). It has a wide range of routing rules for incoming requests based on host name, path, query string parameter, HTTP method, HTTP headers, source IP, or port number. In contrast, ELB only allows routing based on port number. Also, contrary to ELB, ALB can route requests to many ports on a single target. Plus, ALB can route requests to Lambda functions.\n\nIt has a feature called Request Routing which allows you to add routing rules to your application.\n\nA very useful feature of ALB is that it can be configured to return a fixed response or a redirection. So you don’t need a server to perform such basic tasks because it is all embedded in the ALB itself. Also very importantly, ALB supports HTTP/2 and websockets.\n\nALB further supports [Server Name Indication (SNI)](https://www.cloudflare.com/learning/ssl/what-is-sni/), which allows it to serve many domain names. (In contrast, ELB can serve only one domain name). There is a limit, however, to the number of certificates you can attach to an ALB, [namely 25 certificates](https://aws.amazon.com/blogs/aws/new-application-load-balancer-sni/) plus the default certificate.\n\nAn interesting feature of ALB is that it supports user authentication via a variety of methods, including OIDC, SAML, LDAP, Microsoft AD, and well-known social identity providers such as Facebook and Google. This can help you off-load the user authentication part of your application to the load balancer. \n\nALB pricing is a bit more complicated than ELB. For the us-east-1 region, it would cost you $0.0225 per ALB + $0.008 per LCU-hour. The definition of an LCU can be found [here](https://aws.amazon.com/elasticloadbalancing/pricing/). All in all, pricing is roughly equivalent to ELB.\n\nALBs are typically used for web applications. If you have a microservices architecture, ALB can be used as an internal load balancer in front of EC2 instances or Docker containers that implement a given service. You can also use them in front of an application implementing a REST API, although [AWS API Gateway](https://aws.amazon.com/api-gateway/) would generally be a better choice here.\n\n## Network Load Balancer\n\nNLB works on the layer 4 of the [OSI model](OSI%20model) only and can handle both TCP and UDP, as well as TCP connections encrypted with TLS. Its main feature is that it has a very high performance. Also, it uses static IP addresses and can be assigned Elastic IPs—not possible with ALB and ELB.\n\nNLB natively preserves the source IP address in TCP/UDP packets; in contrast, ALB and ELB can be configured to add additional HTTP headers with forwarding information, and those have to be parsed properly by your application.\n\nNLB pricing for the us-east-1 region is $0.0225 per NLB-hour + $0.006 per LCU-hour. The definition of an LCU for NLB is quite similar to that for ALB, and more information can be found [here](https://aws.amazon.com/elasticloadbalancing/pricing/). All in all, pricing is roughly equivalent to ELB and ALB.\n\nNLBs would be used for anything that ALBs don’t cover. A typical use case would be a near real-time data streaming service (video, stock quotes, etc.) Another typical case is that you would need to use an NLB if your application uses non-HTTP protocols.\n\n## Sticky Session\n\nA method to bind a user's session to a specific EC2 session.\ncan only be applied to CLB or ALBs\n\nIt ensures that all requests from that session are sent to the same instance. It is Typically utilized with a Classic Load Balancer\n\n## X-Forwarded-For (XFF) Header\n\nIf you need the IPv4 address of a user, check this header.\n\nThis header is a common method for identifying the originating IP addresses of clients connecting to a web server through an HTTP proxy or a load balancer.\n\n![Pasted image 20220723214311](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220723214311.png)\n\n## ELB - Health Checks\n\n![Pasted image 20220723214425](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220723214425.png)\n\n\n## Cross-Zone Load Balancing\n![Pasted image 20220723214447](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220723214447.png)\n\n\n## ALB - Request Routing\n\nApply riles to incomming request and then forward or redirect traffic\n\n- Host header\n- HTTP header\n- Source IP\n- HTTP header method\n- Path\n- Query string\n![Pasted image 20220723214622](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220723214622.png)\n\n\n\n![Pasted image 20220723214636](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220723214636.png)","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Compute/Lambda":{"title":"Lambda","content":"# Lambda\n#aws #cloud #serverless #compute #development \n\n\nRun code without provisioning or managing servers in [AWS](Cloud%20Computing/AWS/AWS.md).\n\nLambda executes your code only when needed and scales automatically to a few to a 1000 lambda functions concurrently in seconds.\n\nPay only for the times the lambda function is invoked.\n\nLambda is **Cheap**, **Serverless**, and **Scales Automatically**.\n\n7 runtime languages are supported:\n\n1. Ruby\n2. Python\n3. Java\n4. Go\n5. Powershell\n6. Nodejs\n7. C#\n\n\n## Use Cases:\nLambda is used to glue different services together so the use cases are endless.\nExample of use cases are:\n1. Processing Thumbnails\n![Pasted image 20220724095845](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220724095845.png)\n2. Contact Email Form\n![Pasted image 20220724095857](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220724095857.png)\n\n\n## Triggers\nTO invoke a lambda it can be accomplished via the AWS SDK or from other AWS Services.\n\nIt can also be configured with 3rd party partner sources.\n\n\n## Pricing\nThe 1st million requests per month are free.\nThere-after $0.20 per additional 1 million requests\n\n400,000 GB seconds free per month\nThereafter $0.0000166667 for every GB second\n\neg. 128MB RAM X 30Mins pm X 200ms runtime per invokation = $5.83\n\n\n## Defaults and limits\nCan only have 1000 Lambda running concurrently, Ask AWS support for Limit Increase.\n\n/tmp directory can contain upto 500MB\n\nBy default Lambda run in No VPC. You can set them to by in your own VPC but your lambda will lose internet access.\n\nYou can set timeout to be a mazimu of 15 minutes.\n\nMemory can be set between 128MB to a mazimum of 2008MB at an increment of 64MB.\n\n\n## Cold Starts\nA negative trade-off on using server-less functions. At first when the lambda function has not been triggered and is on an turned off state, It will require some time to start the server. \n\nThis can cause delays in the User Experience.\n\nCan be addressed through Pre Warning.\n\n![Pasted image 20220724100910](Cloud%20Computing/AWS/Compute/Pasted%20image%2020220724100910.png)","lastmodified":"2023-03-02T22:23:38.773538031Z","tags":null},"/Cloud-Computing/AWS/Compute/Windows-Docker-on-AWS":{"title":"Windows Docker on AWS","content":"# Windows Container Docker on AWS\n#docker #windows #aws \n\n\nTo run windows containers in docker within [AWS](Cloud%20Computing/AWS/AWS.md), launch an [Elastic Compute Cloud EC2](Cloud%20Computing/AWS/Compute/Elastic%20Compute%20Cloud%20EC2.md)with an Windows_Server-2022-English-Core-ContainersLatest-2022.11.10\n![Pasted image 20230105145020](Microservice%20Architecture/Attachments/Pasted%20image%2020230105145020.png)\n\nMake sure to give it plenty of cpu and ram resources so it can peform well.\n\nThis will launch an Windows ec2 instance with docker container support.\n\n\nThe dotnet framework docker versions:\nhttps://hub.docker.com/_/microsoft-dotnet-framework-runtime/\n\n\nBlog  on configuring dotnet build with codebuild and docker:\nhttps://aws.amazon.com/blogs/devops/extending-aws-codebuild-with-custom-build-environments-for-the-net-framework/\n\n\nArticle found with demo of how to use docker CLI in Windows docker setup:\nhttps://web.archive.org/web/20220120042518/https://www.docker.com/blog/build-your-first-docker-windows-server-container/\n\nOneliner google chrome silent installer powershell:\nhttps://www.snel.com/support/install-chrome-in-windows-server/\n\n\nCommand to switch from windows container \u003c\u003e linux containers: \n(This method Didin't work for the mirantis)\nhttps://forums.docker.com/t/cli-to-switch-between-linux-and-windows-images/30297\n\nExtensive article on using docker within WSL (useful for linux containers):\nhttps://dev.to/_nicolas_louis_/how-to-run-docker-on-windows-without-docker-desktop-hik\n\n\n## Docker containers for windows on aws codepipeline\nhttps://aws.amazon.com/blogs/devops/building-windows-containers-with-aws-codepipeline-and-custom-actions/#:~:text=AWS%20CodeBuild%20supports%20Windows%20builds,NET%20Framework%20SDK%20installed).\n\n### Limitations: (????)\n-   AWS CodeBuild executes Windows Server containers using Windows Server 2016 hosts, which means that build containers are huge—it is not uncommon to have an image size of 15 GB or more (with .NET Framework SDK installed). Windows Server 2019 containers, which are almost half as small, cannot be used due to host-container mismatch. (???)\n\n-   AWS CodeBuild runs build jobs inside Docker containers. You should [enable privileged mode](https://docs.aws.amazon.com/codebuild/latest/APIReference/API_ProjectEnvironment.html) in order to build and publish Linux Docker images as part of your build job. However, [DIND is not supported on Windows](https://github.com/docker-library/docker/issues/49) and, therefore, AWS CodeBuild cannot be used to build Windows Server container images. (???)\n\nThe last point is the critical one for microservice type of applications based on Microsoft stacks (.NET Framework, Web API, IIS). The usual workflow for this kind of applications is to build a Docker image, push it to ECR and update ECS / EKS cluster deployment.\n\n\n## Custom AWS codebuild with ephemeral windows container envs:\nhttps://github.com/aws-samples/aws-codepipeline-custom-action\n\nhttps://aws.amazon.com/blogs/devops/building-windows-containers-with-aws-codepipeline-and-custom-actions/#:~:text=AWS%20CodeBuild%20supports%20Windows%20builds,NET%20Framework%20SDK%20installed\n\n## ALT:\nhttps://aws.amazon.com/blogs/modernizing-with-aws/building-windows-containers-with-aws-codepipeline-on-aws-govcloud-us/\n\n\n\n\n## Windows containers:\n\nMore on what windows containers are:\nhttps://learn.microsoft.com/en-us/virtualization/windowscontainers/about/\n\nPreparing windows for containers:\nhttps://learn.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=containerd\n![Pasted image 20230106173933](Microservice%20Architecture/Attachments/Pasted%20image%2020230106173933.png)\n![Pasted image 20230106173955](Microservice%20Architecture/Attachments/Pasted%20image%2020230106173955.png)\nhttps://hub.docker.com/_/microsoft-dotnet-framework-runtime/\n![Pasted image 20230106182532](Microservice%20Architecture/Attachments/Pasted%20image%2020230106182532.png)\n\n\nwindows vs linux container service\n![Pasted image 20230106173745](Microservice%20Architecture/Attachments/Pasted%20image%2020230106173745.png)\n\n\nhttps://www.youtube.com/watch?v=RjwzADNGUUg\n\nhttps://drive.google.com/file/d/1KK56yO8XTgSZ7jTjstz1ZAFCM2a2co-0/view","lastmodified":"2023-03-02T22:23:38.793538102Z","tags":null},"/Cloud-Computing/AWS/Compute/security-group":{"title":"security group","content":"# Security Groups\n#aws #cloud \n\n[Defence In Depth](Cyber%20Security/Cloud%20Security/Defence%20In%20Depth.md)\n[Zero-Trust](Cyber%20Security/Cloud%20Security/Zero-Trust.md)\n[Elastic Compute Cloud EC2](Cloud%20Computing/AWS/Compute/Elastic%20Compute%20Cloud%20EC2.md)\n[RDS](Cloud%20Computing/AWS/Databases/RDS.md)\n[Elastic Load Balancer (ELB)](Cloud%20Computing/AWS/Compute/Elastic%20Load%20Balancer%20(ELB).md)","lastmodified":"2023-03-02T22:23:38.793538102Z","tags":null},"/Cloud-Computing/AWS/Databases/Aurora":{"title":"Aurora","content":"# Aurora\n#aws #cloud #rdbms #serverless #sql\n\nFully managed Postgres or MySQL database by [AWS](Cloud%20Computing/AWS/AWS.md).\n\nCombines the speed and availability of high end database with the simplicity and cost-effectiveness of opensource databases\n\n## Aurora Scaling\nStarts with 10GG of Storage, and scale in 10GB increments upto 64TB\n\nStorage is auto-scaling\n\nComputing resource can scale all the way upto 32 vCPUs and 244Gb of memory\n\n\n## Aurora-Availability\n\nA minimum of 3-availability zones each contain 2 copies of your database.\n\nso 6 copies are created. (2 copies in each availability zones)\n\n\n## Aurora-Fault Tolerance and Durability\nAurora Backup and Failover are handelled automatically\nSnapshots of Data can be shared with other AWS accounts\n\nStorage is self-healing, in that data blocks and disks are continiously scanned for errors and repaired automatically.\n\n## Aurora-Replicas\n\nThere are 2 types of replicas available:\n\n![Pasted image 20220724011616](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724011616.png)\n\n\n\n## Aurora-Serverless\n\nAurora except the database will automatically startup, shut-down, and scale capacity up or down based on your application's needs\n\nApps used a few times several times per day or week.. eg. low accessed databases.\n\npay for database storage and the database capacity and I/O your database consumes while it is active\n\n\n![Pasted image 20220724011843](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724011843.png)\n","lastmodified":"2023-03-02T22:23:38.793538102Z","tags":null},"/Cloud-Computing/AWS/Databases/DynamoDB":{"title":"DynamoDB","content":"# DynamoDB\n#aws #cloud #databases #nosql\n\nKey value and document database (NoSQL) solution by [AWS](Cloud%20Computing/AWS/AWS.md) which can guarantee consistent read and write speed at any scale .\n\nNoSQL is a database which is neither relational and does not use SQL ro query the data for results.\n\n**Features:**\n- Fully managed\n- Multiregion\n- Multimaster\n- Durable database\n- Built-in Security\n- Backup and restore\n- In-memory cacheing\n\n**Provides:**\nEventual Consistent Reads (default)\nStrongly Consistent Reads\n\n\n## Table Structure\n![Pasted image 20220724013608](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724013608.png)\n\n\n\n\n## Reads:\nWhen data needs to be updated it has to write updates to all copies. It is possible for data to be inconsistent if you are reading from a copy which has yet to be updated. You have the ability to choose the read consistency in DynamoDB to meet your needs.\n\n![Pasted image 20220724013641](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724013641.png)\n\n\n\n\n![Pasted image 20220724013804](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724013804.png)","lastmodified":"2023-03-02T22:23:38.793538102Z","tags":null},"/Cloud-Computing/AWS/Databases/RDS":{"title":"RDS","content":"# RDS\n\n#aws #cloud #sql #databases #rdbms\nA fully managed Relational Database Service by [AWS](Cloud%20Computing/AWS/AWS.md)\n\nA managed relational Database service which supports many RDMS engine which are easy to scale, maintain and update easily.\n\n## Encryption\n\nYou can turn encryption for all RDS engines\n\n\n\n\n\n## Backups\n\nThere are 2 types:\n\n### Automated Backups\nChoose a Retention Period between 1 and 35 days, stores transaction logs throughout the day and Automated backups are enabled by default. All data is stored in S3\n There is no additional charge for backup storage\n Yo can define your backup window\n\n### Manual Backup\nManual backups\n\n\n## Restoring Backups\n\nWhen recovering AWS it will restore it via the most recently taken snapshot.\n\nIt never restores ontop of running instance.\n\nYou will need to create a new RDS to retore on top of it\n\n\n### Multi AZ\n- Slave Database\n- Makes an exact \n- Synchronous replication (highly durable)\n- Used for Durability\n- Only the database on the primary instance is active\n- Backups are taken automatically\n- Always Span across two AZ\n- DB engine version upgrade happens on primary\n- Automatic fail-over to standby instance when a problem is detected on the primary instance\n\n## Read Replica\n\n- Only allows read\n- Asynchronous replication\n- Used to improve performance\n- All of the replicas are active\n- No backups are configured by default\n- Can be within a AZ, Cross-AZ or even Cross-Region\n- DB engine version upgrade is independent from source instance.\n- Should be manually promoted to a standalone dataabase instance\n\n\n\n## Performance Insights\nGives you a rich performance insights of your database.\n\n\n## Aurora Server-less\nA fully managed Serverless solution provided by aws for RDBMS. \n\n\n\n![Pasted image 20220724010918](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724010918.png)\n\n![Pasted image 20220724011034](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724011034.png)\n\n","lastmodified":"2023-03-02T22:23:38.813538174Z","tags":null},"/Cloud-Computing/AWS/Databases/Redshift":{"title":"Redshift","content":"# Redshift\n#aws #cloud #storage #datawarehousing \n\nIt is a fully managed Petabase-sized solution for data ware housing by [AWS](Cloud%20Computing/AWS/AWS.md).\nRedshift is singe AZ\nSnapshots can be resored at a different AZ\n\n\n\nPricing starts at $0.25 per hour with no upfront costs or commitments.\n\nScale up to petabytes for $1000 \n\nDataware house \n\n![Pasted image 20220724012000](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724012000.png)\n\n\n![Pasted image 20220724012758](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724012758.png)\n\n![Pasted image 20220724013125](Cloud%20Computing/AWS/Databases/Pasted%20image%2020220724013125.png)","lastmodified":"2023-03-02T22:23:38.813538174Z","tags":null},"/Cloud-Computing/AWS/Migration-Transfer/Snowball":{"title":"Snowball","content":"# Snowball\n#aws #cloud #snowball #storage #cloud-migration\n\n\nLow Cost data transfer service by [AWS](Cloud%20Computing/AWS/AWS.md) (Petabyte Scale). Snowball can reduce the cost by 1/5th\n\nFeatures:\n- E-ink display (shipping information)\n- Tamper and weather proof\n- Data is encrypted end-to-end using 256 bit encryption\n- users Trusted Platform Module (TPM)\n- For security purposes, data transfers must be completed within 90 days of snowball being created\n- Snowball can Import/Export from [S3](Cloud%20Computing/AWS/Storage/S3.md)\n- Comes in 2 sizes \n\t- (50 TB) \n\t- (80 TB)\n\n# Snowball Edge\nsimilar to Snowball but more storage and local processing\n\nFeatures:\n- LCD Display\n- Can undertake local processing and edge-computing workloads\n- Can use in a groups of 5 to 10 devices.\n- Three options for device configurations:\n\t- Storage Optimised (24 vCPUs)\n\t- Compute Optimised (54 vCPUs)\n\t- GPU Optimised (54 vCPUs)\n- Comes in 2 Sizes:\n\t- 100TB (83 usable)\n\t- 100TB Clustered (45 TB per node)\n\n\n# Snow Mobile#\nMade for Exabyte size data migration\n\nA 45-foot long ruggedized shipping container, pulled by a semi-trailer truck. transfer up to 100PB per Snowmobile.\n\nAWS personnel will help you connect your network to the snowmobile and when data transfer is complete they'll drive it back to AWS to import into [S3](Cloud%20Computing/AWS/Storage/S3.md) or Glacier\n\n*Security Features*\n- GPS Tracking\n- Alarm monitoring\n- 24/7 video surveillance\n- an escort security vehicle while in transit (optional)\n\n\n![Pasted image 20220714014138](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220714014138.png)","lastmodified":"2023-03-02T22:23:38.817538188Z","tags":null},"/Cloud-Computing/AWS/Migration-Transfer/Storage-Gateway":{"title":"Storage Gateway","content":"# Storage Gateway\n#aws #cloud #storage #networking\n\nA networking service by [AWS](Cloud%20Computing/AWS/AWS.md) which provides a seamless and secure integration between your organization's on-premise IT environment and AWS's storage infrastructure.\n\n\n## File Gateway (NFS) (store your files in S3)\n\nTo extend your local storage to S3\n\n\n\n## Volume Gateway (iSCSI) (stores copies of your HDD in S3)\n\nPresents your application with Internet Small Computer Systems Interface block protocol.\n\nData that is written to volumes can be asyncronously backed up as point-in-time snapshots of the volumes, and stored in the cloud as AWS EBS Snapshots.\n\nSnapshots are incremental backups\n\nTreats your local HDD as EBS.\n\nPrimary data is stored locally, while asyncronously backing up that data to AWS\n\n\n- Stored Volumes (primary data is on onsite) (1GB - 16TB)\n- Cached Volumes (primary data is in aws) (1GB - 32GB)\n\n## Tape Gateway (VTL) (virtual tape library)\n\nA durable, cost-effective solution to archive your data in the AWS Cloud\n\nThe VTL interface it provides let you leverage existing tape based backup application infrastructure.\n\nStore data on virtual tape cartridges that you create on your \n\n![Pasted image 20220724155600](Cloud%20Computing/AWS/Migration%20\u0026%20Transfer/Pasted%20image%2020220724155600.png)","lastmodified":"2023-03-02T22:23:38.817538188Z","tags":null},"/Cloud-Computing/AWS/Monitoring/CloudTrail":{"title":"CloudTrail","content":"# CloudTrail\n#aws #cloud #auditing #logs #monitoring \n\nLogs API calls between [AWS](Cloud%20Computing/AWS/AWS.md) services. when you need to know who to blame.\n\nenables governance, complience, operational auditing and risk auditing of aws account.\n\n\nused to monitor API calls and actions made by a user.\n\nEhere Source IP address\nWhen EventTile\nWho User, UserAgent\nWhat Region, Resource, Action\n\n\nCloudTrail is already logging by default and will collect logs for last 90 days via Event History.\n\nIf you need more than 90 days you need to create a Trail\n\nTrails are output to S3 and do not have GUI like Event History. You can use Amazon Athena to analyze these Event Histories. \n\n\n- A Trail can be set to log all regions\n\n- A Trail can be set to across all accounts in an Organization\n\n- You can Encrypt your Logs using Server Side Encryption via (SSE-KMS)\n\n- We can ensure the Integrity of our logs to see if they have been tampered we need to turn on Log File Validation.\n\n## CloudTrail to CloudWatch\n\nCloudTrail can be set to deliver events to a CloudWatch Logs.\n\n\n## Management vs Data Events\n\n![Pasted image 20220724020553](Cloud%20Computing/AWS/Monitoring/Pasted%20image%2020220724020553.png)\n\n\n- [ ] ![Pasted image 20220724020844](Cloud%20Computing/AWS/Monitoring/Pasted%20image%2020220724020844.png)","lastmodified":"2023-03-02T22:23:38.817538188Z","tags":null},"/Cloud-Computing/AWS/Monitoring/CloudWatch":{"title":"CloudWatch","content":"# Cloudwatch\n#aws #cloud  #monitoring #logs \n\nmonitoring solution for all of the various AWS resources by [AWS](Cloud%20Computing/AWS/AWS.md).\n\n![Pasted image 20220724014551](Cloud%20Computing/AWS/Monitoring/Pasted%20image%2020220724014551.png)\n\n\n## Cloudwatch-Logs\n, store, and access your log files.\n\n\nA Log Group is a collection of logs. Log files must belong to a log group.\n\nA log in Log Group is called a Log Stream\n\nBy default, logs are kept indefinitely and never expire\n\nMostAWS services are integrated with CloudWatch Logs.\nLogging of services sometimes need to be turned on or requires the IAM Permissions to write to CloudWatch Logs.\n\n## CloudWatch-Metrics\nRepresents a tie-ordered set of data points.\n\nCloudWatch comes with many predefined metrics eg.\n\nEC2 Per-Instance Metrics\nsuch as CPU Utilization/ DiskReadOps, NetworkIn\n\n### Custom Metrics\nUsing AWS CLI or SDK we can create and publish custom metrics. (Like Memory Utilization, Disk Usage which usually requires a cloudwatch agent).\n\nHigh resolution metrics can be enabled instead of standard metrics. A high definition metrics lets you track a metric under 1 minute down to 1 second. \n\n\n## Cloudwatch-Events\n\nTrigger an event based on condition or on schedule.\n\n\n## Cloudwatch-Alarms\nTriggers a notification based on a metric which breach a defined threshold. \n\n\n## Cloudwatch-Dashboards\nCreate custom dashboards from CloudWatch metrics.\n\n\n## Cloudwatch-Availability\n\n\n\n![Pasted image 20220724015847](Cloud%20Computing/AWS/Monitoring/Pasted%20image%2020220724015847.png)\n","lastmodified":"2023-03-02T22:23:38.817538188Z","tags":null},"/Cloud-Computing/AWS/Networking/CloudFront":{"title":"CloudFront","content":"# CloudFront\n#aws #cloud #edge #CDN\n\nA CDN service provided by [AWS](Cloud%20Computing/AWS/AWS.md).\n\nA CDN is a distributed network of servers which delivers web pages and contents to users based on their geographical location, the origin of the webpage.\n\n## Core Components\n\n### Origin\n\nThe location where the original files are located. eg an S3 Bucket, EC2, \n\n\n### Edge location\n\nThe location where the the web content will be cached.\n\n\n## CloudFront Distributions\n\nA Distribution is a collection of Edge locations. You can set the origin eg. EC2, S3, ELB, Route53.\n\nIt replicates copies based on your Price class\n\nThere are 2 types of Distributions\n1. Web (For websites)\n2. RTMP (For streaming media)\n\n\n#### Settings:\nBehaveour\n\n\n\n\n## Cloudfront-Lambda@Edge\n\nWe use these functions to overrice the behaviour of request and responces\n![Pasted image 20220723225149](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220723225149.png)\n\n A common use case will be using it to authenticate users before they can access secured web content which needs to be authorised via cognito or similar case\n\n## CloudFront-Protection\n\nBy default a Distribution allows everyone to have access\n\n### Original Identity Access (OAI)\nA virtual user identity that will be users to give your CloudFront Distribution permission to fetch a private object\n\nIn order to use Signed URLs or Signed Cookies you need to have an OAI\n\n#### Signed URLs \n\n\n\n![Pasted image 20220723230258](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220723230258.png)","lastmodified":"2023-03-02T22:23:38.825538216Z","tags":null},"/Cloud-Computing/AWS/Networking/Route53":{"title":"Route53","content":"# Route53\n#aws #cloud #dns #networking \n\nA DNS solution by [AWS](Cloud%20Computing/AWS/AWS.md).\nRoute53 is a [DNS](Networking/DNS.md) similar to Godaddy or Namecheap.\n\nUse cases:\n\ncan be used to get your custom domains to your AWS Resources\n\n\n![Pasted image 20220719161710](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220719161710.png)\n\n## Record Sets:\n\nWe create the customs domains using Record sets.\n\n## Alias Record\nAWS has its own special alias Record which extends DNS Functionality. It will route AWS resources easily.\n\n## Routing Policies\nThere are 7 different types of Routing policies:\n![Pasted image 20220720094427](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720094427.png)\n\n\n### 1. Simple Routing Policy\nIts the most basic routing policy in Route53\nIt is also the default Routing policy\n1 record and provide multiple IP addresses.\nWhen multiple values are specified the Route53 will return all\n\nThis is the default routing policy. Use this only when you have exactly one resource such as one EC2 web server. This policy can contain multiple values but it returns one resource. This policy is not recommend for production sites.\n\n![Pasted image 20220720094522](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720094522.png)\n\n\n### 2. Weighted\nThis routing policy lets you split up traffic based on different 'weights' assigned to the routes allowing user to send a certain percentage of overall traffic apart from that directed to a different server.\nIt’s based on a numer2ical value ranging from 0 to 255. If you specify a value of 0 for all regions then it’s routed equally.\n\n![Pasted image 20220720101226](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720101226.png)\n![Pasted image 20220720101237](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720101237.png)\n\n### 3. Latency\nWhen you have multiple resources in multiple regions, this policy routes the user not to the closest resource necessarily but the resource who responds the fastest or lowest latency.\n![Pasted image 20220720101348](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720101348.png)\n\n![Pasted image 20220720101321](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720101321.png)\n\n### 4. Failover\nAllows creating two records for the same name. This starts like simple policy but with a health check. If that single web server is unhealthy then you can point elsewhere. That next pointer can be another web server or possibly an error.html page hosted in AWS S3.\n![Pasted image 20220720101408](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720101408.png)\n![Pasted image 20220720101903](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720101903.png)\n\n\n### 5. Geolocation\nUse this when you want to serve your site based on the location of the client or user. ie. different servers for different users from regions. Like how all users from North American subcontinent to servers in one american servers and traffic from Asia to one of the servers in Asia.\n![Pasted image 20220720101949](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720101949.png)\n![Pasted image 20220720094744](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720094744.png)\n\n### 6. Geoproximity\nGeoproximity routing lets Amazon Route 53 route traffic to your resources based on the geographic location of your users and your resources. You can also optionally choose to route more traffic or less to a given resource by specifying a value, known as a _bias_. A bias expands or shrinks the size of the geographic region from which traffic is routed to a resource.\n\nThe effect of changing the bias for your resources depends on a number of factors, including the following:\n\n-   The number of resources that you have.\n    \n-   How close the resources are to one another.\n    \n-   The number of users that you have near the border area between geographic regions. For example, suppose you have resources in the AWS Regions US East (Northern Virginia) and US West (Oregon) and you have a lot of users in Dallas, Austin, and San Antonio, Texas, USA. Those cities are roughly equidistant between your resources, so a small change in bias could result in a large swing in traffic from resources in one AWS Region to the other.\n\n![Pasted image 20220720094814](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720094814.png)\n\n![Pasted image 20220720094827](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720094827.png)\n![Pasted image 20220720094850](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720094850.png)\n\n### 7. Multivalue\nThis one lets your return multiple values for each of your resources. The client or user browser randomly chooses one. Optionally you can add health checks. If any value becomes unhealthy then the client chooses another value to resolve. This is not an alternative solution to load balancing, it’s an enhancement. This is similar to the [#1 Simple Routing Policy](#1%20Simple%20Routing%20Policy) routing except .\n\n![Pasted image 20220720102628](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220720102628.png)\n\n## Health Checks\n\nChecks health every 30s by default. Can be reduced to every 10s.\nA health check can initiate a failover if the status is returned to unhealthy.\nA CloudWatch Alarm can be created to alert you about the health of the route.\nHealth check can monitor other health checks to create a chain of reactions.\nCan create up to 50 health checks for AWS endpoints that are within or linked to the same AWS Account.\n\n\n## Traffic Flow:\nA visual editor which lets you create routing configurations for your resources using existing routing types.\n","lastmodified":"2023-03-02T22:23:38.869538373Z","tags":null},"/Cloud-Computing/AWS/Networking/VPC":{"title":"VPC","content":"# VPC (Virtual Private Cloud)\n#aws #cloud #vpc #networking\n\n\nAmazon Virtual Private Cloud (VPC) is a commercial cloud computing service that provides users a virtual private cloud, by “provisioning a logically isolated section of [AWS](Cloud%20Computing/AWS/AWS.md) Cloud”.\n\n[VPC FAQ](https://aws.amazon.com/vpc/faqs/)\n\nA \n\nA VPC is like a digital data centre.\nAll VPC traffic can be logged via Flowlogs.\nIn an Amazon VPC, an EC2 instance retains it’s private IP address when the instance is stopped.\nA VPC consists of following components:\n\n![Pasted image 20220714145840](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220714145840.png)\n\n\n\n\nKey Features and Limitations:\n\n- VPCs are Region Specific and they do not span across regions\n- You can create 5 VPCs per region\n- Every region comes with a default VPC\n- You can have 200 subnets per VPC\n- You can use IPv4 CIDR Blocks and in addition to a IPv6 CIDR blocks\n- It costs nothing\n- Some things like NAT Gateway, VPC Endpoints, VPN Gateway and Customer Gateway are not free\n- DNS host names are disabled by default.\n\n\n## VPC Peering\n\nVPC peering can be used when a VPC needs to communicate with another VPC over a direct network route using private IP addresses.\n\nVPC Peering is supported across multiple accounts.\nVPC peering allows direct network connection via a private ip address. Instances behave as if they were on the same private network.\nPeering uses a star Configuration if you were to connect multiple different VPC i.e. a VPC will need to be in the middle of every other VPCs. (No Transitive peering)\nThe following peering configurations are invalid:\n\n-   Overlapping CIDR blocks\n-   Transitive peering\n-   Edge to edge routing through a gateway or private connection\n\n[More info on invalid peering configurations](https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html)\n\nVPC peering is only supported in a star configuration.\n\nTransitive peering / edge-to-edge routing is not supported. i.e. if you have VPC A \u003c-\u003e VPC B \u003c-\u003e VPC C, VPC A can communicate with VPC B, and VPC B with C, but A cannot directly communicate with C unless a direct connection is made between A and C.\n\n[More info on VPC peering](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html)\n\n**You must update both sides of the route tables for VPC peering to work**\n\n\n## Route Tables\nRoute tables are used to determine where the network traffic is directed. Each subnet in VPC must be associated with a route table. \nA subnet can only be associated with one route table at a time.\nA route table can be used to associate multiple subnets.\nEach record in the route table is called a route.\n\nIn VPCs, even though we have these different subnets, we need to allow traffic to flow through them. We do this with Route Tables. **A Route Table is just a list of CIDR blocks (IP ranges) that our traffic can leave and come from.** By default, newly created Route Tables will have the CIDR of our VPC defined. This means that traffic from anywhere within our VPC is allowed.\n\nIn addition to a list of IP ranges that our Route Table connect traffic between, it also has **Subnet Associations**. Simply put, these are \"which subnets use this route table.\"\n\n## Direct Connect \n\n\n## Internet Gateway\n\nCreating a VPC also creates a route table, but doesn’t create a subnet or internet gateway by default.\n\nFor a VPC route table point to an internet gateway, you must first attach the internet gateway to the VPC.\n\n**You can attach only one internet gateway to a VPC at a time**; if youre getting an error when trying to attach an Internet Gateway to a VPC, it could be that an Internet Gateway is already attached to the VPC.\n\nBefore deleting an IGW, you must first detach it from the VPC it’s attached to.\n\n[More info on VPC Internet Gateways](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html)\n\n\n## Direct Connect\n\nA solution for establishing dedicated network connections from on-premises locations to AWS.\n\nVery fast network with Lower bandwidth of 50M-500M or Higher Bandwidth 1GB or 10GB.\n\nHelps reduce network costs and increase bandwidth throughput\nProvides a more consistent network experience than internet based connections. (reliable and secure)\n\n## VPC Endpoints\n\nVPC endpoints allow you to privately connect your VPC to other AWS services, and VPC endpoint services.\n\nEliminates the need for [#Internet Gateway](#Internet%20Gateway), NAT device, VPN connection or even AWS Direct Connect connections.\n\nInstances in the VPC do not require public IP address to communicate with service resources.\n\nTraffic between your VPC and other services does not leave the AWS network.\n\nHorizontally scaled, redundant, and highly available.\n\nAllows secure communication between instances and services without adding availability risks or bandwidth constraints on your traffic.\n\n![Pasted image 20220715002212](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715002212.png)\n### Interface endpoints\n\n![Pasted image 20220715002052](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715002052.png)\n\n\n### Gateway Endpoint\n\nA gateway endpoint is a target for specific route in your route table. \nOnly support [DynamoDB](Cloud%20Computing/AWS/Databases/DynamoDB.md) and [S3](Cloud%20Computing/AWS/Storage/S3.md)\n\nGateway endpoints are free\n\n\n\n## VPC Flow Logs\n\ncaptures IP traffic information flow of Network Interfaces withhin VPC.\ncan be created for:\n\t- VPC\n\t- Subnets\n\t- Network Interface\n\nAll data is stored in Amazon Cloudwatch logs\nCan be viewed in detail in Cloudwatch logs,\nCannot do much than delete it.\nCannot be tagged like other resources\ncan be delivered to S3 or cloudwatch logs\nsome instance traffic can not be monitored\n\n![Pasted image 20220715002555](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715002555.png)\n\n![Pasted image 20220715002614](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715002614.png)\n\n## VPC Virtual Private Gateway\n\nAn Amazon VPC VPN connection links your data-center (or network) to your Amazon VPC virtual private cloud (VPC). A customer gateway is the anchor on your side of that connection. It can be a physical or software appliance. The anchor on the AWS side of the VPN connection is called a virtual private gateway.\n\n[More info](https://docs.aws.amazon.com/vpc/latest/adminguide/Introduction.html)\n\n\n\n### CIDR - Classless Inter-domain Routing\n\n**The first four IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance.**\n\ni.e.\n\n-   10.0.0.0: Network address.\n-   10.0.0.1: Reserved by AWS for the VPC router.\n-   10.0.0.2: Reserved by AWS for DNS.\n-   10.0.0.3: Reserved by AWS for future use.\n-   10.0.0.255: Network broadcast address. We do not support broadcast in a VPC, therefore we reserve this address.\n\nNetwork masks:\n\n-   /16 - supports up to 65,536 IP addresses. Best for large networks.\n-   /24 - supports up to 256 IP addresses. Best for smaller networks.\n-   /27 - supports up to 32 IP addresses\n-   /28 - supports up to 16 IP addresses\n-   /32 - an absolute ip address - matches exactly one\n\nIt’s possible to split a CIDR block into two subnets:\n\n-   one subnet can use CIDR block 10.0.0.0/25 (for addresses 10.0.0.0 - 10.0.0.127)\n-   and then the other subnet can use the CIDR block 10.0.0.128/ 25 (for addresses 10.0.0.128 - 10.0.0.255)\n\nThe allowed CIDR block size in a VPC is between a /16 and /28 netmask.\n\nTo enable ping, you need to allow ICMP traffic.\n\nIn order to ensure providioned EC2 instances have a public IP address, enable “Auto-Assign Public IP” for the subnet.\n\n0.0.0.0/0 is also known as default \nIt represents all possible IP addresses\n\n\n## Network Access Control List (NACL)\n\nNACLs acts as a virtual firewall at a subnet level.\n\nVPCs automatically get a default NACL\nSubnets are associated with NACLs. Subnets can only belong to single NACL.\nEach NACL contains a set of rules that can allow or deny traffic in and out of the subnet. \nStateless\nA default NACL denies all traffic \n\n![Pasted image 20220715002905](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715002905.png)\n![Pasted image 20220715002945](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715002945.png)\n\n\n## Security Groups\nA virtual firewall at an instance level.\nSecurity groups are associated with EC2 instances.\nEach security Group contains a set of rules that filter traffic coming into in or out of Ec2 instances. \nMultiple Instances across multiple subnets can belong to a Security Group.\n\nThere are no deny rules. All inbound traffic are denied as default unless there is a rule specifically allows it. All outbound traffic is allowed by default.\n\nthese are stateful\nchanges take effect immediately.\n\n![Pasted image 20220715003259](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715003259.png)\n\n\n#### Limits\n\ncan have upto 10,000 SGs in a single region. (Default is 2,500)\ncan have 60 inbound and 60 outbound rules per SG\n16 SG per ENI (default is 5)\n\n![Pasted image 20220715003440](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715003440.png)\n\n\n## Network address translation (NAT)\n\nNAT is a method of remapping one IP address space to another.\nIn a private network NAT can help gain outbound access to the internet by using a NAT gateway which will remap the Private IPs.\n\nIf there are two networks which have conflicting network addresses, NAT can be used to make the addresses more agreeable\n\n### NAT Instances vs NAT Gateways\n![Pasted image 20220715003856](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715003856.png)\n\n\n![Pasted image 20220715004501](Cloud%20Computing/AWS/Networking/Pasted%20image%2020220715004501.png)\n\n","lastmodified":"2023-03-02T22:23:38.869538373Z","tags":null},"/Cloud-Computing/AWS/Organizations/AWS-Control-Tower":{"title":"AWS Control Tower","content":"# Control Tower\n#aws #cloud \n\nIs an extention to aws organization, that lets you create a landing zone (a well-architected multi-account baseline)\n","lastmodified":"2023-03-02T22:23:38.869538373Z","tags":null},"/Cloud-Computing/AWS/Organizations/SCP":{"title":"SCP","content":"# Service Control Policies\n#aws #cloud \n\nService control policies (SCPs) are **a type of organization policy that you can use to manage permissions in your organization**. SCPs offer central control over the maximum available permissions for all accounts in your organization.\n\n![Pasted image 20230225014157](Microservice%20Architecture/Attachments/Pasted%20image%2020230225014157.png)\nExplicit deny overrides any allows later levels\n![Pasted image 20230225014220](Microservice%20Architecture/Attachments/Pasted%20image%2020230225014220.png)\n\n\n\n**Topics**\n-   [Testing effects of SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-warning-testing-effect)\n-   [Maximum size of SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-size-limit)\n-   [Inheritance of SCPs in the OU hierarchy](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-about-inheritance)\n-   [SCP effects on permissions](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#scp-effects-on-permissions)\n-   [Using access data to improve SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#data-from-iam)\n-   [Tasks and entities not restricted by SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html#not-restricted-by-scp)\n-   [Creating, updating, and deleting service control policies](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_create.html)\n-   [Attaching and detaching service control policies](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_attach.html)\n-   [Strategies for using SCPs](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_strategies.html)\n-   [SCP syntax](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_syntax.html)\n-   [Example service control policies](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples.html)","lastmodified":"2023-03-02T22:23:38.869538373Z","tags":null},"/Cloud-Computing/AWS/Security-Identity/Cognito":{"title":"Cognito","content":"# Amazon Cognito\n#aws #cloud #security \n\nDecentralised way of managing [Authentication](Cyber%20Security/Cloud%20Security/Authentication.md) by [AWS](Cloud%20Computing/AWS/AWS.md).\n\n\n## Web Identity Federation and IpD\n\n### Web Identity Federation\nTo exchange identity and security information between an [#Identity Provider IdP](#Identity%20Provider%20IdP) and application.\n\n### Identity Provider (IdP)\na trusted provider of your user identity that lets you use authenticate to access other services. Identity Providers could be: Google, Facebook, GitHub, etc\n\ntypes:\n\t1. Security Assertion Markup Language (SAML)\n\t2. OpenID Connect (OIDC) OAuth (Used by Google, Facebook, Github, etc)\n\n## Cognito User Pools\nUser directory with authentication to [#Identity Provider IdP](#Identity%20Provider%20IdP) to grant access to your app to manage actions for web and mobile apps such as:\n\t1. Sign-up\n\t2. Sign-in\n\t3. Account recovery\n\t4. Account Confirmation\n\nAllows users to sign in directly to the user pool or using Web Identity Federation.\n\nUses AWS Cognito as the identity broker between AWS and the identity provider.\n\nSuccessfully authentication generates a JSON Web Token (JWTs).\n\nUser Pools can be thought of as the account used to access the system (ie. email address and password)\n\n*  Choose password requirements\n* Apply MFA\n* Restrict whether users are allows to signup on their own or need admin verification.\n* Analytics with Pinpoint for user campaigns.\n* Trigger custom log via Lambdas after actions such as signup\n\n\n\n## Cognito Identity Pools\n\n**Identity Pools** provide temporary AWS credentials to access services eg. S3 DynamoDB. Identity Pools can be thought of as the actual mechanism authorising access to the AWS resources.\n\n\n## Cognito Sync\n\nSync user data and preferences across devices with one line of code.\n\nCognito uses push synchronisation  to push updates and synchronise data. Uses [SNS](Cloud%20Computing/AWS/Application%20Integration/SNS.md) to send notifications to all user devices when data in the cloud changes.\n\n![Pasted image 20220719153956](Cloud%20Computing/AWS/Security%20\u0026%20Identity/Pasted%20image%2020220719153956.png)\n\n","lastmodified":"2023-03-02T22:23:38.869538373Z","tags":null},"/Cloud-Computing/AWS/Security-Identity/IAM":{"title":"IAM","content":"# IAM\n#aws #cloud #security #rbac\n\nIdentity based management solution by [AWS](Cloud%20Computing/AWS/AWS.md)\n\nIAM allows management of access of users and resources\n\n\n**IAM Users** - End users who access AWS resources via the console or the API\n\n**IAM Groups** - Group of users with shared permission levels which will be common for all of the users.\n\n**IAM Roles** - Associate permissions to a Role and then assign this to an **IAM Users** or **IAM Groups**.\n\n**IAM Policies** - JSON documents granting permissions for a specific user, group, or role to access the services. Policies are attached to **IAM Identities**.\n\n![Pasted image 20220715093815](Cloud%20Computing/AWS/Security%20\u0026%20Identity/Pasted%20image%2020220715093815.png)\n\n\n## IAM Policies\n![Pasted image 20220715094058](Cloud%20Computing/AWS/Security%20\u0026%20Identity/Pasted%20image%2020220715094058.png)\n\n## Managed vs Customer vs Inline policies\n\n### Managed Policies \ndefault policies defined and given by AWS which is designed to support common use cases.\nthese cannot be edited.\nTHese are indicated by an orange box.\n\n### Customer Managed Policies\nCustom policies created by users which is editable.\n\n### Inline Policies\nA policy which is directly attached to a user or a resource.\n\n\n\n\n## IAM - Password Policy\n\nIn IAM you can set a Password Policy to set the minimum requirements of a password and rotate passwords so users have to update their password after X days\n\n\n## IAM - Access Keys\n\nAccess keys allow user to interact with AWS services programmatically via the AWS CLI or the SDK\n\nPer user can have 2 access keys.\n\n## IAM - MFA\n\nCan be turned on per user\nThe user has to turn on MFA themselves.\nAdministrator cannot enforce users to have MFA\n\nThe Administrator cannot create a policy requiring MFA to access certain resources.\n\n![Pasted image 20220719151854](Cloud%20Computing/AWS/Security%20\u0026%20Identity/Pasted%20image%2020220719151854.png)","lastmodified":"2023-03-02T22:23:38.869538373Z","tags":null},"/Cloud-Computing/AWS/Security-Identity/KMS":{"title":"KMS","content":"# KMS\n#cloud #aws #security \n\n[AWS](Cloud%20Computing/AWS/AWS.md) Key Management Service (AWS KMS) lets you create, manage, and control cryptographic keys across your applications and more than 100 AWS services. These keys could be used for [Encryption](Cyber%20Security/Encryption.md) as well as a form of [Authorization](Cyber%20Security/Cloud%20Security/Authorization.md) of the users/services. \n\n\n\n![Pasted image 20230103145238](Microservice%20Architecture/Attachments/Pasted%20image%2020230103145238.png)","lastmodified":"2023-03-02T22:23:38.869538373Z","tags":null},"/Cloud-Computing/AWS/Security-Identity/WAF":{"title":"WAF","content":"# WAF\n\n#aws #cloud \n\nAWS WAF is a web application firewall [WAF](Cyber%20Security/Cloud%20Security/WAF.md) that helps protect apps and APIs against bots and exploits that consume resources, skew metrics, or cause downtime.","lastmodified":"2023-03-02T22:23:38.877538402Z","tags":null},"/Cloud-Computing/AWS/Storage/EBS":{"title":"EBS","content":"# EBS\n#cloud #aws #storage\n\nA device access block storage solution by [AWS](Cloud%20Computing/AWS/AWS.md). \n\nHighly available and durable solution for attaching persistent block storage volumes to an [Elastic Compute Cloud EC2](Cloud%20Computing/AWS/Compute/Elastic%20Compute%20Cloud%20EC2.md) instance. Volumes are automatically replicated within their Availability Zone (AZ) to protect from component failure.\n![Pasted image 20220723215556](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220723215556.png)\n![Pasted image 20220723215541](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220723215541.png)\n\n## Moving Volumes\n\n### From one AZ to another\n1. Take a snapshot\n2. create an AMI from the snapshot \n3. launch an EC2 instance\n\n\n### From one Region to another\n1. Take a snapshot\n2. create an AMI from the snapshot \n3. Copy the AMI from one region to another\n4. launch an EC2 instance\n\n## EBS - Encrypted Root Volume\nYou can enable encrypto\n![Pasted image 20220723224133](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220723224133.png)\n\n\n\n## EBS vs Instance Store Volumes\n![Pasted image 20220723224353](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220723224353.png)\n\n\n\n![Pasted image 20220723224449](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220723224449.png)","lastmodified":"2023-03-02T22:23:38.877538402Z","tags":null},"/Cloud-Computing/AWS/Storage/Elastic-File-Storage-EFS":{"title":"Elastic File Storage (EFS)","content":"# EFS\n#aws #cloud #storage #nfs\n\nScalable, Elastic Cloud-native NFS file System offered by [AWS](Cloud%20Computing/AWS/AWS.md).\n\nActs as a single drive which could be utilized by multiple [Elastic Compute Cloud EC2](Cloud%20Computing/AWS/Compute/Elastic%20Compute%20Cloud%20EC2.md) instances.\n\nEFS is using Network File System version 4 (NFSv4) protocol\nEFS create multiple mount targets to mount to various AZs\n\nIt can expand elasticly just like an S3\n\n","lastmodified":"2023-03-02T22:23:38.877538402Z","tags":null},"/Cloud-Computing/AWS/Storage/S3":{"title":"S3","content":"# S3\n#aws #s3 #storage #serverless #cloud \n\n\nObject storage solution provided by AWS.\nServerless storage in the cloud.\nDo not have to worry about the underlying infrastructure\n\nObject storage is  a a simple data storage architecture that manages data as objects, as opposed to other storage architectures which manages data as files and file hierarchy (file systems) and block storage which manages data as blocks within sectors and tracks.\n\nS3 provides unlimited storage.\n\n\n## Objects\n\nObjects contains data and acts similar to files. they contain:\n- Key (name)\n- Value (data itself)\n- Version ID (if enabled the version)\n- Metadata (additional information i.e.  file-type)\n\n## Buckets\nBucket holds [#Objects](#Objects) \nBuckets can have folders to organise Objects.\nThese should be unique universally similar to domain names. (i.e. there cannot be bucket with same name even in cross-account scenario)\n\n## Storage Classes\n\n![Pasted image 20220713123659](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220713123659.png)\n![Pasted image 20220714012155](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220714012155.png)\n\n### S3-Standard (Default)\n The default storage class. If you don't specify the storage class when you upload an object, Amazon S3 assigns the S3 Standard storage class.\n\n- Fast (Low latency and high throughput performance.)\n- 99.99% Availability\n- 11 9's Durability (Resilient against events that impact an entire Availability Zone.)\n- Replicated across at least 3 [](Cloud%20Computing/AWS/AWS.md#Avilability%20Zones%20AZ#Avilability%20Zones%20AZ#)\n- Backed with the Amazon S3 Service Level Agreement for availability.\n- Supports SSL for data in transit and encryption of data at rest.\n- S3 Life-cycle management for automatic migration of objects to other S3 Storage classes\n\n\n### S3-Intelligent Tiering\nUses ML/AI to analyse object usage and automate cost savings by moving objects between four access tiers when accessing patterns change. data is moved to most suitable tier, without any performance impact or added overhead.\n\n-   Automatically optimises the storage costs for data with changing access patterns.\n-   Stores objects in four access tiers, optimised for frequent, infrequent, archive, and deep archive access.\n-   Frequent and In-frequent Access tiers have the same low latency and high throughput performance as S3 Standard.\n-   Designed for durability of 99.999999999% of objects across multiple Availability zones.\n-   Designed for 99.9% availability over a given year.\n-   Backed with the Amazon S3 Service Level Agreement for availability.\n-   Small monthly monitoring and auto-tiering free.\n\n\n### S3-Standard Infrequently Accessed (IA)\n\n### S3-Onezone IA\n\n- 1 AZ only\n- Avilability is decreased to 99.5%\n### S3-Glacier\n### S3-Glacier-Deep Archive\n- Slowest storage class ()\n- \n-  Cheapest tier here\n\n\n\n## S3 Security\n- All new buckets are PRIVATE by default.\n- Logging per request can be turned on to see the access log of the users\n- Access Control is configured using Bucket Policies and Access Control Lists (ACL)\n- **ACL** are Leagacy feature of controlling access to buckets and objects\n- **Bucket Policies** are newer compared to ACL's and use JSON format policies\n\n\n### S3 Encryption at transit\nSSL/TLS is enabled at transit by default\n\n\n### S3 Encryption at rest\nthere are three types of S3 SSE and also supports Client Side Encryption\n\n\n#### Server Side Encryption (SSE) \n- **SSE-AES** S3 handles the key and uses AES-256 algorithm\n- **SSE-KMS** Envelope the encryption using two passes. Both Amazon KMS and the client manages the keys \n- **SSE-C** Similar to KMS but the customer is responsible for managing the key in the aws.\n\n\n#### Client Side Encryption (CSE)\nwe the clients are responsible for the encryption of the files being stored in the S3. i.e. the file will be encrypted locally even before being transferred to the s3\n\n\n### Data Consistency\n**Read After Write Consistency**\nWhen you upload a new object\n\n**Eventual Consistency** \nwhen you overwrite or delete an object it takes time for S3 to replicate versions to multiple AZ's.\nFetching the updated object from S3 which was just updated might result in returning the old object instead of the newer copy.\n\n## S3 Cross Region Replication\n\nWhen enabled, any object that is uploaded will be automatically replicated to another region/s. It provides higher durability and potential disaster recovery for objects.\nThis requires versioning turned on on both Source and Destination Bucket. Cross account replication is also possible.\n\n\n## S3- Versioning\nStores all version of S3 Objects\nOnce enabled it cannot be disabled, only suspended on the bucket\nFully integrates with [](Cloud%20Computing/AWS/Storage/S3.md#S3%20Life-cycle%20Management) Rules\nMFA Delete feature provides extra protection against accidental deletions\n\n\n\n## S3 Life-cycle Management\n\nAutomated the process of moving objects to different Storage Classes or deleting.\nSort of like a cronjob. \nCan be used together with versioning and can apply changes and commands to both current and previous versions.\n\n\n\n## Transfer Acceleration\n\nFast and secure transfer of files over long distances between your end users and an S3 bucket.\nUtilises CloudFront's Edge Locations\nInstead of uploading directly to the bucket it will use a distinct URL of an Edge Location to upload it there.\nWhen the data is uploaded in the Edge Location it is automatically routed to S3 over a optimised network path\n \n\n## S3 Presigned URLs\n\nGenerates a URL which provides a temporary access to the object to either upload or download object data. Presigned URLs are commonly used to provide access to private objects. You can use AWS CLI or the SDK to generate these Presigned URLs.\n\nwill be required when a web-application requires to allow users to download/upload files to a password protected part of a web-app. The web-app can generate quickly expiring URLs to give the users the brief access they need for their operation\n\n## MFA Delete\n\nEnsures users cannot delete object form S3 bucket unless they provide a valid MFA code.\nIt requires: \n\n\n\n![Pasted image 20220714013034](Cloud%20Computing/AWS/Storage/Pasted%20image%2020220714013034.png)","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/AAD":{"title":"AAD","content":"# Azure Active Directory (AAD)\n#Azure #Active-Directory #rbac \n\n\nAzure AD is not simply a cloud version of [Active Directory](Cyber%20Security/Cloud%20Security/Active%20Directory.md) in [Azure](Cloud%20Computing/Azure/Azure.md) as the name might suggest. Although it performs some of the same functions, it is quite different. Azure Active Directory is a secure online authentication store, which can contain users and groups. \n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/ACR":{"title":"ACR","content":"# ACR (Azure Container Registry)\n#Azure #cloud #containers #registry #container-registry #docker \n\nIt is a simple container registry service provided by [Azure](Cloud%20Computing/Azure/Azure.md). It is similar to [ECR](ECR) Provided by AWS.","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/AVD":{"title":"AVD","content":"# Azure Virtual Desktop\n#cloud #Azure #virtual-machines #compute \n\nAzure Virtual Desktop, (formerly known as Windows Virtual Desktop) is a Microsoft [Azure](Cloud%20Computing/Azure/Azure.md)-based system for [virtualizing](virtualizing) its Windows operating systems,  aimed at enterprise customers rather than at individual users.\n\n\n\n\n## Demo\nSetup of AVD with existing [AAD](Cloud%20Computing/Azure/AAD.md).\n\nSteps:\n1. Create a Resource Group\n2. Create a [VNET](Cloud%20Computing/Azure/VNET.md) link it with the created [Resource Groups](Cloud%20Computing/Azure/Resource%20Groups.md) with a simple subnet\n3. Create a Hostpool under the [AVD](Cloud%20Computing/Azure/AVD.md)\n4. \n\nhttps://www.youtube.com/watch?v=jMAanEp-ugI\n\n## AVD with custom windows 11 image\n\n1. Install necessary program and do required changes\n2. Generalize the VM (Remove specific names from VM) \n3. Stop the instance\n4. Create an Image ","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/App-Service":{"title":"App Service","content":"# Azure App Service\n#azure #cloud #compute \n\nIt is a cloud computing based platform for hosting websites in [Azure](Cloud%20Computing/Azure/Azure.md), created and operated by Microsoft. It is a [PaaS](PaaS) which allows publishing Web apps running on multiple frameworks and written in different programming languages, including Microsoft proprietary ones and 3rd party ones.An Azure subscription is a logical container used to provision resources in Azure. It holds the details of all your resources like virtual machines (VMs), databases, and more. When you create an Azure resource like a VM, you identify the subscription it belongs to.","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Az-900":{"title":"Az 900","content":"# AZ 900\n\nCloud Concepts 15-25%\nAzure Core Services 30-35%\nSecurity 25-30%\nPricing 20-25%\n\n40-60 questions\n\n\n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Azure":{"title":"Azure","content":"\n## Azure Geographies:\n-  US\n-  Azure Government US\n-  Canada\n-  Brazil \n-  Mexico\n\n58 Regions available across 140 Countries\n\n### Pared Regions\nEach region is pared with another region 300 miles away.\nOne region is updated at a time to ensure no outages\nServices are relied on pared region for Disaster Recovery\n\n### Region Types and Service Availability\n![Pasted image 20230210163119](Microservice%20Architecture/Attachments/Pasted%20image%2020230210163119.png)\n\n### Special Regions\nHas specialised regions to meet compliance or legal reasons\n\n- US DoD Central\n- US Gov Virginia\n- US Gov Iowa\n- China East\n- China North\n\n### AZ supported Regions\n**Alternate** or **Other** will not have support for AZ.\nThe Regions with atleast 3 AZs are:\n- Central US\n- East US 2\n- West US 2\n- Went Europe\n- France Central\n- North Europe\n- Southeast Asia\n\n\n## Availability zone (AZ)\n- A physical location made up of one or more data-center.\n- A region will generally contain 3 AZs\n- Data-centers within a region will be isolate from each other.\n- For high availability it is common to run workloads on at least 3AZs\n\n![Pasted image 20230210163519](Microservice%20Architecture/Attachments/Pasted%20image%2020230210163519.png)\n\n### Fault and Update Domain\n\n**Fault Domain** is a logical grouping of hardware to avoid a single point of failure within an AZ\n\n**Update Domain** is used when Azure needs to apply updates to the underlying hardware and software. (Azure make sure by using update domain to eliminate downtime)\n\n**Availability Set** is a logical grouping that can be configured in Azure to ensure that the VMs are placed in different fault/update domains to avoid downtime.\n\n![Pasted image 20230210164159](Microservice%20Architecture/Attachments/Pasted%20image%2020230210164159.png)\n\n\n---\n\n\n\n## Computing Services\n- Azure VM\n- Azure Container Instances (Docker as a Service)\n- Azure kubernetes Service (Kubernetes as a Service)\n- Azure Service Fabric (Tier-1 Enterprise Container as a Service)\n- Azure Functions\n- Azure Batch\n\n\n## Storage Services\n- Azure Blob storage\n- Azure Disk Storage (Similar to EBS)\n- Azure File Storage (NFS, Similar to EFS)\n- \\*Azure Queue Storage (Messaging Queue)\n- \\*Azure Table Storage (Wide column NoSQL Database)\n- Azure Data Box/Azure Databox Heavy (Rugged breifcase computer)\n- Azure Archive Storage (Long term cold storage)\n- Azure Data Lake Storage (centralized repository like [Snowflake](Snowflake))\n\n\n## Database Services\n- Azure Cosmos DB (NoSQL database)\n- Azure SQL Database (MS SQL database)\n- Azure Database for MySQL/PLSQL/MariaDB\n- SQL Server on VMs (lift and shift existing on-prem sql server dbs)\n- Azure Synapse Analytics (Azure SQL Data Warehouse)\n- Azure Database Migration Service\n- Azure Cache for Redis\n- \\*Azure Table Storage\n\n\n## Application Integration Services\n- Azure Notifications Hub (SNS)\n- Azure API Apps (Essentially API Gateways)\n- Azure Service Bus (Messaging as a service SES)\n- Azure Stream Analytics (Serverless real-time analytics)\n- Azure Logic apps\n- Azure API Management (add in front of an existing APIs)\n- \\*Azure Queue service (SQS)\n\n\n## Developer and Mobile Tools\n- Azure Signal Service (Real-time Messaging)\n- Azure App Service (PaaS like Heroku)\n- Visual Studio (IDE code editor)\n- Xamarin (Mobile app framework)\n\n\n## Azure DevOps Services\nAzure devops is basically a \nAzure Boards\nAzure Pipelines\nAzure Repos\nAzure Test Plans (manual and exploratory testing tools like cyprus.io)\nAzure Artifacts\nAzure DevTest Labs\n\n\n## Azure Resource Manager (ARM)\n\nIaC  of Azure, Azure Resources Manager or ARM allows you to create Azure resources via Json templates. \n\n**Azure QuickStart** is a library of pre-made ARM templates provided by the community and partners to help you quickly launch new projects for a variety of stack scenarios\n\n\n## Azure Virtual Networks\n\n**vNet** is a logically isolated section of Azure Network where you launch your Azure resources. you choose a CIDR range to be used within the network.\n\n**Subnet** is a logical partition of an IP network to breakup the IP-ranges within a vNet. The CIDRs range must be smaller than the vNets. There could be Public or Private Subnets.\n\n\n## Cloud-Native Networking Services\n- Azure DNS (like Route 53)\n- Azure Virtual Network (vNet)\n- Azure Load Balancer (OSI level 4 (Transport) Load Balancer)\n- Azure Application Gateway (OSI Layer 7 HTTP load balancer, WAF applicable)\n- Network Security Groups (NSGs) (virtual firewall at subnet level)\n\n## Enterprise/Hybrid Networking Services\n- Azure Frontdoor ()\n- Azure Express Route (Connection between On-prem to cloud)\n- Virtual WAN \n- Azure Connection (VPN connection)\n- Virtual Network Gateway (A site to site VPN)\n\n## Scale Sets\nThis allows you to group together identical virtual machines and automatically increase or decrease the amount of servers based on:\n- change  in CPU, memory, disk and network performance\n- On a predefined schedule\n\nSimilar to AWS EC2 auto scaling groups.\n\n## IOT Services\n- IoT central (device-cloud connection)\n- IoT Hub (device-application connection)\n- IoT Edge (edge computing)\n- Windows 10 IOT Core Services\n\n\n## Big Data and Analytics Services\n- Azure Synapse Analytics (Enterprise data warehousing and BD analytics)\n- HDInsight (Runs Open-source analytics software like Hadoop, Kafka, Spark)\n- Azure Databricks (Apace Spark based analytic platform)\n- Data Lake Analytics\n\n\n## AI/ML Services\n- **Azure Machine Learning Service**  \n- Personalizer\n- Translator\n- Anomaly Detector\n- Azure Bot Service\n- Form Recognizer\n- Computer Vision\n- Language understanding\n- QnA maker (QA bot)\n- Text Analytics\n- Content Moderator\n- Face\n- ink Recogniser (OCR)\n\n\n## Serverless Services\nHighly Available, Scaleable, and Cost-effective solution that could be **Event Driven Scaled**, **Abstract Servers**, and ** Bill in microseconds for cost effectiveness**.\n- Azure Functions\n- Blob storage\n- Logic Apps (Like Lambda step function)\n- Event Grid (pub/sub to trigger other services)\n\n\n**Azure Portal** is a web based, unified console as an alternative to azure cli. There are also *Azure Preview Portal* to utilize new features.\n`preview.portal.azure.com`\n\n**Azure CLI**\nSupported on Windows, Mac and Linux and can be used to manage Azure resources via CLI.\n\n**PowerShell** is a task automation and configuration management framework. Can be used as a command-line shell and a scripting language like bash. It is built on top of .NET Common Language Runtime, it accepts and returns .Net objects.\n\n**Azure PowerShell** are a set of cmdlets for managing Azure resources directly from PowerShell command Line\n\n**Azure Cloud Shell** is and interactive, authenticated browser-accessible shell for managing azure resources via Bash or PowerShell.\n\n**Visual Studio Code** is a free source-code editor. \n\n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Azure-AD":{"title":"Azure AD","content":"# Azure AD\n#azure #Active-Directory \n\nAzure Active Directory (Azure AD) is a directory service provided by Microsoft [Azure](Cloud%20Computing/Azure/Azure.md) that enables you to sign in and access both Microsoft cloud applications and cloud applications that you develop. Azure AD can also help you maintain your on-premises [Active Directory](Cyber%20Security/Cloud%20Security/Active%20Directory.md) deployment.\n\nAzure AD provides services such as:\n\n- **Authentication**: This includes verifying identity to access applications and resources. It also includes providing functionality such as self-service password reset, multi-factor authentication, a custom list of banned passwords, and smart lockout services.\n\n- **Single sign-on**: Single sign-on (SSO) enables you to remember only one username and one password to access multiple applications. A single identity is tied to a user, which simplifies the security model. As users change roles or leave an organization, access modifications are tied to that identity, which greatly reduces the effort needed to change or disable accounts.\n\n- **Application management**: You can manage your cloud and on-premises apps by using Azure AD. Features like Application Proxy, SaaS apps, the My Apps portal, and single sign-on provide a better user experience.\n\n- **Device management**: Along with accounts for individual people, Azure AD supports the registration of devices. Registration enables devices to be managed through tools like Microsoft Intune. It also allows for device-based Conditional Access policies to restrict access attempts to only those coming from known devices, regardless of the requesting user account.","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Azure-DNS":{"title":"Azure DNS","content":"# Azure DNS\n#Azure #cloud #networking \n\nThis service is used to manage your DNS records and also host them. Similar to AWS [Route53](Cloud%20Computing/AWS/Networking/Route53.md). ","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Azure-Load-Balancer":{"title":"Azure Load Balancer","content":"# Azure Load Balancer\n#Azure #cloud \n\nIs used for evenly distributing incoming network traffic across a group of backend resources or servers using **OSI Layer 4 (Transport Layer)**. A A basic networking servile provided by [Azure](Cloud%20Computing/Azure/Azure.md) similar to AWS [Elastic Load Balancer (ELB)](Cloud%20Computing/AWS/Compute/Elastic%20Load%20Balancer%20(ELB).md) There can be a Public Load Balancer as well as Private Load balancer.\n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Azure-NACL":{"title":"Azure NACL","content":"# NACL (Network Access Control List)\n#Azure #cloud #security #acl\n\n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Azure-NSG":{"title":"Azure NSG","content":"# NSG (Network Security Groups)\n#Azure #cloud #security #security-groups\n\nAn [Azure](Cloud%20Computing/Azure/Azure.md) networking firewall like service similar to [AWS NSG](AWS%20NSG). ","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Azure-Traffic-Manager":{"title":"Azure Traffic Manager","content":"# Azure Traffic Manager\n#Azure #cloud #networking \n\nthis services operates at the DNS layer to quickly and efficiently direct incoming DNS requests based on the routing method of your choice. (In AWS it is done within the **Route53**)\n- Route traffic to servers the geographically near (reduces latency)\n- Fail-over to redundant systems (increases fault-tolerance)\n- Route traffics to random VM for A/B testing\n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Azure-WAF":{"title":"Azure WAF","content":"# WAF\n#Azure #cloud #security #waf \n\nA cloud native [WAF 1](WAF%201) Solution by [Azure](Cloud%20Computing/Azure/Azure.md) which protects web-apps from common cyber attacks. \nAzure WAF consists of [](Cloud%20Computing/Azure/Azure%20WAF.md#Managed%20Rules) and [](Cloud%20Computing/Azure/Azure%20WAF.md#Custom%20Rules) .which provides basic configuration such as Comprehensive protection for the Open Web Application Security Project (OWASP) top 10 security risks. \n\n\n## Managed Rules\n\n\n## Custom Rules\n\n\n\n\nREFERENCES:\nhttps://azure.microsoft.com/en-gb/pricing/details/web-application-firewall/","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Blob-Storage":{"title":"Blob Storage","content":"# Azure Blob Storage\n#Azure #cloud #storage \n\nIt is a object storage solution provided by [Azure](Cloud%20Computing/Azure/Azure.md) for cloud-native workloads, data archives, data lakes, etc. It is similar to the [S3](Cloud%20Computing/AWS/Storage/S3.md) A service offered by AWS.\n\nIt is:\nScaleWSable, durable, and available\nSecured\nOptimised for data lakes","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/CosmosDB":{"title":"CosmosDB","content":"# Cosmos DB\n#cloud #Azure #databases \n\nAzure SQL Database is a high-performance, reliable, fully managed, and secure [relational database](relational%20database) based on the latest stable version of the [Microsoft SQL Server](Microsoft%20SQL%20Server) database engine provided by [Azure](Cloud%20Computing/Azure/Azure.md). \n\nAzure Cosmos DB is flexible as it stores data in atom-record-sequence (ARS) format which is then abstracted and projected as an API, which you specify when you're creating your database. Your choices include SQL, MongoDB, Cassandra, Tables, and Gremlin. This allows the user to keep the native API (i.e. no changes to the application code).\n\n## Managed Database engines:\nAzure provides fully managed database capabilities for SQLServer, MySQL and PostgreSQL databases which provides the following benifits:\n-   Built-in high availability with no additional cost.\n-   Predictable performance and inclusive, pay-as-you-go pricing.\n-   Scale as needed, within seconds.\n-   Ability to protect sensitive data at rest and in motion.\n-   Automatic backups.\n-   Enterprise-grade security and compliance.\n\n### Azure Database for MySQL\n\nAzure Database for MySQL offers several service tiers, and each tier provides different performance and capabilities to support lightweight to heavyweight database workloads. You can build your first app on a small database for a few dollars a month, then adjust the scale to meet the needs of your solution. Dynamic scalability enables your database to transparently respond to rapidly changing resource requirements. You only pay for the resources you need, and only when you need them.\n\n\n### Azure Database for PostgreSQL\n\nAzure Database for PostgreSQL is a relational database service in the cloud. The server software is based on the community version of the open-source PostgreSQL database engine. Your familiarity with tools and expertise with PostgreSQL is applicable when you're using Azure Database for PostgreSQL.\n\nAzure Database for PostgreSQL is available in two deployment options: **Single Server** and **Hyperscale (Citus)**.\n\n**Single Server**\nAll those capabilities require almost no administration, and all are provided at no additional cost. You can focus on rapid application development and accelerating your time to market rather than having to manage virtual machines and infrastructure. You can continue to develop your application with the open-source tools and platform of your choice, without having to learn new skills.\n\nThe Single Server deployment option offers three pricing tiers: Basic, General Purpose, and Memory Optimized. Each tier offers different resource capabilities to support your database workloads. You can build your first app on a small database for a few dollars a month, then adjust the scale to meet the needs of your solution. Dynamic scalability enables your database to transparently respond to rapidly changing resource requirements. You only pay for the resources you need, and only when you need them.\n\n**Hyperscale (Citus)**\nThe Hyperscale (Citus) option horizontally scales queries across multiple machines by using sharding. Its query engine parallelizes incoming SQL queries across these servers for faster responses on large datasets. It serves applications that require greater scale and performance, generally workloads that are approaching, or already exceed, 100 GB of data.\n\nThe Hyperscale (Citus) deployment option supports multi-tenant applications, real-time operational analytics, and high-throughput transactional workloads. Applications built for PostgreSQL can run distributed queries on Hyperscale (Citus) with standard connection libraries and minimal changes.\n\n\n### Azure SQL Managed Instance (MI) \n\nSQL Managed Instance (SQL MI) provides native Virtual Network (VNet) integration while Azure SQL Database enables restricted Virtual Network (VNet) access using [VNET](Cloud%20Computing/Azure/VNET.md) Endpoints and SQL MI also helps bridge the gap between Azure SQL Database and On-premises SQL Server due to being built on an instance scoped configuration model.\n\nAzure SQL Managed Instance (MI) is similar to The Azure [SQL-Database](Cloud%20Computing/Azure/SQL-Database.md) on the following topics:\nManagement\n1. Backup\n2. Availability\n3. Host Accessibility\n4. License\n\nHowever the key differences are:\n**1. Recovery model**  \n_Azure SQL Database_: From automated backups only.  \n_SQL MI_: From automated backups and from full backups placed on Azure Blob Storage.\n\n**2. Active Geo-replication**  \n_SQL Database:_ Supported. In all service tiers other than Hyperscale.  \n_SQL MI:_ Not supported. alternative solution is [Auto-failover groups](https://docs.microsoft.com/en-us/azure/azure-sql/database/auto-failover-group-overview).\n\n**3. Auto-failover groups**  \n_SQL Database:_ Supported. In all service tiers other than Hyperscale.  \n_SQL MI:_ Supported.\n\n**4. Auto-scale**  \n_SQL Database:_ Only supported in Serverless model.  \n_SQL MI:_ Not supported. You need to choose reserved compute and storage (vCore or max storage).\n\n**5. Automatic tuning (indexes)**  \n_SQL Database:_ Supported.  \n_SQL MI:_ Not supported.\n\n**6. Elastic jobs**  \n_SQL Database:_ Supported.  \n_SQL MI:_ Not supported. [SQL Agent](https://docs.microsoft.com/en-us/azure/azure-sql/managed-instance/transact-sql-tsql-differences-sql-server#sql-server-agent) can be used instead.\n\n**7. Long-term backup retention (LTR)**  \n_SQL Database:_ Supported. keep automatically taken backups up to 10 years.  \n_SQL MI:_ Not supported yet. Manual backups as a temporary workaround.\n\n**8. Hyperscale architecture**  \n_SQL Database:_ Supported.  \n_SQL MI:_ Not supported.\n\n**9. SQL Server Profiler**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**10. Cross-database transactions**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**11. Database mail (DbMail)**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**12. Linked servers**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**13. Service Broker**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**14. SQL Server Agent**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n**15. SQL Server Auditing**  \n_SQL Database:_ Not supported.  \n_SQL MI:_ Supported.\n\n\n\n## REFERENCES:\nhttps://medium.com/awesome-azure/azure-difference-between-azure-sql-database-and-azure-sql-managed-instance-sql-mi-2e61e4485a65#:~:text=SQL%20Managed%20Instance%20(SQL%20MI)%20provides%20native%20Virtual%20Network%20(,an%20instance%20scoped%20configuration%20model.\n\n### Azure database documentation\n\n-   [Azure Analytics Services](https://azure.microsoft.com/product-categories/analytics/)\n-   [Azure Cosmos DB documentation](https://learn.microsoft.com/en-us/azure/cosmos-db/)\n-   [Azure SQL Database documentation](https://learn.microsoft.com/en-us/azure/sql-database/)\n-   [Azure SQL Managed Instance documentation](https://learn.microsoft.com/en-us/azure/azure-sql/managed-instance/)\n-   [Azure Database for MySQL documentation](https://learn.microsoft.com/en-us/azure/mysql/)\n-   [Azure Database for PostgreSQL documentation](https://learn.microsoft.com/en-us/azure/postgresql/)\n\n### Migrating database workloads to Azure\n\n-   [Migrate SQL workloads to Azure](https://learn.microsoft.com/en-us/training/paths/migrate-sql-workloads-azure/)\n-   [Migrate SQL Workloads to Azure SQL Databases](https://learn.microsoft.com/en-us/training/modules/migrate-sql-workloads-azure-sql-databases/)\n-   [Migrate SQL Workloads to Azure SQL Managed Instances](https://learn.microsoft.com/en-us/training/modules/migrate-sql-workloads-azure-managed-instances/)\n-   [Migrate on-premises MySQL databases to Azure Database for MySQL](https://learn.microsoft.com/en-us/training/modules/migrate-on-premises-mysql-databases/)\n\n### Working with Azure databases\n\n-   [Create an Azure Database for PostgreSQL server](https://learn.microsoft.com/en-us/training/modules/create-azure-db-for-postgresql-server/)\n-   [Insert and query data in your Azure Cosmos DB database](https://learn.microsoft.com/en-us/training/modules/access-data-with-cosmos-db-and-sql-api/)\n-   [Provision an Azure SQL database to store application data](https://learn.microsoft.com/en-us/training/modules/provision-azure-sql-db/)","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/DP-900":{"title":"DP 900","content":"# DP-900\n\n## Core Data related Azure Services\n\n![Pasted image 20230217231056](Microservice%20Architecture/Attachments/Pasted%20image%2020230217231056.png)\n\n![Pasted image 20230217231305](Microservice%20Architecture/Attachments/Pasted%20image%2020230217231305.png)\n\n\nAzure Storage Explorer (To explore Azure Storage accounts)\nAzure Synapse Analytics \nAzure Data Lake Storage\nAzure Data Analytics\nAzure Data Box\nAzure Databricks (Apache spark 3rd party)\nMicrosoft Power BI (Dashboards)\nHDInsight (fully managed Hadoop)\nAzure Data Studio (IDE like VSCode for data related tasks similar to SSIS)\nAzure Data Factory (ETL/ELT pipeline builder)\nSQL Server Integration Services (SSIS)\n![Pasted image 20230217231411](Microservice%20Architecture/Attachments/Pasted%20image%2020230217231411.png)\n\n## Azure Data Roles\n![Pasted image 20230217231752](Microservice%20Architecture/Attachments/Pasted%20image%2020230217231752.png)\n\n\n### Data Engineer Tools\n![Pasted image 20230217232108](Microservice%20Architecture/Attachments/Pasted%20image%2020230217232108.png)\n\n\n## Data Overview\n![Pasted image 20230217232341](Microservice%20Architecture/Attachments/Pasted%20image%2020230217232341.png)\n\n### Data \nBasically Information\n\n\n### Data Documents \nCollective Data (Datasets, Databases, Datastores, Data warehouses, notebooks)\n\n\n### Datasets \nLogical Grouping of units of data (mnist, Stackoverflow developer dataset, etc)\n![Pasted image 20230217232822](Microservice%20Architecture/Attachments/Pasted%20image%2020230217232822.png)\n\n\n### Data Structure \na specific storage format.\n- unstructured (Sharepoint, blob, azure files, Azure Data Lakes) \n- semi-structured (slight relations XML, JSON, AVRO, PARQUET) (Azure Tables, Cosmos DB, Mongo, Cassandra)\n![Pasted image 20230218001000](Microservice%20Architecture/Attachments/Pasted%20image%2020230218001000.png)\n![Pasted image 20230218001143](Microservice%20Architecture/Attachments/Pasted%20image%2020230218001143.png)\n\n![Pasted image 20230218001106](Microservice%20Architecture/Attachments/Pasted%20image%2020230218001106.png)\n- structured \nusually just tables\n\n### Data Type\nSingle unit of data to tell a computer how a data is intended to be used (Int, Float, Characters, String, Array, Hash, Binary, bool, enums etc) some of these overlap with data structures\n\n\n## Schema\nBlueprint of database\n![Pasted image 20230217233245](Microservice%20Architecture/Attachments/Pasted%20image%2020230217233245.png)\n\n### Schemaless\nA cell can accept many types related to Nosql Databases\n\n\n\n### Batch Processing\nUsually a scheduled action to process a collection of data, are cost effective and is not real-time (ie, analysing daily logs)\n\n### Stream Processing\nFor realtime data processing\nProducers send to stream and Consumer pull from stream\n\n\n### Relational Data\n**Tables**: Logical grouping of rows and columns\n**Views**: Result of query which is stored in memory (Temp table)\n**Materialized** View: similar to Views but stored on disk\n**Indexes**: copy of a column to accelerate stuff (By storing partial redundant data)\n**Constraints**: Rules for writes\n**Triggers**: A function triggered on a certain database event\n**PK/FK**: A data to create relationship between tables\n\n**Row Store**: generally used in relational database\n**Column Store**: NoSQL Faster for analytics, good for  large amounts of data (OLTP), for limited columns use\n\n**Pivot Tables**: A table of statistics easy to create in  Excel to draw attention to useful information and finding figures and facts quickly.\n\n**Data Consistency**: when data is kept in many places and weather they match or not. (Strongly consistent vs Eventually Consistent).\nSyncronous data transmissions are used in Strongly consistent data.\n\n### Non Relational Data\n- Key/Value\n- Document\n- Columnar\n- Graph\n\n### Data Sources\nWhere Data originates from, can be:\nData lake\nData warehouse\nDatastore\nDatabase\nData requested from API\nFlat Files (spreadsheet)\n\n\n### Data Store\nA repo for storing data, Database is a subset of data store\n\n### Database \nStores semi-structured or structured data\nA more complex data store with a formal design\n\n### Data Warehouse\nA relational data store for analytic workloads, utilizing usually column-oriented data-store to aggrigate huge amounts of data. they are desined to be HOT (fast). They are run in a schedule. It needs to consume data from a relational database.\n\n### Data Mart\nSubset of Datawarehouse which stores a smaller sets of data and are designed to be read only.\n\n### Data Lake\nA centralized place to store vast amount of raw data. Used for:\nVisualization\nReal-time analytics\nMachine Learning\n![Pasted image 20230218111944](Microservice%20Architecture/Attachments/Pasted%20image%2020230218111944.png)\n![Pasted image 20230218112119](Microservice%20Architecture/Attachments/Pasted%20image%2020230218112119.png)\n\n### Data Lakehouse\nCombines the best elements of Data Lakes and Data warehouse.\nSupports video, audio and text files, used for data science and ML.\nsupport for both streaming and ELT\n\n### Azure Synapse\nBasically Data Lake or LakeHouse service by Azure\n![Pasted image 20230218111352](Microservice%20Architecture/Attachments/Pasted%20image%2020230218111352.png)\n**Synapse SQL**\n- Extends TSQL for ML\n- streaming capabilities to load data\n- Integrate AI with SQL\n- Offers both serverless and dedicated resource models\n\n**Features**:\n- Integrate with Apache Spark (SparkML, )\n- Simplified resource model\n- Fast spark load\n- Built in support for dotnet\n- makes it easy to use SQL and spark\n\n### PolyBase\nData virtualization feature for Sql Server\nQuery directly TSQL from \n- SQL server\n- Oracle\n- Teradata\n- MongoDB\n- Hadoop clusters\n- Cosmos DB\n![Pasted image 20230218112328](Microservice%20Architecture/Attachments/Pasted%20image%2020230218112328.png)\ncan bu used to perform ETL transformation\n![Pasted image 20230218112430](Microservice%20Architecture/Attachments/Pasted%20image%2020230218112430.png)\n\n\n### Azure Data Lake Analytics\nOn demand analytics job service\n![Pasted image 20230218112644](Microservice%20Architecture/Attachments/Pasted%20image%2020230218112644.png)\n\n\n## Data Mining\n![Pasted image 20230218001406](Microservice%20Architecture/Attachments/Pasted%20image%2020230218001406.png)\nfind valid patterns and relationships (classification, clustering, regression, sequential, association rules, Outer Detection, Prediction).\n\n## Data Wrangling\nMatching data from raw to other format. \n\n\n## Data Modelling\nOrganizing elements of data and standardises how they relate to one another. could be conceptial, logical or physical. example a ER diagram.\n\n\n## ETL vs ELT\nused when you want to move data from one location to another. Ie moving data from relational to non relational database\n\n![Pasted image 20230218002020](Microservice%20Architecture/Attachments/Pasted%20image%2020230218002020.png)\n\n## Data Analytics\nExamining, transforming and arranging data to view useful information.\n![Pasted image 20230218002122](Microservice%20Architecture/Attachments/Pasted%20image%2020230218002122.png)\n\n**Techniques**\nDescriptive\nDiagnostic\nPredictive\nPrescriptive\nCognitive\n\n\n\n\n\n# Azure HDInsights\n![Pasted image 20230218103328](Microservice%20Architecture/Attachments/Pasted%20image%2020230218103328.png)\nCan use **Apache Ambari** an opensource Hadoop implementation\n\n**Apache spark** is a unified analytics engine for BD and ML.\n- Super fast \n\n**DataBricks** Fully managed Spark Clusters.\nAvailable on all major cloud platform.\nAzure Data Bricks is a partnership with Databricks to offer the services within Azure.\n- Azure Data-bricks Workspace (for data pipelines: Batching, Streaming, Storage)\n- Azure Database SQL Analytics (run SQL on Data Lakes, visualizations, dashboards)\n\n\n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/DP-900-cheatsheets":{"title":"DP-900 cheatsheets","content":"# Cheet Sheets\n\n**Power BI**\n![Pasted image 20230218113522](Microservice%20Architecture/Attachments/Pasted%20image%2020230218113522.png)\n![Pasted image 20230218114405](Microservice%20Architecture/Attachments/Pasted%20image%2020230218114405.png)\n![Pasted image 20230218114833](Microservice%20Architecture/Attachments/Pasted%20image%2020230218114833.png)\n\n**Data Cheetsheets**\n![Pasted image 20230218110331](Microservice%20Architecture/Attachments/Pasted%20image%2020230218110331.png)\n![Pasted image 20230218110557](Microservice%20Architecture/Attachments/Pasted%20image%2020230218110557.png)\n![Pasted image 20230218110835](Microservice%20Architecture/Attachments/Pasted%20image%2020230218110835.png)\n![Pasted image 20230218111000](Microservice%20Architecture/Attachments/Pasted%20image%2020230218111000.png)\n\n**Relational Databases**\n![Pasted image 20230218120115](Microservice%20Architecture/Attachments/Pasted%20image%2020230218120115.png)\n![Pasted image 20230218002710](Microservice%20Architecture/Attachments/Pasted%20image%2020230218002710.png)\n\n**Account Storage**\n![Pasted image 20230218113200](Microservice%20Architecture/Attachments/Pasted%20image%2020230218113200.png)\n\n**CosmosDB**\n![Pasted image 20230218121343](Microservice%20Architecture/Attachments/Pasted%20image%2020230218121343.png)\n![Pasted image 20230218121706](Microservice%20Architecture/Attachments/Pasted%20image%2020230218121706.png)\n\n\n**Azure Synapse and Data Lake**\n![Pasted image 20230218112816](Microservice%20Architecture/Attachments/Pasted%20image%2020230218112816.png)\n\n**Hadoop**\n![Pasted image 20230218122232](Microservice%20Architecture/Attachments/Pasted%20image%2020230218122232.png)\n\n**Spark and DataBricks**\n![Pasted image 20230218122602](Microservice%20Architecture/Attachments/Pasted%20image%2020230218122602.png)\n\n**SQL Management Studio (SSMS)**\n![Pasted image 20230218122457](Microservice%20Architecture/Attachments/Pasted%20image%2020230218122457.png)\n\n![Pasted image 20230218105604](Microservice%20Architecture/Attachments/Pasted%20image%2020230218105604.png)\n![Pasted image 20230218105647](Microservice%20Architecture/Attachments/Pasted%20image%2020230218105647.png)\n![Pasted image 20230218122909](Microservice%20Architecture/Attachments/Pasted%20image%2020230218122909.png)\n![Pasted image 20230218105830](Microservice%20Architecture/Attachments/Pasted%20image%2020230218105830.png)\n![Pasted image 20230218105929](Microservice%20Architecture/Attachments/Pasted%20image%2020230218105929.png)\n![Pasted image 20230218105936](Microservice%20Architecture/Attachments/Pasted%20image%2020230218105936.png)\n![Pasted image 20230218110125](Microservice%20Architecture/Attachments/Pasted%20image%2020230218110125.png)\n\n**Database Security**\n![Pasted image 20230218120454](Microservice%20Architecture/Attachments/Pasted%20image%2020230218120454.png)","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Resource-Groups":{"title":"Resource Groups","content":"# Resource Groups (Azure)\n#Azure #cloud #organization\n\nA required grouping tag for all of the [Azure](Cloud%20Computing/Azure/Azure.md) services. It helps in organizing the resources. == Microservice Architecture ==/-= AKS =-/AKS","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/SQL-Database":{"title":"SQL-Database","content":"# Azure SQL Database\n#cloud #Azure #databases \n\nAzure SQL Database is a PaaS deployment option of Azure SQL that abstracts both the OS and the SQL Server instance provided by [Azure](Cloud%20Computing/Azure/Azure.md). An Azure SQL database is a fully managed service. You don't have to deal with complex database tasks like configuring and managing high availability, tuning, and backups. The service automatically upgrades each SQL database to run the most recent version of SQL Server. You get the latest SQL Server capabilities without having to perform manual updates.\n\n![Pasted image 20221030085434](Microservice%20Architecture/Attachments/Pasted%20image%2020221030085434.png)","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/Subscriptions":{"title":"Subscriptions","content":"# Subscriptions\n#Azure #cloud \n\nAn [Azure](Cloud%20Computing/Azure/Azure.md) subscription is **a logical container used to provision resources in Azure**. It holds the details of all your resources like virtual machines (VMs), databases, and more. When you create an Azure resource like a VM, you identify the subscription it belongs to.","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/VM":{"title":"VM","content":"# VM (Virtual Macines)\n#Azure #cloud #compute \n\n\nIt is a simple compute service provided by [Azure](Cloud%20Computing/Azure/Azure.md) to host [VM](Cloud%20Computing/Azure/VM.md)s in a [VNET](Cloud%20Computing/Azure/VNET.md). Comparable to the [Elastic Compute Cloud EC2](Cloud%20Computing/AWS/Compute/Elastic%20Compute%20Cloud%20EC2.md) of AWS.\n\n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Azure/VNET":{"title":"VNET","content":"# VNET (Virtual Network)\n#Azure #cloud\n\n-   An [Azure](Cloud%20Computing/Azure/Azure.md) Virtual Network (VNet) is a network or environment that can be used to run VMs and applications in the cloud.\n-   When it is created, the services and Virtual Machines within the Azure network interact securely with each other.\n- It is similar to the [VPC](Cloud%20Computing/AWS/Networking/VPC.md) service provided by AWS\n\nAzure Virtual Network (VNet) is the fundamental building block for your private network in Azure. You can use a VNets to:\n\n-   **Communicate between Azure resources**: You can deploy VMs, and several other types of Azure resources to a virtual network, such as Azure App Service Environments, the Azure Kubernetes Service (AKS), and Azure Virtual Machine Scale Sets.\n    \n-   **Communicate between each other**: You can connect virtual networks to each other, enabling resources in either virtual network to communicate with each other, using virtual network peering. The virtual networks you connect can be in the same, or different, Azure regions.\n    \n-   **Communicate to the internet**: All resources in a VNet can communicate outbound to the internet, by default. You can communicate inbound to a resource by assigning a public IP address or a public Load Balancer. You can also use [Public IP addresses](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-public-ip-address) or public [Load Balancer](https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-overview) to manage your outbound connections.\n    \n-   **Communicate with on-premises networks**: You can connect your on-premises computers and networks to a virtual network using [VPN Gateway](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways) or [ExpressRoute](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-introduction).\n    \n\nWhen you design a network from bottom up, you gather some basic information. This information could be number of hosts, network devices, number of [subnets](subnets), routing between subnets, isolation domains such as VLANs. This information helps in sizing the network and security devices as well creating the architecture to support applications and services.\n\nWhen you plan to deploy your applications and services in Azure, you will start by creating a logical boundary in Azure, which is called a virtual network. This virtual network is akin to a physical network boundary. As it is a virtual network, you don't need physical gear but still have to plan for the logical entities such as IP addresses, IP subnets, routing, and policies.\n\nWhen you create a virtual network in Azure, it's pre-configured with an IP range (10.0.0.0/16). This range isn't fixed, you can define your own IP range. You can define both IPv4 and IPv6 address ranges. IP ranges defined for the virtual network are not advertised to Internet. You can create multiple subnets from your IP range. These subnets will be used to assign IP addresses to virtual network interfaces (vNICs). Azure reserves the first four and last IP address for a total of 5 IP addresses within each subnet. There is no concept of VLANs in a public cloud. However, you can create isolation within a virtual network based on your defined subnets.\n\nYou can create one large subnet encompassing all the virtual network address space or choose to create multiple subnets.\n\nA virtual network is a virtual, isolated portion of the Azure public network. Each virtual network is dedicated to your subscription. Things to consider when deciding whether to create one virtual network, or multiple virtual networks in a subscription:\n\n-   Do any organizational security requirements exist for isolating traffic into separate virtual networks? You can choose to connect virtual networks or not. If you connect virtual networks, you can implement a network virtual appliance, such as a firewall, to control the flow of traffic between the virtual networks. For more information, visit [security](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-vnet-plan-design-arm?toc=/azure/networking/fundamentals/toc.json) and [connectivity](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-vnet-plan-design-arm?toc=/azure/networking/fundamentals/toc.json).\n    \n-   Do any organizational requirements exist for isolating virtual networks into separate [subscriptions](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-vnet-plan-design-arm?toc=/azure/networking/fundamentals/toc.json) or [regions](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-vnet-plan-design-arm?toc=/azure/networking/fundamentals/toc.json)?\n    \n-   A [network interface](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-network-interface) enables a VM to communicate with other resources. Each network interface has one or more private IP addresses assigned to it. How many network interfaces and [private IP addresses](https://learn.microsoft.com/en-us/azure/virtual-network/private-ip-addresses) do you require in a virtual network? There are [limits](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits?toc=/azure/virtual-network/toc.json) to the number of network interfaces and private IP addresses that you can have within a virtual network.\n\n[Azure NSG](Cloud%20Computing/Azure/Azure%20NSG.md)\n\n[Azure NACL](Cloud%20Computing/Azure/Azure%20NACL.md)","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Cloud-Networking":{"title":"Cloud Networking","content":"# Cloud Networking\n#cloud #networking \n\nCloud computing has changed what we know about software design and the role/functions of data centers. The journey to the cloud begins with choosing a cloud provider and provisioning private networks or extending their on-premise network. Customers looking to provision their resources in the cloud can choose from the different private networks offered by the various cloud providers. The two most deployed private networks are Virtual Network [VNET](Cloud%20Computing/Azure/VNET.md) and Virtual Private Cloud [VPC](Cloud%20Computing/AWS/Networking/VPC.md) from Microsoft and Amazon respectively. This blog looks at the similarities and differences between these two private network offerings with the goal of informing potential customers on what differentiates the two private networks and assist in their decision on which is suitable for their workload. In this first blog in the series, I will cover some basic components of every cloud network. This current blog will not compare the pricing due to its complexity, it may be covered in a future post. In this way computer [Networking](Networking/Networking.md) could be implemented in a \n\n\n![Pasted image 20230111134110](Microservice%20Architecture/Attachments/Pasted%20image%2020230111134110.png)","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cloud-Computing/Cloud-Providers":{"title":"Cloud Providers","content":"# Cloud Providers\n#cloud #servers #vendors\n\nCloud is basically someone else's computer. This practice abstracts away the heavy configuration required to support the traditional \n\n## Benifits of Cloud Computing:\n\n1. Exchange capital data consistency model one time expense to variable timely expense\n2. Benefit from a pool of shared resources\n3. Pay for what you use\n4. Increase speed and agility of developing products\n5. Save money on operational cost of managing your own server\n6. Easy global reach\n\n## Types of Cloud Computing:\n### SaaS\n\tSoftware as a Service can be directly used by the customer.\n\n### PaaS\n\tPlatform as a Service provides an easy environment the developers can deploy their apps to.\n\n### IaaS\n\tInfrastructure as a Service barebone services that needs to be \n\n![Cloud *aaS](Cloud%20Computing/AWS/Cloud%20*aaS.png)\n## Cloud Computing Deployment Models\n\n### **Cloud**\n### **Hybrid**\n### **On-Premise**\n![cloud-stratagies](Cloud%20Computing/AWS/cloud-stratagies.png)\n\n[AWS](Cloud%20Computing/AWS/AWS.md)\n\n[Azure](Cloud%20Computing/Azure/Azure.md)\n\n[GCP](GCP)\n\n[Heroku](Heroku)\n\n[Digital Ocean](Digital%20Ocean)\n\n[Linode](Linode)\n\n[Gurka-host](Gurka-host)\n\n[Himalayan-hosts](Himalayan-hosts)\n\n[Alibaba Cloud](Alibaba%20Cloud)\n\n[Huawei Cloud](Huawei%20Cloud)\n\n\n","lastmodified":"2023-03-02T22:23:38.901538487Z","tags":null},"/Cyber-Operations/Operation-Tools/Aliases":{"title":"Aliases","content":"# Linux CLI Aliases\n#linux #cli #zsh\n\n\n\n\nhttps://blog.lftechnology.com/command-line-productivity-with-zsh-aliases-28b7cebfdff9","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Apache":{"title":"Apache","content":"# Apache\n#webserver #networking \n\n\nApache is the one of the [Webservers](Networking/Webservers.md) that processes requests and serves web assets and content via HTTP. MySQL is the database that stores all your information in an easily queried format. [PHP](PHP) is the programming language that works with apache to help create dynamic web content and is used mosty to host websites via [Linux](Cyber%20Operations/Operation%20Tools/Linux.md).","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/BASH":{"title":"BASH","content":"#cli #scripting #cli","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/CDN":{"title":"CDN","content":"#cloud #networking \n\n\n[CloudFront](Cloud%20Computing/AWS/Networking/CloudFront.md)\n[CloudFlare](Cyber%20Operations/Operation%20Tools/CloudFlare.md)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Cent-OS":{"title":"Cent OS","content":"#os","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/CloudFlare":{"title":"CloudFlare","content":"#networking \n\n[CloudFlare](Cyber%20Operations/Operation%20Tools/CloudFlare.md)\n[pagerues](Cyber%20Operations/Operation%20Tools/pagerues.md)\n[Cloudflare WAF](Cyber%20Operations/Operation%20Tools/Cloudflare%20WAF.md)\n[Custom pages](Cyber%20Operations/Operation%20Tools/Custom%20pages.md)\n[zone](Cyber%20Operations/Operation%20Tools/zone.md)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Cloudflare-WAF":{"title":"Cloudflare WAF","content":"","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Custom-pages":{"title":"Custom pages","content":"","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Debian":{"title":"Debian","content":"#os","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/IIS-Server":{"title":"IIS Server","content":"# IIS Server\n#windows #networking #webserver \n\nInternet Information Services (IIS) Internet Information Services (IIS) is a flexible, general-purpose [Webservers](Networking/Webservers.md) from Microsoft that runs on [Windows](Windows) systems to serve requested HTML pages or files. An IIS web server accepts requests from remote client computers and returns the appropriate response.","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Kali-Linux":{"title":"Kali Linux","content":"#os #cyber-security ","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Linux":{"title":"Linux","content":"#networking #networking #os \n[Aliases](Cyber%20Operations/Operation%20Tools/Aliases.md)\n[Nginx](Cyber%20Operations/Operation%20Tools/Nginx.md)\n[ZSH](Cyber%20Operations/Operation%20Tools/ZSH.md)\n[BASH](Cyber%20Operations/Operation%20Tools/BASH.md)\n[Cent OS](Cyber%20Operations/Operation%20Tools/Cent%20OS.md)\n[Debian](Cyber%20Operations/Operation%20Tools/Debian.md)\n[Kali Linux](Cyber%20Operations/Operation%20Tools/Kali%20Linux.md)\n[Pop OS](Cyber%20Operations/Operation%20Tools/Pop%20OS.md)\n[Windows Server](Cyber%20Operations/Operation%20Tools/Windows%20Server.md)\n[WSL](Cyber%20Operations/Operation%20Tools/WSL.md)\n[WSmicrosoftL2](WSmicrosoftL2)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Nginx":{"title":"Nginx","content":"# Nginx\n#networking #webserver #loadbalancer ","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Pop-OS":{"title":"Pop OS","content":"#linux #os","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/WSL":{"title":"WSL","content":"# WSL\n\n#linux #containers \n\nWSL or Windows Subsystem for Linux is a feature of [Windows](Windows) that allows developers to run a Linux environment without the need for a separate virtual machine or dual booting. There are two versions of WSL: WSL 1 and [WSL2](Cyber%20Operations/Operation%20Tools/WSL2.md).","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/WSL2":{"title":"WSL2","content":"# WSL 2\n#linux #windows #containers \n\n","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/Windows-Server":{"title":"Windows Server","content":"#os #windows","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/ZSH":{"title":"ZSH","content":"# ZSH\n\n#linix","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/pagerues":{"title":"pagerues","content":"","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Operation-Tools/zone":{"title":"zone","content":"","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Operations/Windows-Containers":{"title":"Windows Containers","content":"# Windows Containers\n#windows #os #docker \n\n\nWindows containers are a different animal than a typical [Docker](Microservice%20Architecture/Docker/Docker.md) [container](container). It requires the window's container enabled and the linux container disabled in the docker settings within a [Windows](Windows) Opereting system. It is not supported in [Linux](Cyber%20Operations/Operation%20Tools/Linux.md) officially but there is a project that aims to bridge the gap [Mono](https://hub.docker.com/_/mono/).\n\n\n","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/ABAC":{"title":"ABAC","content":"# Attribute Based Access Control\n#cloud #security\n\nUse Tags to access resources","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Active-Directory":{"title":"Active Directory","content":"# Active Directory\n#cloud-security #cyber-security \n\nActive Directory is a directory service developed by [Microsoft](Microsoft) for [Windows](Windows) domain networks. It is included in most Windows Server operating systems as a set of processes and services. Initially, Active Directory was used only for centralized domain management.\n\n![Pasted image 20230204165919](Microservice%20Architecture/Attachments/Pasted%20image%2020230204165919.png)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Auditing":{"title":"Auditing","content":"# Auditing\n#cyber-security #cloud-security \n\n[Scout Suite](Cyber%20Security/Cloud%20Security/Scout%20Suite.md)\n\n[CloudTrail](Cloud%20Computing/AWS/Monitoring/CloudTrail.md)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Authentication":{"title":"Authentication","content":"# Authentication\n#cyber-security #cloud-security\n\nAuthentication is the process of determining whether someone or something is, in fact, who or what it says it is. Authentication technology provides access control for systems by checking to see if a user's credentials match the credentials in a database of authorized users or in a data authentication server.\n\n\nAuthentication and [Authorization](Cyber%20Security/Cloud%20Security/Authorization.md) are two vital information security processes that administrators use to protect systems and information. Authentication verifies the identity of a user or service, and authorization determines their access rights.\n\nWhen you want to access a computer or device, you'll encounter a similar type of authentication. You may get asked to enter a username and password. The username states who you are, but by itself isn't enough to grant you access. When combined with the password, which only that user should know, it allows access to your systems. The username and password, together, are a form of authentication. Authentication is sometimes shortened to AuthN.","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Authorization":{"title":"Authorization","content":"# Authorization\n#cyber-security #cloud-security #rbac\n\nOnce you authenticate a user, you'll need to decide where they can go, and what they're allowed to see and touch. This process is called authorization.\n\nSuppose you want to spend the night in a hotel. The first thing you'll do is go to reception to start the \"authentication process\". After the receptionist has verified who you are, you're given a keycard and can go to your room. Think of the keycard as the authorization process. The keycard will only let you open the doors and elevators you're permitted to access, such as for your hotel room.\n\nIn cybersecurity terms, authorization determines the level of access or the permissions an authenticated person has to your data and resources. Authorization is sometimes shortened to AuthZ.","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/CIA":{"title":"CIA","content":"# Confidentiality, Integrity, Availability (CIA)\n#cyber-security #security \n\nAs described in [Defence In Depth](Cyber%20Security/Cloud%20Security/Defence%20In%20Depth.md) strategy uses a series of mechanisms to slow the advance of an attack. All the different mechanisms (technologies, processes, and training) are elements of a cybersecurity strategy, whose goals include ensuring confidentiality, integrity, and availability; often referred to as CIA.\n\n![Pasted image 20230204162218](Microservice%20Architecture/Attachments/Pasted%20image%2020230204162218.png)\nConfidentiality refers to the need to keep confidential sensitive data such as customer information, passwords, or financial data. You can encrypt data to keep it confidential, but then you also need to keep the encryption keys confidential. Confidentiality is the most visible part of security; we can clearly see need for sensitive data, keys, passwords, and other secrets to be kept confidential.\n\nIntegrity refers to keeping data or messages correct. When you send an email message, you want to be sure that the message received is the same as the message you sent. When you store data in a database, you want to be sure that the data you retrieve is the same as the data you stored. Encrypting data keeps it confidential, but you must then be able to decrypt it so that it's the same as before it was encrypted. Integrity is about having confidence that data hasn't been tampered with or altered.\n\nAvailability refers to making data available to those who need it, when they need it. It's important to the organization to keep customer data secure, but at the same time it must also be available to employees who deal with customers. While it might be more secure to store the data in an encrypted format, employees need access to decrypted data.\n\nWhile the goals of a cybersecurity strategy are to preserve the confidentiality, integrity, and availability of systems, networks, applications, and data; it's the goal of cybercriminals to disrupt these goals. Microsoft’s portfolio includes the solutions and technologies to enable organizations to deliver on the goals of the CIA triad.","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Cloud-IAM":{"title":"Cloud-IAM","content":"# Identity and Access Management\n#cyber-security #cloud-security \n\n[IAM](Cloud%20Computing/AWS/Security%20\u0026%20Identity/IAM.md)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Cloud-Security":{"title":"Cloud Security","content":"#cyber-security \n\n[Auditing](Cyber%20Security/Cloud%20Security/Auditing.md)\n[Authentication](Cyber%20Security/Cloud%20Security/Authentication.md)\n[Authorization](Cyber%20Security/Cloud%20Security/Authorization.md)\n[Cloud-IAM](Cyber%20Security/Cloud%20Security/Cloud-IAM.md)\n[Defence In Depth](Cyber%20Security/Cloud%20Security/Defence%20In%20Depth.md)\n[DMZ](Cyber%20Security/Cloud%20Security/DMZ.md)\n[Monitoring](Cyber%20Security/Cloud%20Security/Monitoring.md)\n[NAC](Cyber%20Security/Cloud%20Security/NAC.md)\n[Virtual Networks](Cyber%20Security/Cloud%20Security/Virtual%20Networks.md)\n[WAF](Cyber%20Security/Cloud%20Security/WAF.md)\n[Zero-Trust](Cyber%20Security/Cloud%20Security/Zero-Trust.md)\n[Encryption](Cyber%20Security/Encryption.md)\n[Key Storage](Key%20Storage)\n\n","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/DMZ":{"title":"DMZ","content":"#cyber-security #cloud-security #cyber-security #cloud-security # Demilitarised Zone\n#cyber-security #cloud-security #cyber-security #cloud-security ","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Defence-In-Depth":{"title":"Defence In Depth","content":"# Defence In Depth\n#cyber-security #cloud-security \n\nDefense in depth uses a layered approach to security, rather than relying on a single perimeter. A defense in-depth strategy uses a series of mechanisms to slow the advance of an attack. Each layer provides protection so that, if one layer is breached, a subsequent layer will prevent an attacker getting unauthorized access to data.\n\nExample layers of security might include:\n\n-   **Physical** security such as limiting access to a datacenter to only authorized personnel.\n-   **Identity and access** security controls, such as multifactor authentication or condition-based access, to control access to infrastructure and change control.\n-   **Perimeter** security of your corporate network includes distributed denial of service (DDoS) protection to filter large-scale attacks before they can cause a denial of service for users.\n-   **Network** security, such as network segmentation and network access controls, to limit communication between resources.\n-   **Compute** layer security such as securing access to virtual machines either on-premises or in the cloud by closing certain ports.\n-   **Application** layer security to ensure applications are secure and free of security vulnerabilities.\n-   **Data** layer security including controls to manage access to business and customer data and encryption to protect data.\n\n![Defense in depth uses multiple layers of security to protect sensitive data.](https://learn.microsoft.com/en-us/training/wwl-sci/describe-security-concepts-methodologies/media/4-defense-depth.png)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Monitoring":{"title":"Monitoring","content":"# Monitoring\n#cyber-security #cloud-security \n\n[CloudWatch](Cloud%20Computing/AWS/Monitoring/CloudWatch.md)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/NAC":{"title":"NAC","content":"# Network Access Control\n#cyber-security #cloud-security #networking \n\n[security group](Cloud%20Computing/AWS/Compute/security%20group.md)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Scout-Suite":{"title":"Scout Suite","content":"","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Virtual-Networks":{"title":"Virtual Networks","content":"# Virtual Networks\n#cyber-security #cloud-security #networking \n\n[VPC](Cloud%20Computing/AWS/Networking/VPC.md)\n[VNET](Cloud%20Computing/Azure/VNET.md)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/WAF":{"title":"WAF","content":"# WAF (Web Application Firewall)\n#cyber-security #cloud #waf #firewall \n\nIt helps protect web applications by filtering and monitoring web traffic between a web application and the internet. It is a Layer 7 (Application Level) defense in terms of [OSI](Networking/OSI.md) model. \n\nThe common attacks that a WAF can protect a web application are:\n1. [XSS](XSS) (Cross Site Scripting)\n2. [SQL Injecton](SQL%20Injecton)\n3. \n\n\n\nhttps://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/web_application_firewall_policy","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cloud-Security/Zero-Trust":{"title":"Zero-Trust","content":"# Zero Trust Policy\n#cyber-security #cloud-security \n\nThe Zero Trust framework describes a strict approach to cybersecurity in which every individual or device that attempt to access a private network, whether they are located inside or outside of that network, must be identified and authorized. Unlike other security models, which automatically trust individuals and devices that are already within the corporate network, zero trust advocates trusting no one at any time. The model was first described by John Kindervag, then a principal analyst at Forrester Research, in 2010.\n\n## Principles of Zero Trust\n\nZero Trust can best be described by the axiom “don’t trust, always verify.”\n\nIt acknowledges that traditional IT security models that seek to protect networks from outside threats but that inherently trust individuals or devices already within the network, are flawed. The reason is because that trust could be misplaced: there may be insider threats within the network in the form of an employee who wants to compromise corporate data, or a device that has been compromised by an outside attack, or a set of user security credentials that has been stolen by a bad actor outside of the organization.\n\nZero Trust proposes that by inherently trusting all users or devices within a network, traditional IT security models leave open the possibility that unchecked bad actors could roam freely within the corporate network, accessing more corporate data along the way, and raising the potential scale and severity of a cyberattack.\n\n## Zero Trust strategies\n\nBy comparison, the argument with Zero Trust is that organizations should assume their network has already been compromised and implement strategies or technologies to minimize further risk. Several of those strategies include:\n\n### Segregation of Duties (SoD) (Guiding Principals)\n\nThis principle describes the idea that no one individual or device should have full access to all of an organization’s critical IT sources. If that were to happen, then a hacker who gains control of that individual or device’s security credentials would have unfettered access to everything in the corporate network.\n\nExamples of too broad access include network firewalls and virtual private networks (VPNs). They isolate and limit access to technology resources and services but once you gain entry, you are trusted by default. \n\nAnother important dimension of SoD is that no individual should have multiple roles especially in the critical parts of the software publishing pipeline. For example, no developer should have access from test to production or be able to self-elevate privileges without proper oversight.\n\n### Least privilege access\n\nIn practice, the segregation of duties is achieved by giving each user a role with least privilege access, meaning that every user or device within the network can access only the most essential resources they need, and nothing else. The benefit is that if that user’s credentials or device is compromised by an outside attack, a hacker would only have access to that device’s environment, and nothing more than that, which reduces the potential security risk.\n\n### Microsegmentation\n\nSimilarly, the Zero Trust model favors microsegmentation, which involves splitting up the corporate IT environment into security zones and requiring separate authorization in order to access each of those zones. This practice limits the chance that a hacker could “jump” from one part of the network to another in order to access and compromise more sensitive data.\n\n### Multifactor authentication\n\nThis principle requires more than one method of authentication to verify user credentials. For example, rather than relying on a password alone, multifactor authentication might require that a user also input a secret code that has been sent to an email address or a mobile phone number that only the user should have access to.\n\n### Just-in-time access\n\n[Just-in-time access](https://www.ssh.com/academy/iam/just-in-time) is built around the idea that no user or machine identity should have permanent, always-on access to a critical resource. Instead, the identity is verified each time a connection is established but the authorization to access a resource disappears automatically after establishing the connection. This ensures that the identity requesting access goes through the required security controls every time.\n\n### Auditing and tracking\n\nA proper audit trail of activities ensures that there's always an up-to-date log of every connection along with a verified identity. Moreover, many Zero Trust solutions offer session recordings for knowing exactly what actions were taken in a session. This is very useful for forensics and for reporting in [Security Information and Event Management (SIEM)](https://www.ssh.com/academy/ssh/security-orchestration/siem) systems.\n\n### Zero Trust technologies\n\nA number of technology solutions have been created to address aspects of the Zero Trust framework, including but not limited to:\n\n-   [Cloud-IAM](Cyber%20Security/Cloud%20Security/Cloud-IAM.md)\n    \n-   [Privileged access management (PAM)](https://www.ssh.com/iam/pam)\n    \n-   Multifactor authentication\n    \n-   Encryption software\n    \n\nSSH.COM has developed a comprehensive set of Zero Trust solutions to mitigate the risk of managing digital keys, privileged passwords and other secrets (like API tokens or certificates) by greatly reducing their numbers in IT infrastructures. Learn more about the [SSH.COM's Zero Trust and Just-in-time (JIT) solutions here](https://www.ssh.com/ssh-zero-trust-access-key-and-secrets-management).","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Cyber-Security":{"title":"Cyber Security","content":"#cyber-security \n\n[Cloud Security](Cyber%20Security/Cloud%20Security/Cloud%20Security.md)\n[Standards](Cyber%20Security/Standards.md)\n\n[Digital Forensics](Digital%20Forensics)\n[Information Security](Information%20Security)\n[Threat Assessment](Threat%20Assessment)\n\n\n\n","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Encryption":{"title":"Encryption","content":"# Encryption\n#cyber-security #security #encryption \n\nEncryption is the process of making data unreadable and unusable to unauthorized viewers by using of a secret key to access the data. This ensures safety of information and sensitive information.\n\nThere are two types of encryption strategies. Symmetric encryption uses the same key to encrypt and decrypt the data. Asymmetric encryption uses a public key and private key pair. Either key can encrypt data, but a single key can’t be used to decrypt encrypted data. To decrypt, you need a paired key. Asymmetric encryption is used for things such accessing sites on the internet using the HTTPS protocol and electronic data signing solutions. Encryption may protect data at rest, or in transit.\n![Pasted image 20230204162800](Microservice%20Architecture/Attachments/Pasted%20image%2020230204162800.png)\n\n\n\n","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Encryption-at-Rest":{"title":"Encryption at Rest","content":"## Encryption for data at rest\n\n[Encryption](Cyber%20Security/Encryption.md) of data at rest ensures the data is unreadable without the keys and secrets needed to de-crypt it. If an attacker obtained a data store with encrypted data and didn't have access to the encryption keys, they would be unable to read the data.\n\n\n","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Encryption-at-transit":{"title":"Encryption at transit","content":"# Encryption at transit\n#cyber-security #encryption \n\n\n[Encryption](Cyber%20Security/Encryption.md)  ofData in transit is the data moving from one location to another, such as across the internet or through a private network. Secure transfer can be handled by several different layers. It could be done by encrypting the data at the application layer before sending it over a network. HTTPS is an example of encryption in transit.\n\nEncrypting data in transit protects it from outside observers and provides a mechanism to transmit data while limiting the risk of exposure.\n\n## Encryption for data in use\n\nA common use case for encryption of data in use involves securing data in nonpersistent storage, such as RAM or CPU caches. This can be achieved through technologies that create an enclave (think of this as a secured lockbox) that protects the data and keeps data encrypted while the CPU processes the data.","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/GDPR":{"title":"GDPR","content":"#cyber-security ","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Hashing":{"title":"Hashing","content":"## Hashing\n#cyber-security #security #encryption\n\nHashing uses an algorithm to convert text to a _unique_ fixed-length value called a hash. Each time the same text is hashed using the same algorithm, the same hash value is produced. That hash can then be used as a unique identifier of its associated data.\n\nHashing is different to [Encryption](Cyber%20Security/Encryption.md) in that it doesn't use keys, and the hashed value isn't subsequently decrypted back to the original.\n\nHashing is used to store passwords. When a user enters their password, the same algorithm that created the stored hash creates a hash of the entered password. This is compared to the stored hashed version of the password. If they match, the user has entered their password correctly. This is more secure than storing plain text passwords, but hashing algorithms are also known to hackers. Because hash functions are deterministic (the same input produces the same output), hackers can use brute-force dictionary attacks by hashing the passwords. For every matched hash, they know the actual password. To mitigate this risk, passwords are often “salted”. This refers to adding a fixed-length random value to the input of hash functions to create unique hashes for same input.\n\n![The concept of hashing](https://learn.microsoft.com/en-us/training/wwl-sci/describe-security-concepts-methodologies/media/6-hashing-3-inline.png)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/ISO-27001":{"title":"ISO 27001","content":"#cyber-security ","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/NIST":{"title":"NIST","content":"#cyber-security ","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/OWASP":{"title":"OWASP","content":"#cyber-security ","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/Cyber-Security/Standards":{"title":"Standards","content":"#cyber-security \n\n[ISO 27001](Cyber%20Security/ISO%2027001.md)\n[NIST](Cyber%20Security/NIST.md)\n[OWASP](Cyber%20Security/OWASP.md)\n\n[GDPR](Cyber%20Security/GDPR.md)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/DevOps/CICD/Azure-DevOps":{"title":"Azure DevOps","content":"# Azure DevOps\n#azure #devops\n\n\n\n![Pasted image 20221210223636](Microservice%20Architecture/Attachments/Pasted%20image%2020221210223636.png)\n\nConfiguring processes and communications\n\tConfigure activity traceability \nDesign and implement source control\nDesign and implement build and release pipelines 45%\n\n\t\nDevelop a security and compliance plan\nImplement an instrumentation strategy\n\n![Pasted image 20221210213337](Microservice%20Architecture/Attachments/Pasted%20image%2020221210213337.png)","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/DevOps/CICD/GitHub-Actions":{"title":"GitHub Actions","content":"# Github - Actions\n#CICD \n\nGitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline by [GitHub](DevOps/SCR/GitHub.md). You can create workflows that build and test every pull request to your repository, or deploy merged pull requests to production.\n","lastmodified":"2023-03-02T22:23:38.909538516Z","tags":null},"/DevOps/GitOps/Git":{"title":"Git","content":"# Git\n#git #source-control #version-control\n\n\nGit is a distributed version control system: tracking changes in any set of files, usually used for coordinating work among programmers collaboratively developing source code during software development. Its goals include speed, data integrity, and support for distributed, non-linear workflows. \n\nGit is a distributed version control system developed by Linus Torvalds, the creator of the Linux Kernel. Initially developed to assist in developing the Linux Kernel, Git is powerful and easy to use. It supports linear development, which allows more than one developer to work on the same project concomitantly. It is widely used for collaboration of Opensource projects such as [Linux](Cyber%20Operations/Operation%20Tools/Linux.md).￼\nAgain those image names need to be prefixed with mcr.microsoft.com/, and the tags are for the latest LTS release so they're moving targets - right now aspnet:3.1 is an alias for aspnet:3.1.11, but next month the same 3.1 tag will be used for an updated release.\n\ndotnet/core/runtime:3.1 has the .NET Core runtime, so you can use it for console apps;\ndotnet/core/sdk:3.1 has the SDK installed so you'll use it in the builder stage to compile .NET Core apps;\ndotnet/core/aspnet:3.1 has ASP.NET Core 3.1 installed, so you can use it to run web apps (they're still console apps in .NET Core, but the web runtime has extra dependencies).\n.NET Core 3.1 will be supported until December 2022; 2.1 is also an LTS release with support until August 2021, and there are images availabl","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/GitOps/Git-Commands":{"title":"Git - Commands","content":"# Git Commands\n#git #source-control \n\nAny [Git](DevOps/GitOps/Git.md) commands that I might need\n\n```\n\ngit config user.email \"shrestharajat@hotmail.com\"\ngit config user.name \"shrestharajat\"\n\ngit rebase -r --root --exec \"git commit --amend --no-edit --reset-author\"\n\n\ngit push origin *:*\n\ngit commit --allow-empty -m \"stash\"\n\n\n\n```","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/IAC/IaC":{"title":"IaC","content":"# Infrastructure as Code\n#devops #IaC \n\n[Terraform](DevOps/IAC/Terraform/Terraform.md)\n[Terragrunt](DevOps/IAC/Terraform/Terragrunt.md)\n[CloudFormation](Cloud%20Computing/AWS/Application%20Integration/CloudFormation.md)\n[ARM templates](ARM%20templates)\n[Bicep](Bicep)\n[Pulumi](Pulumi)","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/IAC/Packer/Packer":{"title":"Packer","content":"# Packer\n#packer #IaC #terraform \n\nPacker is an open source tool for creating identical machine images for multiple platforms from a single source configuration by hashicorp. Packer is lightweight, runs on every major operating system, and is highly performant, creating machine images for multiple platforms in parallel. Think of it as creating AMI in amazon or OS images in Azure.\n\nHere are some example to create Machine Images on Different cloud Providers:\n","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/IAC/Packer/Packer-AWS-Windows":{"title":"Packer AWS Windows","content":"# Packer: Creating a base windows server in AWS\n#cloud #hasicorp #IaC #terraform #windows \n\nThis example uses the hcl format packer file to create a [AMI](AMI) in [AWS](Cloud%20Computing/AWS/AWS.md) through [Packer](DevOps/IAC/Packer/Packer.md). This demo builds an [Windows](Windows) AMI based on windows server 2016 with containers with custom applications (Datadog agent and dotnet framework, firefox, putty, devtools).\n\n1. Set the aws credentials on the CLI\n2. Create a VPC or just use a default VPC\n3. Create a `packer.hcl` filewith the following:\n\n```hcl\nvariable \"ami_name\" {\n\ttype = string\n\tdefault = \"Win-2016-Containers-Base-{{timestamp}}\"\n}\n\nvariable \"region\" {\n\ttype = string\n\tdefault = \"eu-west-1\"\n}\n  \nvariable \"var_instance_type\" {\n\ttype = string\n\tdefault = \"c6i.large\"\n}\n\nvariable \"var_vm_base_name\" {\n\ttype = string\n\tdefault = \"WinServer-2016-English-Full-Containers\" \n}\n\nvariable \"var_vm_base_owner\" {\n\ttype = string\n\tdefault = \"amazon\"\n}\n  \ndata \"amazon-ami\" \"server_win2016_con\" {\n\tfilters = {\n\t\tname = \"${var.var_vm_base_name}*\"\n\t\troot-device-type = \"ebs\"\n\t\tvirtualization-type = \"hvm\"\n\t}\n\tmost_recent = true\n\towners = [\"${var.var_vm_base_owner}\"]\n\tregion = var.region\n}\n\nsource \"amazon-ebs\" \"windows\" {\n\tami_name = var.ami_name\n\tinstance_type = var.var_instance_type\n\tregion = var.region\n\tsource_ami = data.amazon-ami.server_win2016_con.id\n\t\n\t# Use these vars for custom vpc public sn\n\t# vpc_id = \"vpc-03e5a79ba2cf55673\"\n\t# subnet_id = \"subnet-05aed32d3db86345c\"\n\t# associate_public_ip_address = \"true\"\n\t\n\tcommunicator = \"winrm\"\n\twinrm_username = \"Administrator\"\n\twinrm_use_ssl = true\n\twinrm_insecure = true\n\tlaunch_block_device_mappings {\n\t\tdelete_on_termination = true\n\t\tdevice_name = \"/dev/sda1\"\n\t\tvolume_size = 50\n\t\tvolume_type = \"gp3\"\n\t} \n\n\ttags = {\n\t\tApprovedEnvironments = \"test\"\n\t\tApprovedInspector = \"false\"\n\t\tBuildDate = \"{{ isotime }}\"\n\t\tName = \"ebs-${var.ami_name}\"\n\t\tstable = \"false\"\n\t}\n\n\t# user data file is required for packer to connect\n\n\tuser_data_file = \"winrm_bootstrap.txt\"\n\t\n}\n\nbuild {\n\tsources = [\"source.amazon-ebs.windows\"]\n\tprovisioner \"powershell\" {\n\t\tscript = \"install.ps1\"\n\t}\n\n\tprovisioner \"powershell\" {\n\t\tinline = [\n\t\t\t# Re-initialise the AWS instance on startup\n\t\t\t\"C:/ProgramData/Amazon/EC2-Windows/Launch/Scripts/InitializeInstance.ps1 -Schedule\",\n\t\t\t\n\t\t\t# Remove system specific information from this image\n\t\t\t\"C:/ProgramData/Amazon/EC2-Windows/Launch/Scripts/SysprepInstance.ps1 -NoShutdown\"\n\t\t]\n\t}\n\n}\n```\n\n\nThen create a powershell script `install.ps1` with:\n\n``` powershell\n# Install Programs and updates\n\n[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls, [Net.SecurityProtocolType]::Tls11, [Net.SecurityProtocolType]::Tls12, [Net.SecurityProtocolType]::Ssl3\n[Net.ServicePointManager]::SecurityProtocol = \"Tls, Tls11, Tls12, Ssl3\"\n\ntry {\n\t# Install Windows update PS cmdlet\n\tWrite-Host \"Installing Windows update PS cmdlet\"\n\tInstall-Module -Name PSWindowsUpdate -Force\n\tWrite-Host \"Getting windows update\"\n\tGet-WindowsUpdate\n\tWrite-Host \"Downloading and Applying Windows Updates\"\n\tGet-WUInstall -AcceptAll -AutoReboot | Out-File C:\\PSWindowsUpdate.log\n\tWrite-Host \"Contents of the update log:\"\n\tcat C:\\PSWindowsUpdate.log\n\tWrite-Host \"Finished updating!\"\n  \n\n\t# Install Dotnet Framework\n\tWrite-Host \"Downloading dotnet_4.72\"\n\tInvoke-WebRequest -Uri \"https://download.visualstudio.microsoft.com/download/pr/158dce74-251c-4af3-b8cc-4608621341c8/9c1e178a11f55478e2112714a3897c1a/ndp472-devpack-enu.exe\" -OutFile dotnet_4_72.exe\n\tWrite-Host \"Installing dotnet_4.72\"\n\t$dotnet = (Start-Process .\\dotnet_4_72.exe -ArgumentList \"/SILENT\",\"/NORESTART\",\"/MERGETASKS=!runcode\" -NoNewWindow -Wait -PassThru)\n\tif ($dotnet.ExitCode -ne 0) {\n\t\tWrite-Error \"Error installing Dotnet4.72\"\n\t\texit 1\n\t}\n\n\t# Install DataDog Agent\n\tWrite-Host \"Downloading Datadog\"\n\tInvoke-WebRequest -Uri \"https://s3.amazonaws.com/ddagent-windows-stable/datadog-agent-7-latest.amd64.msi\" -OutFile DataDog.msi\n\tWrite-Host \"Installing Datadog\"\n\t$datadog = (Start-Process msiexec.exe -ArgumentList \"/qn\", \"/i\",\"DataDog.msi\",\"/passive\" -NoNewWindow -Wait -PassThru)\n\tif ($datadog.ExitCode -ne 0) {\n\t\tWrite-Error \"Error installing Datadog\"\n\t\texit 1\n\t}\n\tWrite-Host \"Downloading Powershell\"\n\tInvoke-WebRequest -Uri \"https://objects.githubusercontent.com/github-production-release-asset-2e65be/49609581/e4df067c-213c-4418-9ce1-194abf2f3aec?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230111%2Fus-east-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20230111T122115Z\u0026X-Amz-Expires=300\u0026X-Amz-Signature=7ef9288ef60c2113631bc06610e60d62eaaf05bba399bd36a8e9b61d9dde8375\u0026X-Amz-SignedHeaders=host\u0026actor_id=107860829\u0026key_id=0\u0026repo_id=49609581\u0026response-content-disposition=attachment%3B%20filename%3DPowerShell-7.4.0-preview.1-win-x64.msi\u0026response-content-type=application%2Foctet-stream\" -OutFile PowershellSetup.msi\n\tWrite-Host \"Installing Powershell\"\n\t$Powershell = (Start-Process msiexec.exe -ArgumentList \"/i\",\"PowershellSetup.msi\",\"/passive\" -NoNewWindow -Wait -PassThru)\n\tif ($Powershell.ExitCode -ne 0) {\n\tWrite-Error \"Error installing Powershell\"\n\texit 1\t\n\t}\n\n\tWrite-Host \"Downloading Firefox\"\n\t\n\tInvoke-WebRequest -Uri \"https://download.mozilla.org/?product=firefox-msi-latest-ssl\u0026os=win64\u0026lang=en-GB\" -OutFile FirefoxSetup.msi\n\tWrite-Host \"Installing Firefox\"\n\t$firefox = (Start-Process msiexec.exe -ArgumentList \"/i\",\"FirefoxSetup.msi\",\"/passive\" -NoNewWindow -Wait -PassThru)\n\tif ($firefox.ExitCode -ne 0) {\n\tWrite-Error \"Error installing Firefox\"\n\texit 1\n\t}\t  \n\t\n\tWrite-Host \"Downloading Putty\"\n\tInvoke-WebRequest -Uri \"https://the.earth.li/~sgtatham/putty/0.74/w64/putty-64bit-0.74-installer.msi\" -OutFile putty-installer.msi\n\tWrite-Host \"Installing Putty\"\n\t$putty = (Start-Process msiexec.exe -ArgumentList \"/i\",\"putty-installer.msi\",\"/passive\" -NoNewWindow -Wait -PassThru)\n\tif ($putty.ExitCode -ne 0) {\n\t\tWrite-Error \"Error installing Putty\"\n\t\texit 1\n\t}\n\tWrite-Host \"Downloading VSCode\"\n\t\n\tInvoke-WebRequest -Uri \"https://code.visualstudio.com/sha/download?build=stable\u0026os=win32-x64\" -OutFile VSCodeSetup.exe\n\tWrite-Host \"Installing VSCode\"\n\t$vscode = (Start-Process .\\VSCodeSetup.exe -ArgumentList \"/SILENT\",\"/NORESTART\",\"/MERGETASKS=!runcode\" -NoNewWindow -Wait -PassThru)\n\tif ($vscode.ExitCode -ne 0) {\n\t\tWrite-Error \"Error installing VSCode\"\n\t\texit 1\t\n\t}\n\n\t$vscode_extensions = @(\"ms-vscode-remote.remote-ssh\")\n\tforeach ($vse in $vscode_extensions) {\n\t\tWrite-Host \"Installing VSCode extension $vse\"\n\t\t\n\t\t# Unfortunately this always seems to return 0 even if there's an error\n\t\t$vscodeext = (Start-Process \"C:\\Program Files\\Microsoft VS Code\\bin\\code.cmd\" -ArgumentList \"--install-extension\",$vse,\"--force\" -NoNewWindow -Wait -PassThru)\n\t\tif ($vscodeext.ExitCode -ne 0) {\n\t\tWrite-Error \"Error installing VSCode extension\"\n\t\texit 1\n\t\t}\n\t}\n}\n\ncatch\n{\n\tWrite-Error $_.Exception\n\texit 1\n}\n```\n\nAlso create this file named `winrm_bootstrap.txt` with:\n```powershell\n\u003cpowershell\u003e\nwrite-output \"Running User Data Script\"\nwrite-host \"(host) Running User Data Script\"\nSet-ExecutionPolicy Unrestricted -Scope LocalMachine -Force -ErrorAction Ignore\n\n# Don't set this before Set-ExecutionPolicy as it throws an error\n$ErrorActionPreference = \"stop\"\n\n# Remove HTTP listener\nRemove-Item -Path WSMan:\\Localhost\\listener\\listener* -Recurse\n\n# Create a self-signed certificate to let ssl work\n$Cert = New-SelfSignedCertificate -CertstoreLocation Cert:\\LocalMachine\\My -DnsName \"packer\"\nNew-Item -Path WSMan:\\LocalHost\\Listener -Transport HTTPS -Address * -CertificateThumbPrint $Cert.Thumbprint -Force\n\n# WinRM\nwrite-output \"Setting up WinRM\"\nwrite-host \"(host) setting up WinRM\"\n\ncmd.exe /c winrm quickconfig -q\ncmd.exe /c winrm set \"winrm/config\" '@{MaxTimeoutms=\"1800000\"}'\ncmd.exe /c winrm set \"winrm/config/winrs\" '@{MaxMemoryPerShellMB=\"1024\"}'\ncmd.exe /c winrm set \"winrm/config/service\" '@{AllowUnencrypted=\"true\"}'\ncmd.exe /c winrm set \"winrm/config/client\" '@{AllowUnencrypted=\"true\"}'\ncmd.exe /c winrm set \"winrm/config/service/auth\" '@{Basic=\"true\"}'\ncmd.exe /c winrm set \"winrm/config/client/auth\" '@{Basic=\"true\"}'\ncmd.exe /c winrm set \"winrm/config/service/auth\" '@{CredSSP=\"true\"}'\ncmd.exe /c winrm set \"winrm/config/listener?Address=*+Transport=HTTPS\" \"@{Port=`\"5986`\";Hostname=`\"packer`\";CertificateThumbprint=`\"$($Cert.Thumbprint)`\"}\"\ncmd.exe /c netsh advfirewall firewall set rule group=\"remote administration\" new enable=yes\ncmd.exe /c netsh firewall add portopening TCP 5986 \"Port 5986\"\ncmd.exe /c net stop winrm\ncmd.exe /c sc config winrm start= auto\ncmd.exe /c net start winrm\n\n\u003c/powershell\u003e\n```\n\n\nAt last just run `packer build packer.hcl to create the ami`\n\nNote this will create a ","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/IAC/Packer/Packer-Azure-Windows":{"title":"Packer Azure Windows","content":"# Packer: Creating a generalized IIS windows server in Azure\n#cloud #hasicorp #IaC #terraform #windows \n\nThis example uses the json format packer file to create a VM Image in [Azure](Cloud%20Computing/Azure/Azure.md) through [Packer](DevOps/IAC/Packer/Packer.md). This demo builds an [Windows](Windows) Image and installs IIS server.\n\n1. Create a resource group\n2. Create azure credentials and set it in your cli \n3. Create a file named packer.json\nThis one is done in json you can also use the newer hcl\n```json\n{\n    \"builders\": [{\n      \"type\": \"azure-arm\",\n      \n      \"subscription_id\": \"2991547e-62b7-4ef8-8b12-78e8e3a9af3b\",\n      \"use_interactive_auth\" : \"true\",\n  \n      \"managed_image_resource_group_name\": \"packer-artifacts-rg\",\n      \"managed_image_name\": \"packerImage\",\n\n      \"os_type\": \"Windows\",\n      \"image_publisher\": \"MicrosoftWindowsServer\",\n      \"image_offer\": \"WindowsServer\",\n      \"image_sku\": \"2016-Datacenter\",\n  \n      \"communicator\": \"winrm\",\n      \"winrm_use_ssl\": true,\n      \"winrm_insecure\": true,\n      \"winrm_timeout\": \"5m\",\n      \"winrm_username\": \"packer\",\n  \n      \"azure_tags\": {\n          \"dept\": \"DevOps\",\n          \"task\": \"Image deployment\"\n      },\n      \"location\": \"UK South\",\n      \"vm_size\": \"Standard_D2_v2\"\n    }],\n    \"provisioners\": [{\n      \"type\": \"powershell\",\n      \"inline\": [\n        \"Add-WindowsFeature Web-Server\",\n        \"while ((Get-Service RdAgent).Status -ne 'Running') { Start-Sleep -s 5 }\",\n        \"while ((Get-Service WindowsAzureGuestAgent).Status -ne 'Running') { Start-Sleep -s 5 }\",\n        \"\u0026 $env:SystemRoot\\\\System32\\\\Sysprep\\\\Sysprep.exe /oobe /generalize /quiet /quit\",\n        \n        \"while($true) { $imageState = Get-ItemProperty HKLM:\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Setup\\\\State | Select ImageState; if($imageState.ImageState -ne 'IMAGE_STATE_GENERALIZE_RESEAL_TO_OOBE') { Write-Output $imageState.ImageState; Start-Sleep -s 10  } else { break } }\"\n      ]\n    }]\n  }\n```\n\n4. Run the packer build command `packer build packer.json`\n\nFrom: https://learn.microsoft.com/en-us/azure/virtual-machines/windows/build-image-with-packer\n","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/IAC/Terraform/Terraform":{"title":"Terraform","content":"Encription# Terraform\n#cloud #IaC #terraform \n\nTerraform is a open-source infrastructure as code [IaC](DevOps/IAC/IaC.md) tool, which enables users to safely and predictably manage infrastructure. It helps in organizing large Infrastructures by managing it as code. Terraform enables developers to use a high-level configuration language called [HCL](HCL) (HashiCorp Configuration Language) to describe the desired “end-state” cloud or on-premises infrastructure for running an application. It then generates a plan for reaching that end-state and executes the plan to provision the infrastructure.\n\n[Packer Azure Windows](DevOps/IAC/Packer/Packer%20Azure%20Windows.md) is a tool that is often used with terraform to create images (os images required for terraform) which are then used to spinup virtual machines.\n\n[AWS](Cloud%20Computing/AWS/AWS.md)\n[Azure](Cloud%20Computing/Azure/Azure.md)\n[CloudFlare](Cyber%20Operations/Operation%20Tools/CloudFlare.md)","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/IAC/Terraform/Terragrunt":{"title":"Terragrunt","content":"# Terragrunt\n#cloud #IaC #terraform #DRY\n\nA thin wrapper created around [Terraform](DevOps/IAC/Terraform/Terraform.md) that helps on keeping the cloud configuration IaC [DRY](DRY).  It is built by Gruntworks to extend the utility of terraform.\n\nI helps on:\n- Executing multiple, complex terraform command at once\n- Keeping your backend configuration DRY\n- Keeping Terraform CLI arguments DRY\n- Create custom hooks for terraform","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/IAC/Terraform/Terragrunt-Commands":{"title":"Terragrunt - Commands","content":"# Terragrunt Commands\n#terraform #IaC \n\nyou can use the following commands in console for [Terragrunt](DevOps/IAC/Terraform/Terragrunt.md):\n\nTo debug the plan process:\n\n```bash\nterragrunt plan --terragrunt-log-level debug --terragrunt-debug\n```\n\n\nTo print the secret in terraform output use:\n```bash\nterragrunt output notsosecret\n```","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/IAC/Terraform/Terragrunt-Organiztion":{"title":"Terragrunt - Organiztion","content":"# Organizaing Terragrunt\n#terraform #IaC \n\nOrganizing [Terragrunt](DevOps/IAC/Terraform/Terragrunt.md) enables us to write Dry code which could be easily be repeated to spin off multiple similar environments. For example if a company wants an app to have three separate environments in 9 different regions of the world with the same structure, using an effective terragrunt foldering stradegy can help to make this task easier as You will just have to create a common component for all of the components then spin the components of different environments in a region and just duplicate the region as a whole for example in this folder structure:\n![Pasted image 20230117160643](Microservice%20Architecture/Attachments/Pasted%20image%2020230117160643.png)\nThis will create a single environment within a single region which could easily be tweaked to create other evironments by just copying the level of folder and renaming/configuring the variables.","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/SCR/Bitbucket":{"title":"Bitbucket","content":"# BitBucket\n#source-code-repo #repo #git\n\nBitbucket is a [Git](DevOps/GitOps/Git.md) based source code repository hosting service owned by Atlassian. Bitbucket offers both commercial plans and free accounts with an unlimited number of private repositories.","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/SCR/CodeCommit":{"title":"CodeCommit","content":"# Codecommit\n#source-code-repo #repo #git #aws\n\nCodecommit is a [Git](DevOps/GitOps/Git.md) based source code repository hosting service owned by AWS. It integrates well with the [Codestar](Codestar) group of [AWS](Cloud%20Computing/AWS/AWS.md)services such as [AWS Codepipeline](DevOps/CICD/AWS%20Codepipeline.md), [AWS Codebuild](AWS%20Codebuild), etc.","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/SCR/GitHub":{"title":"GitHub","content":"# GitHub\n#git #CICD #source-code-repo #repo \n\nGitHub, Inc. is an Internet hosting service for software development and version control using [Git](DevOps/GitOps/Git.md). It provides the distributed version control of Git plus access control, bug tracking, software feature requests, task management, continuous integration, and wikis for every project.","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/DevOps/SCR/GitLab":{"title":"GitLab","content":"# GitLab\n#git #CICD #source-code-repo #repo \n\nGitLab Inc. is an open-core company that operates GitLab, a DevOps software package which can develop, secure, and operate software.  Similar to Github it is also an Internet hosting service for software development and version control using [Git](DevOps/GitOps/Git.md).","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/Microservice-Architecture/AKS/AKS":{"title":"AKS","content":"# AKS\n#Azure #cloud #Kubernetes #microservices #managed-kubernetes-cluster\n\nAKS is a fully managed [Kubernetes](Microservice%20Architecture/Kubernetes/Kubernetes.md) container management service by Microsoft [Azure](Cloud%20Computing/Azure/Azure.md). Along with [Azure DevOps](DevOps/CICD/Azure%20DevOps.md) It offers a robust Serverless Continios Integration and Contious Deployment experience. \n\nIn AKS the users will just need to pay for the nodes that are being used. Which means the other services such as the Azure managed Control pane is free AKSAKSof cost.\n\n## Control plane\nWhen you create an AKS cluster, a control plane is automatically created and configured. This control plane is provided at no cost as a managed Azure resource abstracted from the user. You only pay for the nodes attached to the AKS cluster. The control plane and its resources reside only on the region where you created the cluster.\n\n![Pasted image 20220928225117](Microservice%20Architecture/Attachments/Pasted%20image%2020220928225117.png)\n\n\n## Node pools\nNode pools use virtual machine scale sets as the underlying infrastructure to allow the cluster to scale the number of nodes in a node pool. New nodes created in the node pool will always be the same size as you specified when you created the node pool.\n![Pasted image 20220930162008](Microservice%20Architecture/Attachments/Pasted%20image%2020220930162008.png)\n\n\n## Networking\nAn Azure Kubernetes Service (AKS) cluster blocks all inbound traffic from the internet to the cluster to assure network security. Deployed workloads in Kubernetes are, by default, only accessible from inside the cluster. To expose the applications to the outside world, you need to open specific ports and forward them to your services. The network configuration for containers is temporary. A container's configuration and the data in it isn't persistent between executions. After you delete a container, all information is gone unless it's configured to use a volume. The same applies to the container's network configuration and any IP addresses assigned to it.\n\nKubernetes has two network availability abstractions that allow you to expose any app: _services_ and _ingresses_ They're both responsible for allowing and redirecting the traffic from external sources to the cluster.\n\n## Service\nA Kubernetes service is a workload that abstracts the IP address for networked workloads. A Kubernetes service acts as a load balancer and redirects traffic to the specified ports by using port-forwarding rules.\n\nA diagram that shows two Kubernetes services. The first service is applied to one pod. The second service is applied to two pods.\n\nYou define a service in the same way as a deployment, by using a YAML manifest file. The service uses the same selector key as deployments to select and group resources with matching labels into one single IP.\n\nA Kubernetes service needs four pieces of information to route traffic.\n\n| Information|Description     |\n| --- | --- |\n|  **Target resource** |The target resource is defined by the `selector` key in the service manifest file. This value selects all the resources with a given label onto a single IP address.       |\n|**Service port** |This port is the inbound port for your application. All the requests come to |this port from where the service forwards the requests to the resource.\n|**Network protocol** |This value identifies the network protocol for which the service will forward network data.|\n|**Resource port** | This value identifies the port on the target resource on which incoming requests are received. This port is defined by the `targetPort` key in the service manifest file. |\n### Types of services:\n\nServices can be of several types. Each type changes the behavior of the applications selected by the service.\n\n-   **ClusterIP**: This value exposes the applications internally only. This option allows the service to act as a port-forwarder and makes the service available within the cluster. This value is the default when omitted.\n    \n-   **NodePort**: This value exposes the service externally. It assigns each node a static port that responds to that service. When accessed through `nodeIp:port`, the node automatically redirects the request to an internal service of the `ClusterIP` type. This service then forwards the request to the applications.\n    \n-   **LoadBalancer**: This value exposes the service externally by using Azure's load-balancing solution. When created, this resource spins up an Azure Load Balancer resource within your Azure subscription. Also, this type automatically creates a `NodePort` service to which the load balancer's traffic is redirected and a `ClusterIP` service to forward it internally.\n    \n-   **ExternalName**: This value maps the service by using a DNS resolution through a CNAME record. You use this service type to direct traffic to services that exist outside the Kubernetes cluster.\n\n## Ingress Controller\nIngress controllers provide the capability to deploy and expose your applications to the world without the need to configure network-related services. \n\nIngress controllers create a reverse-proxy server that automatically allows for all the requests to be served from a single DNS output. You don't have to create a DNS record every time a new service is deployed. The ingress controller will take care of it. When a new ingress is deployed to the cluster, the ingress controller creates a new record on an Azure managed DNS zone and links it to an existing load balancer. This functionality allows for easy access to the resource through the internet without the need for additional configuration.\n\n- Acts as a reverse proxy to allow external URLs.\n- Might act as a load balancer.\n- Terminates SSL/TLS requests.\n- Offers name-based virtual hosting.\n\n![Pasted image 20220930162708](Microservice%20Architecture/Attachments/Pasted%20image%2020220930162708.png)\n\n![Pasted image 20220930162112](Microservice%20Architecture/Attachments/Pasted%20image%2020220930162112.png)\n\n\n## Demo\nTo setup a basic AKS cluster which simply hosts a static webapp.\n\n### Requirements\n1. An Azure subscription with basic authority to create AKS cluster and related services (i.e. Compute instances, Container Registry).\n\n\n### Steps:\n1. Create a resource group to organize the azure services that are going to be used in the project.\n2. Create the cluster\n\t\t- Select the resource-group for the AKS Cluster\n\t\t- Fill in the basic stuffs (Cluster name, Region, Kubernetes version)\n\t\t- Create only 1 node\n\t\t- Configure other settings (node-pools, authentication, networking, Integration and tags)\n\t\t- Create the cluster\n3.  copy the [azure-vote deployment yml](https://github.com/Azure-Samples/azure-voting-app-redis/blob/master/azure-vote-all-in-one-redis.yaml) and apply it\nTODO: modify yml to run simple nginx webserver to host a page\n\n```bash\n# create a container registry and resource group\naz group create --name test-nginx --location uksouth\naz acr create --resource-group test-nginx \\\n--name testNginx --sku Basic\n\n# upload docker image to acr\ncd ~/Documents/nginx-example\naz acr build --image testnginx \\\n--registry testNginx \\\n--file dockerfile .\n\n#  create a aks cluster\naz group create --name test-nginx --location uksouth\naz aks create --resource-group test-nginx --name nginx-cluster --node-count 2 --enable-addons monitoring --generate-ssh-keys\n\n# after setting up the cluster set the local cli scubcription for the kubectl\naz account set --subscription xxxxxxxxxxxxx\naz aks get-credentials --resource-group test-nginx --name nginx-cluster\n# after running the previous command your local machine \n# will have access to the kubernetes api and you can finally run kubectl command\n\n# download the azure-vote yml\ncurl https://raw.githubusercontent.com/Azure-Samples/azure-voting-app-redis/master/azure-vote-all-in-one-redis.yaml \u003e azure-vote.yml\n\n# apply the azure-vote.yml deployment\nkubectl apply -f azure-vote.yml\n\n# fetch the ip of the loadbalancer \nget svc azure-vote-front --watch\n\n```\n\n## References\nhttps://learn.microsoft.com/en-us/azure/aks/concepts-clusters-workloads\nhttps://github.com/Azure-Samples/azure-voting-app-redis/blob/master/azure-vote-all-in-one-redis.yaml\nhttps://github.com/Azure-Samples/azure-voting-app-redis\nhttps://collabnix.github.io/kubelabs/pods101/deploy-your-first-nginx-pod.html\nhttps://learn.microsoft.com/en-us/training/modules/aks-deploy-container-app\n","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/Microservice-Architecture/AKS/AKS-Automatic-Deployments":{"title":"AKS - Automatic Deployments","content":"# AKS Automatic Deployments setup\n#Azure #AKS #Kubernetes \n\nFor Creating a [AKS](Microservice%20Architecture/AKS/AKS.md) cluster with Automatic deployments:\n\n## Requirements:\n- A valid Azure subscription\n- kubectl installed  \n- azure-cli installed\n\n\n## Steps:\n1. Create a resource group, acr and aks:\n```bash\naz group create --name test-nginx --location uksouth\n\naz acr create --resource-group test-nginx --name shrestharajat --sku Basic\n\naz aks create --resource-group test-nginx --name nginx-cluster --node-count 1 --enable-addons monitoring\n```\n\n2. Link the ACR to AKS\n```bash\naz aks update -n nginx-cluster -g test-nginx --attach-acr shrestharajat\n```\n\n3. Push an initial image to ACR\n```bash\naz acr build --image nginx/testnginx:latest --registry shrestharajat --file Dockerfile .\n```\n\n4. Create and setup automatic deployment via azure portal\n\t- Go to cluster\u003eautomatic deployments\u003ecreate cluster \n\t- Select a github workflow name same as the deployment name\n\t- Select repo and branch\n\t- Go to Image settings after setting repo\n\t- Select Dockerfile\n\t- Select ACR and image repository image\n\t- Go to Deployment details\n\t- Select Kubernetes manifest\n\t- Select the deployment yml file\n\t- Select default namespace (Do not create a new one)\n\t- Review and create\n\t- After a while, a pull request will be created\n\t- Go to your github repo and accept the pull request\n\t[If you do not want to use the default namespace you will need to define a new service and ingress](https://learn.microsoft.com/en-us/training/modules/aks-deploy-container-app/7-exercise-expose-app)\n\n5. Enable the Github action to fetch the image by setting ACR credentials on GHA secrets\n\t1.  On the repository start page, select the **Settings** tab. In the menu, select **Secrets**.\n\t2. Set the following secrets:\n\t\tACR_NAME = shrestharajat\n\t\tACR_LOGIN = shrestharajat\n\t\tACR_PASSWORD = xxxxxxxxxxxxxxxxxxxx\n\tTo get these values you can use the following commands:\n```bash\n# ACR_NAME\naz acr list --query \"[?contains(resourceGroup, 'test-nginx')].loginServer\" -o table\n\n# ACR_LOGIN\naz acr credential show --name shrestharajat.azurecr.io --query \"username\" -o table\n  \n# ACR_PASSWORD\naz acr credential show --name shrestharajat.azurecr.io --query \"passwords[0].value\" -o table\n```](\u003cFor Creating a AKS cluster with Automatic deployments:\n\n## Requirements:\n- A valid Azure subscription\n- kubectl installed  \n- azure-cli installed\n\n\n## Steps:\n1. Create a resource group, acr and aks:\n```bash\naz group create --name test-nginx --location uksouth\n\naz acr create --resource-group test-nginx --name shrestharajat --sku Basic\n\naz aks create --resource-group test-nginx --name nginx-cluster --node-count 1 --enable-addons monitoring\n```\n\n2. Link the ACR to AKS\n```bash\naz aks update -n nginx-cluster -g test-nginx --attach-acr shrestharajat\n```\n\n3. Push an initial image to ACR\n```bash\naz acr build --image nginx/testnginx:latest --registry shrestharajat --file Dockerfile .\n```\n\n4. Create and setup automatic deployment via azure portal\n\t- Go to cluster%3Eautomatic deployments\u003ecreate cluster \n\t- Select a github workflow name same as the deployment name\n\t- Select repo and branch\n\t- Go to Image settings after setting repo\n\t- Select Dockerfile\n\t- Select ACR and image repository image\n\t- Go to Deployment details\n\t- Select Kubernetes manifest\n\t- Select the deployment yml file\n\t- Select default namespace (Do not create a new one)\n\t- Review and create\n\t- After a while, a pull request will be created\n\t- Go to your github repo and accept the pull request\n\t[If you do not want to use the default namespace you will need to define a new service and ingress](https://learn.microsoft.com/en-us/training/modules/aks-deploy-container-app/7-exercise-expose-app)\n\n5. Enable the Github action to fetch the image by setting ACR credentials on GHA secrets\n\t1.  On the repository start page, select the **Settings** tab. In the menu, select **Secrets**.\n\t2. Set the following secrets:\n\t\tACR_NAME = shrestharajat\n\t\tACR_LOGIN = shrestharajat\n\t\tACR_PASSWORD = xxxxxxxxxxxxxxxxxxxx\n\tTo get these values you can use the following commands:\n```bash\n# ACR_NAME\naz acr list --query \"[?contains(resourceGroup, 'test-nginx')].loginServer\" -o table\n\n# ACR_LOGIN\naz acr credential show --name shrestharajat.azurecr.io --query \"username\" -o table\n  \n# ACR_PASSWORD\naz acr credential show --name shrestharajat.azurecr.io --query \"passwords[0].value\" -o table\n```\n\n\n## Msic commands:\n```bash\n# set context\naz aks get-credentials --resource-group test-nginx --name nginx-cluster\nkubectl config view\n\n# Get the svc and pod details\nkubectl get svc\nkubectl get pods -o wide\n\n# apply the deployments locally\nkubectl apply -f ./nginx-test.yml\n```","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/Microservice-Architecture/AKS/AKS-Full-Demo":{"title":"AKS - Full Demo","content":"￼ # AKS Full Demo\n\n#Azure #Kubernetes #AKS #Nginx #Helm #Ingress #TLS #CICD\n[AKS](Microservice%20Architecture/AKS/AKS.md)\nAKS Full demo with following features:\n\n- Good Namespace organization\n- Nginx Ingress controller\n- host based ingress routing (redirecting to at least 2 pods)\n- TLS termination using ingress\n- Helm to manage all of the yml files\n- Automated deployments \n\n## Steps:\n\n### Step 1: Create a cluster in Azure\nTo create a cluster in azure you will require a valid azure subscription. Additional tools such as azcli, kubectl and helm is reccomended to be installed. Follow the Instructions on the main [AKS - Full Demo](Microservice%20Architecture/AKS/AKS%20-%20Full%20Demo.md) note.\n\n\n### Step 2: Configure Ingress Controller\nAfter creating the cluster you will then need an ingress controller which will link up the Azure Loadbalancer with the AKS cluster. luckily, this is fairly simple to setup and will require only helm to setup. This will essentially install the Ingress controller which can then be used to setup Several ingress service. Follow the guide [AKS - Ingress Controller](Microservice%20Architecture/AKS/AKS%20-%20Ingress%20Controller.md) to install, configure, and run apps with a public IP\n\n\n","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/Microservice-Architecture/AKS/AKS-Ingress-Controller":{"title":"AKS - Ingress Controller","content":"￼ ￼ # Ingress controller in AKS\n#Azure #Kubernetes #AKS #Nginx\n\n[AKS](Microservice%20Architecture/AKS/AKS.md)\nIt is used to configure reverse proxy, configurable traffic routing, and TLS termination for [Kubernetes](Microservice%20Architecture/Kubernetes/Kubernetes.md) services.\n\nIt helps expose routes to public from various different apps hosted within a cluster.\n\n## Usage:\n1. Use a single IP address to route traffic to different services\n2. For TLS termination\n3. To perform path or host based traffic routing\n\n## Architecture:\n![Pasted image 20221012140156](Microservice%20Architecture/Kubernetes/Pasted%20image%2020221012140156.png)\n\n## Demo:\n\nA simple demo to show the routing of traffic using a path based routing on the IP address of the loadbalancer.\n\n### Requirements:\n\n**Tools:**\n1. azcli\n2. kubectl\n3. helm\n\n**Other:**\n1. A valid azure subscription\n2. kubectl context set to the cluster\n\n### Steps:\n1. Create two deployment yml files for the demo applications:\n```bash\n\ncat hw1.yml \u003c\u003c EOF\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: aks-helloworld-one  \nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aks-helloworld-one\n  template:\n    metadata:\n      labels:\n        app: aks-helloworld-one\n    spec:\n      containers:\n      - name: aks-helloworld-one\n        image: mcr.microsoft.com/azuredocs/aks-helloworld:v1\n        ports:\n        - containerPort: 80\n        env:\n        - name: TITLE\n          value: \"Hello world 1\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: aks-helloworld-one  \nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n  selector:\n    app: aks-helloworld-one\n\nEOF\n```\n```bash\ncat hw2.yml \u003c\u003c EOF\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: aks-helloworld-two  \nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aks-helloworld-two\n  template:\n    metadata:\n      labels:\n        app: aks-helloworld-two\n    spec:\n      containers:\n      - name: aks-helloworld-two\n        image: mcr.microsoft.com/azuredocs/aks-helloworld:v1\n        ports:\n        - containerPort: 80\n        env:\n        - name: TITLE\n          value: \"Hello world 2!\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: aks-helloworld-two  \nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n  selector:\n    app: aks-helloworld-two\n\nEOF\n```\n2. Switch to the hello-world namespace and apply the deployments\n```bash\nkubectl create namespace hello-world\nkubectl config set-context --current --namespace=hello-world\nkubectl create -f hw1.yml\nkubectl create -f hw2.yml\n```\n3. Install the nginx-ingress on a seprate namespace using helm\n```bash\n# create a new namespace, and use helm to install ingress\nNAMESPACE=ingress-basic\n\nhelm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\nhelm repo update\n\nhelm install ingress-nginx ingress-nginx/ingress-nginx \\ --create-namespace \\ --namespace $NAMESPACE \\ --set controller.service.annotations.\"service\\.beta\\.kubernetes\\.io/azure-load-balancer-health-probe-request-path\"=/healthz\n```\n4. Create a hello world ingress yml file and deploy it\n```bash\ncat hw-ingress.yml \u003c\u003c EOF\n\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: hello-world-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /hello-world-one(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: aks-helloworld-one\n            port:\n              number: 80\n      - path: /hello-world-two(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: aks-helloworld-two\n            port:\n              number: 80\n      - path: /(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: aks-helloworld-one\n            port:\n              number: 80\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: hello-world-ingress-static\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n    nginx.ingress.kubernetes.io/rewrite-target: /static/$2\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /static(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: aks-helloworld-one\n            port: \n              number: 80\n\nEOF\n```\n\n`kubectl create -f hello-world-ingress.yml`\n\n### Debugging commands:\n```bash\n# To view the running pods:\nkubectl get po\nkubectl get po --all-namespaces\n\n# To view services:\nkubectl get svc\nkubectl get svc --all-namespaces\n\n## To view ingress:\nkubectl get ingress\nkubectl get ingress --all-namespaces\n\n## To view all of these at the same time\nkubectl get ingress,po,svc\nkubectl get ingress,po,svc --all-namespaces\n\n## To view the current config on kubectl\nkubectl view config\n\n## To delete config contexts, users, and clusters\nkubectl config unset clusters\nkubectl config unset contexts\nkubectl config unset users\n\n```\n","lastmodified":"2023-03-02T22:23:38.91353853Z","tags":null},"/Microservice-Architecture/Docker/Containers":{"title":"Containers","content":"","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Docker/Docker":{"title":"Docker","content":"# Docker\n#containers #virtual-machines #docker\n\n\nDocker is an open source platform for building, deploying, and managing containerized applications. Docker is simply a popular implementation of [Containers](Microservice%20Architecture/Docker/Containers.md) and has become a standard in the industry.\n\nDocker uses a client-server architecture. The Docker _client_ talks to the [Docker - Daemon](Microservice%20Architecture/Docker/Docker%20-%20Daemon.md), which does the heavy lifting of building, running, and distributing your Docker containers. The Docker client and daemon _can_ run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface. Another Docker client is Docker Compose, that lets you work with applications consisting of a set of containers.\n![Pasted image 20221017160401](Microservice%20Architecture/Attachments/Pasted%20image%2020221017160401.png)","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Docker/Docker-Compose":{"title":"Docker - Compose","content":"# Docker compose\n#docker #containers \n\nIt is a tool for defining and running multi-container [Docker](Microservice%20Architecture/Docker/Docker.md) applications. With Compose, you use a YAML file to configure your application's services.\n\nIf you want to setup multi container application which requires different container components stiched together, docker-compose provides the functionality to make this happen. \n\nCompose revolves around a config file called `docker-compose.yml`. In it we define all of our services. Think of a service as a part of your application; a database or API for example. All of our services rely on an image with which we create a container. Spinning up a container can have many options; how these options are configured will be stored in the yml file.\n\n\n![Pasted image 20221017161114](Microservice%20Architecture/Attachments/Pasted%20image%2020221017161114.png)\n\n## Features:\n-   [Multiple isolated environments on a single host](https://docs.docker.com/compose/#multiple-isolated-environments-on-a-single-host)\n-   [Preserve volume data when containers are created](https://docs.docker.com/compose/#preserve-volume-data-when-containers-are-created)\n-   [Only recreate containers that have changed](https://docs.docker.com/compose/#only-recreate-containers-that-have-changed)\n-   [Variables and moving a composition between environments](https://docs.docker.com/compose/#variables-and-moving-a-composition-between-environments)\n\n\n\nhttps://towardsdatascience.com/docker-compose-for-absolute-beginners-how-does-it-work-and-how-to-use-it-examples-733ca24c5e6c","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Docker/Docker-Containers":{"title":"Docker - Containers","content":"# Docker Containers\n#docker #containers \n\nA [container](container) spun from a [Docker - Images](Microservice%20Architecture/Docker/Docker%20-%20Images.md) is called a docker container. An image is essential to create one or multiple [Docker](Microservice%20Architecture/Docker/Docker.md) containers. A docker container could be in running or stopped state.","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Docker/Docker-Daemon":{"title":"Docker - Daemon","content":"# Docker Daemon\n#dockercybersec\n\nDocker daemon or dockerd is the persistent process that manages containers. [Docker](Microservice%20Architecture/Docker/Docker.md) uses different binaries for the daemon and client. To run the daemon you type dockerd.\nThe Docker daemon (`dockerd`) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.\n\nIt is basically the main service responsible for managing all of the containers, images, volumes, networks, contexts, etc.\n\n\n\nhttps://docs.docker.com/engine/reference/commandline/dockerd/","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Docker/Docker-Images":{"title":"Docker - Images","content":"# Docker images\n#containers #docker #images\n\nA docker image is simply a package with all the dependencies and information needed to create a [container](container) in [Docker](Microservice%20Architecture/Docker/Docker.md). An image includes all the dependencies (such as frameworks) plus deployment and execution configuration to be used by a container runtime. Usually, an image derives from multiple base images that are layers stacked on top of each other to form the container's filesystem. An image is immutable once it has been created.\n\n\n## Dockerfile\nDocker images are built with a simple text file containing instructions for how to build the Docker container image. It contains a list of command-line interface (CLI) instructions that Docker Engine will run in order to assemble the image.","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Docker/Docker-Swarm":{"title":"Docker - Swarm","content":"# Docker Swarm\n#docker #containers #container-orchestration\n\n\nA Docker Swarm is a group of either physical or virtual machines that are running the [Docker](Microservice%20Architecture/Docker/Docker.md) application and that have been configured to join together in a cluster. The activities of the cluster are controlled by a swarm manager, and machines that have joined the cluster are referred to as nodes.\n\n\nDocker Swarm is an alternative [Container orchestration](Container%20orchestration) platform to [Kubernetes](Microservice%20Architecture/Kubernetes/Kubernetes.md)\nThe major difference between the platforms is based on complexity. Kubernetes is well suited for complex applications. On the other hand, Docker Swarm is designed for ease of use, making it a preferable choice for simple applications.","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Kubernetes/Helm":{"title":"Helm","content":"# Helm\n#kubernetes #Helm\n\nHelm is basically a package manager for [Kubernetes](Microservice%20Architecture/Kubernetes/Kubernetes.md) which is used to automates the process of installing, upgrading, configuring, and removing software in a consistent manner. It is used to package yaml files and distribute them in public / private repositories,  manage/create kubernetes deployments with one command.\n\nIt is quite powerful due to its templeting capabilities. You can use helm to define multiple pod/service/ingress definition using a [DRY](DRY) template which helps you use a single file to configure common variables that could be interchanged throughout  the operation of the application on the cluster.\n\nSome of the tasks that helm enables us to do are:\n-   create new charts from scratch\n-   package charts into chart archive (tgz) files\n-   interact with chart repositories where charts are stored\n-   install and uninstall charts into an existing Kubernetes cluster\n-   manage the release cycle of charts that have been installed with Helm\n\n## Helm Client\n Helm client is a command-line tool for end user which aids in:\n-   local chart development\n-   managing repositories\n-   managing releases\n-   interfacing with the Helm library\n-   sending charts to be installed\n-   requesting upgrading or uninstalling of existing releases\n\n## Helm Library\nHelm Library are the projects that provides the logic for executing all Helm operations and  interfaces with the Kubernetes API server. It also help  provides the following capability:\n     -   combining a chart and configuration to build a release\n     -   installing charts into Kubernetes, and providing the subsequent release object\n     -   upgrading and uninstalling charts by interacting with Kubernetes\n","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Kubernetes/Kubernetes":{"title":"Kubernetes","content":"what does waf do# Kubernetes\n\n#kubernetes #cloud-native #microservices #containers\n\nAn opensource Container Management or Container **Orchestration tool** which basically automates the operations related to [Containers]. Basic usage of kubernetes is to automate [container](container) deployment, auto-scaling, operating, and managing it. In most cases it works by running [Docker](Microservice%20Architecture/Docker/Docker.md) containers on top of [Docker - Daemon](Microservice%20Architecture/Docker/Docker%20-%20Daemon.md) setup on top of nodes in the cluster.\n\nIt is developed by google and is later donated to CNCF. It is fully opensource and is made using [golang](golang). Kubernetes is often abbreviated as **K8s**.\n\n![Pasted image 20221016000801](Microservice%20Architecture/Attachments/Pasted%20image%2020221016000801.png)\n\n\n## Key words\n1. Cluster: Group of Nodes which are interconnected.\n2. Node: A single compute unit (virtual or bare-metal) which helps to host containers inside of them.\n3. Master: Master node which controls the cluster.\n4. Service: An object on Master that provides load-balancing across a replicated groups of pods or a single pod.\n5. Replication Controller: It ensures the normal operation of the applications by managing the normal operations of the pods.\n6. Worker Nodes: A basic compute unit which help host pods. It as a kubernetes application (Kubelet) which helps the communication between the main master node but doesn't have the main kubernetes daemon on it. The worker node will also contain docker Daemon which enables the use of containers.\n7. Deployment: xxxxxxxxxxxxxxx\n8. \n9. Pods: A Logical collection of containers which forms a basic application.\n10. [Containers]: A simple package of application and its dependencies created to do something.\n11. Container Registry: \n\n*Some of these services are explored in detail later on this document*\n\n*Kubernetes requires at least a node in which the Kubernetes master is installed at which then controls any additional nodes.*\n\n## How it works\nKubernetes works with the help of a main Kubenetes master application which runs on a computer. The main Kubernetes master is also known as a master nodes. It then manages other nodes also known as Worker nodes. The master node contains the main kubernetes master service which provides the user with essential API to do various operations to the services that takes instructions from the main administrator and operated accordingly. Another key component of the kubernetes is the Image Registry service which is usually third party. Image registry is bacially a repository for container images usually docker.\n\nAll of these services work together to form a basic kubernetes workflow with the API provided by the master node Kubernetes daemon, Image registry providing the container images with essential application files and instructions, master nodes, and worker nodes.\n\n![Pasted image 20220928221909](Microservice%20Architecture/Attachments/Pasted%20image%2020220928221909.png)\n\nA general kubernetes cluster consists of the following components:\n1. Master Node ((*Required*) A node with Kubernetes Master installed)\n2. Worker Nodes (Other nodes which provides the compute capabilities to the applications)\n\n![Pasted image 20220928223829](Microservice%20Architecture/Attachments/Pasted%20image%2020220928223829.png)\n\n\nKubernetes allows us to auto scale application automatically, by creating them from a container registry, manage them, enable several modes of communication between the containers, and also give the admin the options to secure their resources. \n\n![Pasted image 20220928221530](Microservice%20Architecture/Attachments/Pasted%20image%2020220928221530.png)","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Kubernetes/Kubernetes-Secret":{"title":"Kubernetes Secret","content":"# Kubernetes Secrets\n#Kubernetes #microservices #security \n\nThere are various types of secrets in [Kubernetes](Microservice%20Architecture/Kubernetes/Kubernetes.md). ","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Microservice-Architecture/Kubernetes/Minikube":{"title":"Minikube","content":"what does waf do# Minikube\n#Kubernetes #containers #docker #cli\n\nIt is a simple local [Kubernetes](Microservice%20Architecture/Kubernetes/Kubernetes.md) setup designed to make learning kubernetes easier and accessible. It runs on top of [Docker](Microservice%20Architecture/Docker/Docker.md) engine to create a container which acts as the \n","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Networking/DNS":{"title":"DNS","content":"# DNS\n#networking \n\nDomain Name System (DNS) is a service which handles converting a domain name into a routable[#Internet Protocol IP address](#Internet%20Protocol%20IP%20address), allowing your personal computer to access the specific servers.\n\n## Internet Protocol (IP) address\nIt is the unique identifier of each computer in a network to allow communication between them\n\n### IPv4\nAddress space with 32 bits with upto 4,294,967,296 available addresses\n\n\n### IPv6\nAddress space is 128-bits long with 340 undecillion ips.\n\n\n## Domain Registrars\nDomain registrars are authorities who have the ability to assign domain names under one or more top-level domains.\n\nDomains get registered through InterNIC, Which is a service provided by the Internet Corporation (ICANN), and enforces the uniqueness of domain names all over the internet.\n\nAfter registration all domain names can be found publicly in a central WhoIS database.\n\n\n## Top-Level Domains\n\nThe last work with a domain name represents the top-level domain name eg: `example.com`\n\nthe second word within a domain name is known as the second-level domain name eg `example.co.uk`\n\n\nTop-level domain names are controlled by the Internet Assigned Numbers Authority (IANA)\n\nAll available top level domains are stored in a publicly available database at:\nhttp://www.iana.org/domains/root/db\n\n\n\n## Start of Authority (SOA)\n\nEvery domain must have a SOA record. The SOA is a way for the Domain Admins to provide information about the domain eg. how often it is updated, what is the admin's email address and etc.\n\n## What is a DNS SOA record?\n\nThe [DNS](https://www.cloudflare.com/learning/dns/what-is-dns/) ‘start of authority’ (SOA) record stores important information about a [domain](https://www.cloudflare.com/learning/dns/glossary/what-is-a-domain-name/) or [zone](https://www.cloudflare.com/learning/dns/glossary/dns-zone/) such as the email address of the administrator, when the domain was last updated, and how long the server should wait between refreshes.\n\nAll DNS zones need an SOA record in order to conform to IETF standards. SOA records are also important for zone transfers.\n\nExample of an SOA record:\n\n---------\n| Name:       |     example.com                |\n| ----------- | -------------------- |\n| record type | SOA                  |\n| MNAME       | ns.primaryserver.com |\n| RNAME       | admin.example.com    |\n| SERIAL      | 1111111111           |\n| REFRESH     | 86400                |\n| RETRY       | 7200                 |\n| EXPIRE      | 4000000              |\n| TTL         | 11200                |\n|             |                      |\n\n\n## A Records\nAddress Records are one of the fundamental types of DNS records\n\nAn A Record allows you to convert the name of a domain directly into an [#Internet Protocol IP address](#Internet%20Protocol%20IP%20address). They can also be used on the root(naked domain name) itself.\n\n## CNAME Records\nCanonical Names (CNAMES) are another fundamental DNS record used to resolve one domain name to another - rather than an IP address.\n\n\n## NS Records\nName Server Records (NS) are used by the top-level domain servers to direct traffic to the DNS server containing the authoritative DNS records. Usually 2-4 records are provided for redundancy.\n\n## TTL\n\nTile to Live (TTL) is the length of time that a DNS record gets cached on the resolving server or the users own local maching\n\nThe lower the TTL - the faster that changes to the DNS records will propagate across the internet.\n\nTTL is always measured in seconds under IPv4.\n\n\n\n\n","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Networking/Networking":{"title":"Networking","content":"\n#networking \n\n[Subnetting](Networking/Subnetting.md)\n[OSI](Networking/OSI.md)\n[DNS](Networking/DNS.md)\n[Webservers](Networking/Webservers.md)","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Networking/OSI":{"title":"OSI","content":"# OSI (Open System Interconnection)\n#networking \n","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Networking/Subnetting":{"title":"Subnetting","content":"# Subnet\n#networking\n\nA subnet, or sub-network, is a [network](https://www.cloudflare.com/learning/network-layer/what-is-the-network-layer/) inside a network. Subnets make networks more efficient. Through subnetting, network traffic can travel a shorter distance without passing through unnecessary [routers](https://www.cloudflare.com/learning/network-layer/what-is-routing/) to reach its destination.\n\n![zSubnet2.png](Networking/zSubnet2.png.png)\nLike the postal service, networks are more efficient when messages travel as directly as possible. When a network receives data packets from another network, it will sort and route those packets by subnet so that the packets do not take an inefficient route to their destination.\n\n## What is an IP address?\n\nIn order to understand subnets, we must quickly define [IP addresses](https://www.cloudflare.com/learning/dns/glossary/what-is-my-ip-address/). Every device that connects to the Internet is assigned a unique IP ([Internet Protocol](https://www.cloudflare.com/learning/ddos/glossary/internet-protocol/)) address, enabling data sent over the Internet to reach the right device out of the billions of devices connected to the Internet. While computers read IP addresses as binary code (a series of 1s and 0s), IP addresses are usually written as a series of alphanumeric characters.\n\n## What do the different parts of an IP address mean?\n\nThis section focuses on IPv4 addresses, which are presented in the form of four decimal numbers separated by periods, like 203.0.113.112. (IPv6 addresses are longer and use letters as well as numbers.)\n\nEvery IP address has two parts. The first part indicates which network the address belongs to. The second part specifies the device within that network. However, the length of the \"first part\" changes depending on the network's class.\n\nNetworks are categorized into different classes, labeled A through E. Class A networks can connect millions of devices. Class B networks and Class C networks are progressively smaller in size. (Class D and Class E networks are not commonly used.)\n\nLet's break down how these classes affect IP address construction:\n\n**Class A network:** Everything before the first period indicates the network, and everything after it specifies the device within that network. Using 203.0.113.112 as an example, the network is indicated by \"203\" and the device by \"0.113.112.\"\n\n**Class B network:** Everything before the second period indicates the network. Again using 203.0.113.112 as an example, \"203.0\" indicates the network and \"113.112\" indicates the device within that network.\n\n**Class C network:** For Class C networks, everything before the third period indicates the network. Using the same example, \"203.0.113\" indicates the Class C network, and \"112\" indicates the device.\n\n## Why is subnetting necessary?\n\nAs the previous example illustrates, the way IP addresses are constructed makes it relatively simple for Internet routers to find the right network to route data into. However, in a Class A network (for instance), there could be millions of connected devices, and it could take some time for the data to find the right device. This is why subnetting comes in handy: subnetting narrows down the IP address to usage within a range of devices.\n\nBecause an IP address is limited to indicating the network and the device address, IP addresses cannot be used to indicate which subnet an IP packet should go to. Routers within a network use something called a subnet mask to sort data into subnetworks.\n\n## What is a subnet mask?\n\nA subnet mask is like an IP address, but for only internal usage within a network. Routers use subnet masks to route data packets to the right place. Subnet masks are not indicated within data packets traversing the Internet — those packets only indicate the destination IP address, which a router will match with a subnet.\n\nSuppose Bob answers Alice's letter, but he sends his reply to Alice's place of employment rather than her home. Alice's office is quite large with many different departments. To ensure employees receive their correspondence quickly, the administrative team at Alice's workplace sorts mail by department rather than by individual employee. After receiving Bob's letter, they look up Alice's department and see she works in Customer Support. They send the letter to the Customer Support department instead of to Alice, and the customer support department gives it to Alice.\n\nIn this analogy, \"Alice\" is like an IP address and \"Customer Support\" is like a subnet mask. By matching Alice to her department, Bob's letter was quickly sorted into the right group of potential recipients. Without this step, office administrators would have to spend time laboriously looking for the exact location of Alice's desk, which could be anywhere in the building.\n\nFor a real-world example, suppose an IP packet is addressed to the IP address 192.0.2.15. This IP address is a Class C network, so the network is identified by \"192.0.2\" (or to be technically precise, 192.0.2.0/24). Network routers forward the packet to a host on the network indicated by \"192.0.2.\"\n\nOnce the packet arrives at that network, a router within the network consults its routing table. It does some binary mathematics using its subnet mask of 255.255.255.0, sees the device address \"15\" (the rest of the IP address indicates the network), and calculates which subnet the packet should go to. It forwards the packet to the router or [switch](https://www.cloudflare.com/learning/network-layer/what-is-a-network-switch/) responsible for delivering packets within that subnet, and the packet arrives at IP address 192.0.2.15 (learn more about [routers](https://www.cloudflare.com/learning/network-layer/what-is-routing/) and [switches](https://www.cloudflare.com/learning/network-layer/what-is-a-network-switch/)).\n\n# CIDR\n**CIDR - Classless Inter-domain Routing**\n\n**The first four IP addresses and the last IP address in each subnet CIDR block are not available for you to use, and cannot be assigned to an instance.**\n\ni.e.\n\n-   10.0.0.0: Network address.\n-   10.0.0.1: Reserved by AWS for the VPC router.\n-   10.0.0.2: Reserved by AWS for DNS.\n-   10.0.0.3: Reserved by AWS for future use.\n-   10.0.0.255: Network broadcast address. We do not support broadcast in a VPC, therefore we reserve this address.\n\nNetwork masks:\n\n-   /16 - supports up to 65,536 IP addresses. Best for large networks.\n-   /24 - supports up to 256 IP addresses. Best for smaller networks.\n-   /27 - supports up to 32 IP addresses\n-   /28 - supports up to 16 IP addresses\n-   /32 - an absolute IP address - matches exactly one\n\nIt’s possible to split a CIDR block into two subnets:\n\n-   one subnet can use CIDR block 10.0.0.0/25 (for addresses 10.0.0.0 - 10.0.0.127)\n-   and then the other subnet can use the CIDR block 10.0.0.128/ 25 (for addresses 10.0.0.128 - 10.0.0.255)\n\nThe allowed CIDR block size in a VPC is between a /16 and /28 subnetmask.\n\nTo enable ping, you need to allow ICMP traffic.\n\nIn order to ensure provisioned EC2 instances have a public IP address, enable “Auto-Assign Public IP” for the subnet.\n\n0.0.0.0/0 is also known as default \nIt represents all possible IP addresses\u003e)\n","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null},"/Networking/Webservers":{"title":"Webservers","content":"\n[Nginx](Cyber%20Operations/Operation%20Tools/Nginx.md)","lastmodified":"2023-03-02T22:23:39.065539072Z","tags":null}}